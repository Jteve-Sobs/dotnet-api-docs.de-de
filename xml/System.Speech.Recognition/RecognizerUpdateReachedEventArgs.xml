<Type Name="RecognizerUpdateReachedEventArgs" FullName="System.Speech.Recognition.RecognizerUpdateReachedEventArgs">
  <Metadata><Meta Name="ms.openlocfilehash" Value="a5443fb7af16d43830d3125aaeda90227ee314a0" /><Meta Name="ms.sourcegitcommit" Value="b53d35b4a410c949742abd4c6a989d1af5357bca" /><Meta Name="ms.translationtype" Value="MT" /><Meta Name="ms.contentlocale" Value="de-DE" /><Meta Name="ms.lasthandoff" Value="07/21/2020" /><Meta Name="ms.locfileid" Value="86589995" /></Metadata><TypeSignature Language="C#" Value="public class RecognizerUpdateReachedEventArgs : EventArgs" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi beforefieldinit RecognizerUpdateReachedEventArgs extends System.EventArgs" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Recognition.RecognizerUpdateReachedEventArgs" />
  <TypeSignature Language="VB.NET" Value="Public Class RecognizerUpdateReachedEventArgs&#xA;Inherits EventArgs" />
  <TypeSignature Language="C++ CLI" Value="public ref class RecognizerUpdateReachedEventArgs : EventArgs" />
  <TypeSignature Language="F#" Value="type RecognizerUpdateReachedEventArgs = class&#xA;    inherit EventArgs" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>3.0.0.0</AssemblyVersion>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.EventArgs</BaseTypeName>
  </Base>
  <Interfaces />
  <Docs>
    <summary>Gibt Daten von einem <see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached" /> oder von einem <see cref="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached" />-Ereignis zurück.</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 `RecognizerUpdateReached` Ereignisse bieten einen Mechanismus zum Anhalten einer Spracherkennungs-Engine, um atomarische und synchrone Änderungen wie das Laden und Entladen von Grammatiken anzuwenden.  
  
 Wenn Ihre Anwendung eine- <xref:System.Speech.Recognition.SpeechRecognitionEngine> Instanz zum Verwalten der Erkennung verwendet, kann Sie eine der- <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A?displayProperty=nameWithType> Methoden verwenden, um anzufordern, dass die Engine angehalten wird, um ein Update zu erhalten. Die- <xref:System.Speech.Recognition.SpeechRecognitionEngine> Instanz löst ein- <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached?displayProperty=nameWithType> Ereignis aus, wenn Sie für das Update bereit ist.  
  
 Wenn eine- <xref:System.Speech.Recognition.SpeechRecognitionEngine> Instanz angehalten ist, können Sie Objekte laden, entladen, aktivieren und deaktivieren <xref:System.Speech.Recognition.Grammar> sowie Werte für die <xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A> <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A> Eigenschaften, und ändern <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A> .  
  
 Wenn Ihre Anwendung eine- <xref:System.Speech.Recognition.SpeechRecognizer> Instanz zum Verwalten der Erkennung verwendet, kann Sie eine der- <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A?displayProperty=nameWithType> Methoden verwenden, um anzufordern, dass die Engine angehalten wird, um ein Update zu erhalten. Die- <xref:System.Speech.Recognition.SpeechRecognizer> Instanz löst ein- <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached?displayProperty=nameWithType> Ereignis aus, wenn Sie für das Update bereit ist.  
  
 Wenn eine- <xref:System.Speech.Recognition.SpeechRecognizer> Instanz angehalten ist, können Sie Objekte laden, entladen, aktivieren und deaktivieren <xref:System.Speech.Recognition.Grammar> .  
  
 Bei der Behandlung von <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached?displayProperty=nameWithType> -und-  <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached?displayProperty=nameWithType> Ereignissen wird eine Erkennungs-Engine angehalten, bis der Ereignishandler zurückgibt.  
  
 <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs> wird von <xref:System.EventArgs> abgeleitet.  
  
   
  
## Examples  
 Das folgende Beispiel zeigt eine Konsolenanwendung, die Objekte lädt und entlädt <xref:System.Speech.Recognition.Grammar> . Die Anwendung verwendet die- <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> Methode, um die sprach Erkennungs-Engine anzufordern, damit Sie ein Update empfangen kann. Die Anwendung lädt oder entlädt ein- <xref:System.Speech.Recognition.Grammar> Objekt.  
  
 Bei jedem Update schreibt ein Handler für das <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached?displayProperty=nameWithType> Ereignis den Namen und den Status der aktuell geladenen <xref:System.Speech.Recognition.Grammar> Objekte in die Konsole. Wenn Grammatiken geladen und entladen werden, erkennt die Anwendung zuerst die Namen von Farm-animals, dann die Namen der Farm-und die Namen der Früchte und dann nur die Namen der Früchte.  
  
```csharp  
using System;  
using System.Speech.Recognition;  
using System.Collections.Generic;  
using System.Threading;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognitionEngine recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize an in-process speech recognition engine and configure its input.  
      using (recognizer = new SpeechRecognitionEngine(new System.Globalization.CultureInfo("en-US")))  
      {  
        recognizer.SetInputToDefaultAudioDevice();  
  
        // Create the first grammar - Farm.  
        Choices animals = new Choices(new string[] { "cow", "pig", "goat" });  
        GrammarBuilder farm = new GrammarBuilder(animals);  
        Grammar farmAnimals = new Grammar(farm);  
        farmAnimals.Name = "Farm";  
  
        // Create the second grammar - Fruit.  
        Choices fruit = new Choices(new string[] { "apples", "peaches", "oranges" });  
        GrammarBuilder favorite = new GrammarBuilder(fruit);  
        Grammar favoriteFruit = new Grammar(favorite);  
        favoriteFruit.Name = "Fruit";  
  
        // Attach event handlers.  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
        recognizer.RecognizerUpdateReached +=  
          new EventHandler<RecognizerUpdateReachedEventArgs>(recognizer_RecognizerUpdateReached);  
        recognizer.SpeechRecognitionRejected +=  
          new EventHandler<SpeechRecognitionRejectedEventArgs>(recognizer_SpeechRecognitionRejected);  
  
        // Load the Farm grammar.  
        recognizer.LoadGrammar(farmAnimals);  
  
        // Start asynchronous, continuous recognition.  
        recognizer.RecognizeAsync(RecognizeMode.Multiple);  
        Console.WriteLine("Starting asynchronous, continuous recognition");  
        Console.WriteLine("  Farm grammar is loaded and enabled.");  
  
        // Pause to recognize farm animals.  
        Thread.Sleep(7000);  
        Console.WriteLine();  
  
        // Request an update and load the Fruit grammar.  
        recognizer.RequestRecognizerUpdate();  
        recognizer.LoadGrammarAsync(favoriteFruit);  
        Thread.Sleep(7000);  
  
        // Request an update and unload the Farm grammar.  
        recognizer.RequestRecognizerUpdate();  
        recognizer.UnloadGrammar(farmAnimals);  
        Thread.Sleep(7000);  
      }  
  
      // Keep the console window open.  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // At the update, get the names and enabled status of the currently loaded grammars.  
    public static void recognizer_RecognizerUpdateReached(  
      object sender, RecognizerUpdateReachedEventArgs e)  
    {  
      Console.WriteLine();  
      Console.WriteLine("Update reached:");  
      Thread.Sleep(1000);  
  
      string qualifier;  
      List<Grammar> grammars = new List<Grammar>(recognizer.Grammars);  
      foreach (Grammar g in grammars)  
      {  
        qualifier = (g.Enabled) ? "enabled" : "disabled";  
        Console.WriteLine("  {0} grammar is loaded and {1}.",  
        g.Name, qualifier);  
      }  
    }  
  
    // Write the text of the recognized phrase to the console.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("    Speech recognized: " + e.Result.Text);  
    }  
  
    // Write a message to the console when recognition fails.  
    static void recognizer_SpeechRecognitionRejected(object sender, SpeechRecognitionRejectedEventArgs e)  
    {  
      Console.WriteLine("    Recognition attempt failed");  
    }  
  }  
}  
  
```  
  
 ]]></format>
    </remarks>
    <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached" />
    <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate" />
    <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate" />
  </Docs>
  <Members>
    <Member MemberName="AudioPosition">
      <MemberSignature Language="C#" Value="public TimeSpan AudioPosition { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.TimeSpan AudioPosition" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.AudioPosition" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property AudioPosition As TimeSpan" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property TimeSpan AudioPosition { TimeSpan get(); };" />
      <MemberSignature Language="F#" Value="member this.AudioPosition : TimeSpan" Usage="System.Speech.Recognition.RecognizerUpdateReachedEventArgs.AudioPosition" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName Language="C#">[get: System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")]</AttributeName>
          <AttributeName Language="F#">[&lt;get: System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")&gt;]</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.TimeSpan</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Ruft die dem Ereignis zugeordnete Audioposition ab.</summary>
        <value>Gibt die Position innerhalb des sprach Puffers eines <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> oder eines zurück, wenn es angehalten wird <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> und ein <c>Erkennungs</c> Ereignis auslöst.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Anwendungen können den von festgelegten Speicherort verwenden <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.AudioPosition%2A> , um auf Audioeingaben zuzugreifen, die aufgetreten sind, während die Erkennungs-Engine angehalten wurde.  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognizerUpdateReachedEventArgs" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate" />
      </Docs>
    </Member>
    <Member MemberName="UserToken">
      <MemberSignature Language="C#" Value="public object UserToken { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance object UserToken" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property UserToken As Object" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Object ^ UserToken { System::Object ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.UserToken : obj" Usage="System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName Language="C#">[get: System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")]</AttributeName>
          <AttributeName Language="F#">[&lt;get: System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")&gt;]</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Object</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Ruft das <c>UserToken</c> ab, das dem System übergeben wird, wenn eine Anwendung <see cref="Overload:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate" /> oder <see cref="Overload:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate" /> aufruft.</summary>
        <value>Gibt ein Objekt zurück, das das <c>userToken</c>enthält.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Eine Anwendung gibt eine `UserToken` an, wenn Sie die Generierung eines `RecognizerUpdateReached` Ereignisses anfordert, indem Sie eine der- <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A?displayProperty=nameWithType> oder-Methoden aufrufen <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A?displayProperty=nameWithType> , die einen- `userToken` Parameter annehmen.  
  
   
  
## Examples  
 Das folgende Beispiel zeigt eine Konsolenanwendung, die Objekte lädt und entlädt <xref:System.Speech.Recognition.Grammar> . Die Anwendung verwendet die- <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> Methode, um die sprach Erkennungs-Engine anzufordern, damit Sie ein Update empfangen kann. Die-Methode übergibt ein- <xref:System.String> Objekt für den- `userToken` Parameter, der beschreibt, was die Anwendung nach dem Update erkennt. Die Anwendung lädt oder entlädt ein- <xref:System.Speech.Recognition.Grammar> Objekt.  
  
 Bei jedem Update schreibt ein Handler für <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached?displayProperty=nameWithType> das Ereignis den Inhalt von `userToken` in die Konsole. Wenn Grammatiken geladen und entladen werden, erkennt die Anwendung zuerst die Namen von Farm-animals, dann die Namen der Farm-und die Namen der Früchte und dann nur die Namen der Früchte.  
  
```  
using System;  
using System.Speech.Recognition;  
using System.Collections.Generic;  
using System.Threading;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognitionEngine recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize an in-process speech recognition engine and configure its input.  
      using (recognizer = new SpeechRecognitionEngine(  
        new System.Globalization.CultureInfo("en-US")))  
      {  
        recognizer.SetInputToDefaultAudioDevice();  
  
        // Create the first grammar - Farm.  
        Choices animals = new Choices(new string[] { "cow", "pig", "goat" });  
        GrammarBuilder farm = new GrammarBuilder(animals);  
        Grammar farmAnimals = new Grammar(farm);  
        farmAnimals.Name = "Farm";  
  
        // Create the second grammar - Fruit.  
        Choices fruit = new Choices(new string[] { "apples", "peaches", "oranges" });  
        GrammarBuilder favorite = new GrammarBuilder(fruit);  
        Grammar favoriteFruit = new Grammar(favorite);  
        favoriteFruit.Name = "Fruit";  
  
        // Attach event handlers.  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
        recognizer.RecognizerUpdateReached +=  
          new EventHandler<RecognizerUpdateReachedEventArgs>(recognizer_RecognizerUpdateReached);  
        recognizer.SpeechRecognitionRejected +=  
          new EventHandler<SpeechRecognitionRejectedEventArgs>(recognizer_SpeechRecognitionRejected);  
  
        // Load the farmAnimals grammar  
        recognizer.LoadGrammar(farmAnimals);  
  
        // Start continuous, asynchronous recognition.  
        recognizer.RecognizeAsync(RecognizeMode.Multiple);  
        Console.WriteLine("Starting asynchronous recognition...");  
        Console.WriteLine("  Farm animals will now be recognized.");  
        Thread.Sleep(7000);  
        Console.WriteLine();  
  
        // Load the Fruit grammar.  
        string activeGrammars = "Farm animals and fruits will now be recognized.";  
        recognizer.RequestRecognizerUpdate(activeGrammars);  
        recognizer.LoadGrammarAsync(favoriteFruit);  
        Console.WriteLine();  
        Thread.Sleep(7000);  
        Console.WriteLine();  
  
        // Unload the Farm grammar.  
        string onlyFruit = "Only fruits will now be recognized.";  
        recognizer.RequestRecognizerUpdate(onlyFruit);  
        recognizer.UnloadGrammar(farmAnimals);  
        Thread.Sleep(7000);  
      }  
  
      // Keep the console window open.  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // At the update, describe what the application will recognize next.  
    public static void recognizer_RecognizerUpdateReached(object sender, RecognizerUpdateReachedEventArgs e)  
    {  
      Console.WriteLine("  Update reached: " + e.UserToken);  
    }  
  
    // Write the text of the recognized phrase to the console.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("    Speech recognized: " + e.Result.Text);  
    }  
  
    // Write a message to the console when recognition fails.  
    static void recognizer_SpeechRecognitionRejected(object sender, SpeechRecognitionRejectedEventArgs e)  
    {  
      Console.WriteLine("    Recognition attempt failed");  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognizerUpdateReachedEventArgs" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate" />
      </Docs>
    </Member>
  </Members>
</Type>
