<Type Name="DictationGrammar" FullName="System.Speech.Recognition.DictationGrammar">
  <Metadata><Meta Name="ms.openlocfilehash" Value="18a457ab8c4b088fb91ffc48e4b48c4dc26c4a89" /><Meta Name="ms.sourcegitcommit" Value="88014e1c5440e3df4f66ef04393854d15b1fd534" /><Meta Name="ms.translationtype" Value="MT" /><Meta Name="ms.contentlocale" Value="de-DE" /><Meta Name="ms.lasthandoff" Value="09/05/2019" /><Meta Name="ms.locfileid" Value="70677532" /></Metadata><TypeSignature Language="C#" Value="public class DictationGrammar : System.Speech.Recognition.Grammar" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi beforefieldinit DictationGrammar extends System.Speech.Recognition.Grammar" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Recognition.DictationGrammar" />
  <TypeSignature Language="VB.NET" Value="Public Class DictationGrammar&#xA;Inherits Grammar" />
  <TypeSignature Language="C++ CLI" Value="public ref class DictationGrammar : System::Speech::Recognition::Grammar" />
  <TypeSignature Language="F#" Value="type DictationGrammar = class&#xA;    inherit Grammar" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>3.0.0.0</AssemblyVersion>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Speech.Recognition.Grammar</BaseTypeName>
  </Base>
  <Interfaces />
  <Docs>
    <summary>Stellt eine Spracherkennungsgrammatik dar, die für Diktat des freien Texts verwendet wird.</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Diese Klasse bietet Anwendungen ein vordefiniertes Sprachmodell, das gesprochene Benutzereingaben in Text verarbeiten kann. Diese Klasse unterstützt sowohl standardmäßige <xref:System.Speech.Recognition.DictationGrammar> als auch benutzerdefinierte-Objekte. Weitere Informationen zum Auswählen einer Diktat Grammatik finden Sie im <xref:System.Speech.Recognition.DictationGrammar.%23ctor%28System.String%29> -Konstruktor.  
  
 Standardmäßig ist das <xref:System.Speech.Recognition.DictationGrammar> Sprachmodell kontextfrei. Es verwendet keine bestimmten Wörter oder Wort Reihenfolge, um Audioeingaben zu identifizieren und zu interpretieren. Um der Diktat Grammatik Kontext hinzuzufügen, verwenden Sie die <xref:System.Speech.Recognition.DictationGrammar.SetDictationContext%2A> -Methode.  
  
> [!NOTE]
>  <xref:System.Speech.Recognition.DictationGrammar>-Objekte unterstützen die <xref:System.Speech.Recognition.Grammar.Priority%2A> -Eigenschaft nicht. <xref:System.Speech.Recognition.DictationGrammar>löst eine <xref:System.NotSupportedException> aus <xref:System.Speech.Recognition.Grammar.Priority%2A> , wenn festgelegt ist.  
  
   
  
## Examples  
 Im folgenden Beispiel werden drei Diktat Grammatiken erstellt, einem neuen <xref:System.Speech.Recognition.SpeechRecognitionEngine> -Objekt hinzugefügt und das neue-Objekt zurückgegeben. Die erste Grammatik ist die standardmäßige Diktat Grammatik. Die zweite Grammatik ist die Rechtschreibprüfung für die Rechtschreibprüfung. Die dritte Grammatik ist die standardmäßige Diktat Grammatik, die einen Kontext Ausdruck enthält. Die <xref:System.Speech.Recognition.DictationGrammar.SetDictationContext%2A> -Methode wird verwendet, um den Kontext Ausdruck der Diktat Grammatik zuzuordnen, nachdem Sie in das <xref:System.Speech.Recognition.SpeechRecognitionEngine> -Objekt geladen wurde.  
  
```csharp  
  
private SpeechRecognitionEngine LoadDictationGrammars()  
{  
  
  // Create a default dictation grammar.  
  DictationGrammar defaultDictationGrammar = new DictationGrammar();  
  defaultDictationGrammar.Name = "default dictation";  
  defaultDictationGrammar.Enabled = true;  
  
  // Create the spelling dictation grammar.  
  DictationGrammar spellingDictationGrammar =  
    new DictationGrammar("grammar:dictation#spelling");  
  spellingDictationGrammar.Name = "spelling dictation";  
  spellingDictationGrammar.Enabled = true;  
  
  // Create the question dictation grammar.  
  DictationGrammar customDictationGrammar =  
    new DictationGrammar("grammar:dictation");  
  customDictationGrammar.Name = "question dictation";  
  customDictationGrammar.Enabled = true;  
  
  // Create a SpeechRecognitionEngine object and add the grammars to it.  
  SpeechRecognitionEngine recoEngine = new SpeechRecognitionEngine();  
  recoEngine.LoadGrammar(defaultDictationGrammar);  
  recoEngine.LoadGrammar(spellingDictationGrammar);  
  recoEngine.LoadGrammar(customDictationGrammar);  
  
  // Add a context to customDictationGrammar.  
  customDictationGrammar.SetDictationContext("How do you", null);  
  
  return recoEngine;  
}  
  
```  
  
 ]]></format>
    </remarks>
    <altmember cref="T:System.Speech.Recognition.Grammar" />
  </Docs>
  <Members>
    <MemberGroup MemberName=".ctor">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Initialisiert eine neue Instanz der <see cref="T:System.Speech.Recognition.DictationGrammar" />-Klasse.</summary>
      </Docs>
    </MemberGroup>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public DictationGrammar ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.DictationGrammar.#ctor" />
      <MemberSignature Language="VB.NET" Value="Public Sub New ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; DictationGrammar();" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters />
      <Docs>
        <summary>Initialisiert eine neue Instanz der <see cref="T:System.Speech.Recognition.DictationGrammar" />-Klasse für die standardmäßige Diktiergrammatik an, die von Windows Desktop Speech Technology bereitgestellt wird.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Die standardmäßige Diktat Grammatik emuliert Standardmethoden, einschließlich Interpunktion. Die Schreibweise eines Worts wird nicht unterstützt.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public DictationGrammar (string topic);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(string topic) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.DictationGrammar.#ctor(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub New (topic As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; DictationGrammar(System::String ^ topic);" />
      <MemberSignature Language="F#" Value="new System.Speech.Recognition.DictationGrammar : string -&gt; System.Speech.Recognition.DictationGrammar" Usage="new System.Speech.Recognition.DictationGrammar topic" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="topic" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="topic">Ein XML-kompatibler universeller Ressourcenbezeichner (URI), der die Diktatgrammatik angibt, entweder <c>grammar:dictation</c> oder <c>grammar:dictation#spelling</c>.</param>
        <summary>Initialisiert eine neue Instanz der <see cref="T:System.Speech.Recognition.DictationGrammar" />-Klasse mit einer bestimmten Diktatgrammatik.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Die Sprachplattform verwendet eine spezialisierte URI-Syntax, um die benutzerdefinierte Diktat Grammatik zu definieren. Der Wert `grammar:dictation` gibt die standardmäßige Diktat Grammatik an. Der Wert `grammar:dictation#spelling` gibt die Rechtschreibprüfung für die Rechtschreibprüfung an.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="SetDictationContext">
      <MemberSignature Language="C#" Value="public void SetDictationContext (string precedingText, string subsequentText);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void SetDictationContext(string precedingText, string subsequentText) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.DictationGrammar.SetDictationContext(System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub SetDictationContext (precedingText As String, subsequentText As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void SetDictationContext(System::String ^ precedingText, System::String ^ subsequentText);" />
      <MemberSignature Language="F#" Value="member this.SetDictationContext : string * string -&gt; unit" Usage="dictationGrammar.SetDictationContext (precedingText, subsequentText)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="precedingText" Type="System.String" />
        <Parameter Name="subsequentText" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="precedingText">Text, der den Anfang eines Diktatkontexts anzeigt.</param>
        <param name="subsequentText">Text, der das Ende eines Diktatkontexts anzeigt.</param>
        <summary>Fügt einer Diktatgrammatik einen Kontext hinzu, die von einem <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> oder einem <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> Objekt geladen wurde.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Standardmäßig verwendet die Diktat Grammatik keine bestimmten Wörter oder Wort Reihen, um Audioeingaben zu identifizieren und zu interpretieren. Wenn einer Diktat Grammatik ein Kontext hinzugefügt wird, verwendet `precedingText` die Erkennungs-Engine und `subsequentText` , um zu identifizieren, wann Sprache als Diktat interpretiert werden soll.  
  
> [!NOTE]
>  Eine Diktat Grammatik muss von einem <xref:System.Speech.Recognition.SpeechRecognizer> -oder <xref:System.Speech.Recognition.SpeechRecognitionEngine> -Objekt geladen werden, bevor Sie <xref:System.Speech.Recognition.DictationGrammar.SetDictationContext%2A> zum Hinzufügen eines Kontexts verwenden können.  
  
 In der folgenden Tabelle wird beschrieben, wie die Erkennungs-Engine die zwei Parameter verwendet, um zu bestimmen, wann die Diktat Grammatik verwendet werden soll.  
  
|`precedingText`|`subsequentText`|Beschreibung|  
|---------------------|----------------------|-----------------|  
|nicht `null`|nicht `null`|Die Erkennungs-Engine verwendet die Begriffe, um mögliche Kandidaten Ausdrücke zu Klammern.|  
|`null`|nicht `null`|Die Erkennungs-Engine verwendet `subsequentText` das, um das Diktat zu beenden.|  
|nicht `null`|`null`|Die Erkennungs-Engine verwendet `precedingText` das, um mit dem Diktat zu beginnen.|  
|`null`|`null`|Die Erkennungs-Engine verwendet bei Verwendung der Diktat Grammatik keinen Kontext.|  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.Grammar" />
      </Docs>
    </Member>
  </Members>
</Type>
