<Type Name="DictationGrammar" FullName="System.Speech.Recognition.DictationGrammar">
  <Metadata>
    <Meta Name="ms.openlocfilehash" Value="d5c28c7dfec51de61f92b6ce9ce6ae8cdb22688d" />
    <Meta Name="ms.sourcegitcommit" Value="5a49536d99d2d0b54e4cb7280870903e043272df" />
    <Meta Name="ms.translationtype" Value="HT" />
    <Meta Name="ms.contentlocale" Value="de-DE" />
    <Meta Name="ms.lasthandoff" Value="07/03/2018" />
    <Meta Name="ms.locfileid" Value="37756011" />
  </Metadata>
  <TypeSignature Language="C#" Value="public class DictationGrammar : System.Speech.Recognition.Grammar" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi beforefieldinit DictationGrammar extends System.Speech.Recognition.Grammar" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Recognition.DictationGrammar" />
  <TypeSignature Language="VB.NET" Value="Public Class DictationGrammar&#xA;Inherits Grammar" />
  <TypeSignature Language="C++ CLI" Value="public ref class DictationGrammar : System::Speech::Recognition::Grammar" />
  <TypeSignature Language="F#" Value="type DictationGrammar = class&#xA;    inherit Grammar" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>3.0.0.0</AssemblyVersion>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Speech.Recognition.Grammar</BaseTypeName>
  </Base>
  <Interfaces />
  <Docs>
    <summary>Stellt eine Spracherkennungsgrammatik dar, die für Diktat des freien Texts verwendet wird.</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Diese Klasse stellt Anwendungen mit einem vordefinierten Language-Modell, das gesprochene Benutzereingaben in Text verarbeitet werden können. Diese Klasse unterstützt die standardmetriken und benutzerdefinierten <xref:System.Speech.Recognition.DictationGrammar> Objekte. Weitere Informationen zum Auswählen einer diktatgrammatik, finden Sie unter den <xref:System.Speech.Recognition.DictationGrammar.%23ctor%28System.String%29> Konstruktor.  
  
 In der Standardeinstellung die <xref:System.Speech.Recognition.DictationGrammar> Sprachmodell ist Kontext frei. Es macht nicht die Verwendung bestimmter Wörter oder auch word zu identifizieren und Interpretieren der Audioeingabe. Verwenden Sie zum Hinzufügen von Kontext, der die diktatgrammatik der <xref:System.Speech.Recognition.DictationGrammar.SetDictationContext%2A> Methode.  
  
> [!NOTE]
>  <xref:System.Speech.Recognition.DictationGrammar> Objekte unterstützen nicht die <xref:System.Speech.Recognition.Grammar.Priority%2A> Eigenschaft. <xref:System.Speech.Recognition.DictationGrammar> löst eine <xref:System.NotSupportedException> Wenn <xref:System.Speech.Recognition.Grammar.Priority%2A> festgelegt ist.  
  
   
  
## Examples  
 Das folgende Beispiel erstellt drei Diktat Grammatiken, fügt diese in ein neues <xref:System.Speech.Recognition.SpeechRecognitionEngine> -Objekt und gibt das neue Objekt zurück. Die erste Grammatik ist die standardmäßige diktiergrammatik an. Die zweite Grammatik ist die Schreibweise diktatgrammatik. Die dritte Grammatik ist die standardmäßige diktiergrammatik an, die einen Kontext-Ausdruck enthält. Die <xref:System.Speech.Recognition.DictationGrammar.SetDictationContext%2A> Methode wird verwendet, um den Kontext Ausdruck mit die diktatgrammatik zuordnen, nachdem es, in geladen wird der <xref:System.Speech.Recognition.SpeechRecognitionEngine> Objekt.  
  
```csharp  
  
private SpeechRecognitionEngine LoadDictationGrammars()  
{  
  
  // Create a default dictation grammar.  
  DictationGrammar defaultDictationGrammar = new DictationGrammar();  
  defaultDictationGrammar.Name = "default dictation";  
  defaultDictationGrammar.Enabled = true;  
  
  // Create the spelling dictation grammar.  
  DictationGrammar spellingDictationGrammar =  
    new DictationGrammar("grammar:dictation#spelling");  
  spellingDictationGrammar.Name = "spelling dictation";  
  spellingDictationGrammar.Enabled = true;  
  
  // Create the question dictation grammar.  
  DictationGrammar customDictationGrammar =  
    new DictationGrammar("grammar:dictation");  
  customDictationGrammar.Name = "question dictation";  
  customDictationGrammar.Enabled = true;  
  
  // Create a SpeechRecognitionEngine object and add the grammars to it.  
  SpeechRecognitionEngine recoEngine = new SpeechRecognitionEngine();  
  recoEngine.LoadGrammar(defaultDictationGrammar);  
  recoEngine.LoadGrammar(spellingDictationGrammar);  
  recoEngine.LoadGrammar(customDictationGrammar);  
  
  // Add a context to customDictationGrammar.  
  customDictationGrammar.SetDictationContext("How do you", null);  
  
  return recoEngine;  
}  
  
```  
  
 ]]></format>
    </remarks>
    <altmember cref="T:System.Speech.Recognition.Grammar" />
  </Docs>
  <Members>
    <MemberGroup MemberName=".ctor">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Initialisiert eine neue Instanz der <see cref="T:System.Speech.Recognition.DictationGrammar" />-Klasse.</summary>
      </Docs>
    </MemberGroup>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public DictationGrammar ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.DictationGrammar.#ctor" />
      <MemberSignature Language="VB.NET" Value="Public Sub New ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; DictationGrammar();" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters />
      <Docs>
        <summary>Initialisiert eine neue Instanz der <see cref="T:System.Speech.Recognition.DictationGrammar" />-Klasse für die standardmäßige Diktiergrammatik an, die von Windows Desktop Speech Technology bereitgestellt wird.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Die standardmäßige diktiergrammatik emuliert standard Diktat-Methoden, einschließlich Satzzeichen. Die Schreibweise eines Worts wird nicht unterstützt.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public DictationGrammar (string topic);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(string topic) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.DictationGrammar.#ctor(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub New (topic As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; DictationGrammar(System::String ^ topic);" />
      <MemberSignature Language="F#" Value="new System.Speech.Recognition.DictationGrammar : string -&gt; System.Speech.Recognition.DictationGrammar" Usage="new System.Speech.Recognition.DictationGrammar topic" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="topic" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="topic">Ein XML-kompatibler universeller Ressourcenbezeichner (URI), der die Diktatgrammatik angibt, entweder <c>grammar:dictation</c> oder <c>grammar:dictation#spelling</c>.</param>
        <summary>Initialisiert eine neue Instanz der <see cref="T:System.Speech.Recognition.DictationGrammar" />-Klasse mit einer bestimmten Diktatgrammatik.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Sprachplattform verwendet eine spezielle URI-Syntax zum Definieren der benutzerdefinierten diktatgrammatik an. Der Wert `grammar:dictation` gibt Sie die standardmäßige diktiergrammatik an. Der Wert `grammar:dictation#spelling` gibt an, der die diktatgrammatik Schreibweise.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="SetDictationContext">
      <MemberSignature Language="C#" Value="public void SetDictationContext (string precedingText, string subsequentText);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void SetDictationContext(string precedingText, string subsequentText) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.DictationGrammar.SetDictationContext(System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub SetDictationContext (precedingText As String, subsequentText As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void SetDictationContext(System::String ^ precedingText, System::String ^ subsequentText);" />
      <MemberSignature Language="F#" Value="member this.SetDictationContext : string * string -&gt; unit" Usage="dictationGrammar.SetDictationContext (precedingText, subsequentText)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="precedingText" Type="System.String" />
        <Parameter Name="subsequentText" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="precedingText">Text, der den Anfang eines Diktatkontexts anzeigt.</param>
        <param name="subsequentText">Text, der das Ende eines Diktatkontexts anzeigt.</param>
        <summary>Fügt einer Diktatgrammatik einen Kontext hinzu, die von einem <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> oder einem <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> Objekt geladen wurde.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Standardmäßig ist die diktatgrammatik nicht einzurichten, verwenden Sie für bestimmte Begriffe startet oder word zu identifizieren und Interpretieren der Audioeingabe. Wenn es sich bei einer diktatgrammatik ein Kontext hinzugefügt wird, die erkennungs-Engine verwendet die `precedingText` und `subsequentText` zu ermitteln, wann die Spracherkennung als Diktat interpretiert.  
  
> [!NOTE]
>  Eine diktatgrammatik muss geladen werden, indem eine <xref:System.Speech.Recognition.SpeechRecognizer> oder <xref:System.Speech.Recognition.SpeechRecognitionEngine> Objekt vor der Verwendung <xref:System.Speech.Recognition.DictationGrammar.SetDictationContext%2A> einen Kontext hinzufügen.  
  
 In der folgende Tabelle wird beschrieben, wie die erkennungs-Engine die beiden Parameter verwendet, um zu bestimmen, wann mit die diktatgrammatik.  
  
|`precedingText`|`subsequentText`|Beschreibung |  
|---------------------|----------------------|-----------------|  
|nicht `null`|nicht `null`|Die erkennungs-Engine verwendet die Bedingungen, um die möglichen Ausdrücke Klammer.|  
|`null`|nicht `null`|Die erkennungs-Engine verwendet die `subsequentText` Diktat abgeschlossen.|  
|nicht `null`|`null`|Die erkennungs-Engine verwendet die `precedingText` Diktat zu starten.|  
|`null`|`null`|Die erkennungs-Engine verwendet keine Verwendung von die diktatgrammatik einen Kontext an.|  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.Grammar" />
      </Docs>
    </Member>
  </Members>
</Type>