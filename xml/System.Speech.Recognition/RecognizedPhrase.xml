<Type Name="RecognizedPhrase" FullName="System.Speech.Recognition.RecognizedPhrase">
  <Metadata>
    <Meta Name="ms.openlocfilehash" Value="71464227f9486ed513c58cfb8029f276b246b4b8" />
    <Meta Name="ms.sourcegitcommit" Value="6a0b904069161bbaec4ffd02aa7d9cf38c61e72e" />
    <Meta Name="ms.translationtype" Value="HT" />
    <Meta Name="ms.contentlocale" Value="de-DE" />
    <Meta Name="ms.lasthandoff" Value="06/24/2018" />
    <Meta Name="ms.locfileid" Value="36409368" />
  </Metadata>
  <TypeSignature Language="C#" Value="public class RecognizedPhrase" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi serializable beforefieldinit RecognizedPhrase extends System.Object" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Recognition.RecognizedPhrase" />
  <TypeSignature Language="VB.NET" Value="Public Class RecognizedPhrase" />
  <TypeSignature Language="C++ CLI" Value="public ref class RecognizedPhrase" />
  <TypeSignature Language="F#" Value="type RecognizedPhrase = class" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Object</BaseTypeName>
  </Base>
  <Interfaces />
  <Attributes>
    <Attribute>
      <AttributeName>System.Diagnostics.DebuggerDisplay("{Text}")</AttributeName>
    </Attribute>
  </Attributes>
  <Docs>
    <summary>Contains detailed information, generated by the speech recognizer, about the recognized input.</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Diese Klasse enthält ausführliche Informationen zu den Wörtern und Ausdrücken, die während der Spracherkennung Recognition Vorgänge, einschließlich der folgenden verarbeitet werden:  
  
-   Die <xref:System.Speech.Recognition.RecognizedPhrase.Grammar%2A> Eigenschaftenverweise der <xref:System.Speech.Recognition.Grammar> , dass die Erkennung verwendet wird, um die Eingabe zu identifizieren.  
  
-   Die <xref:System.Speech.Recognition.RecognizedPhrase.Text%2A> Eigenschaft enthält den normalisierten Text für den Ausdruck.  
  
-   Die <xref:System.Speech.Recognition.RecognizedPhrase.Semantics%2A> -Eigenschaft verweist auf die semantischen Informationen, die im Resultset enthalten sind. Die semantische Informationen ist ein Wörterbuch mit den Schlüsselnamen und zugehörige semantische Daten.  
  
-   Die <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> Eigenschaft enthält eine geordnete Auflistung von <xref:System.Speech.Recognition.RecognizedWordUnit> Objekte, die jeweils darstellen erkannt Wort in der Eingabe. À Word enthält Anzeigeformat lexikalischen Format und Aussprache-Informationen für das entsprechende Wort.  
  
-   Die <xref:System.Speech.Recognition.RecognizedPhrase.ReplacementWordUnits%2A> Eigenschaft enthält Informationen über spezielle Word Ersetzung.  
  
-   Die <xref:System.Speech.Recognition.RecognizedPhrase.Homophones%2A> und <xref:System.Speech.Recognition.RecognizedPhrase.HomophoneGroupId%2A> Eigenschaften enthalten Informationen über Erkennungsalternativen, die gleiche oder ähnlich wie Aussprache verfügen.  
  
-   Der Wert, der die <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> Eigenschaft gibt den Grad an Sicherheit, von der Spracherkennung zugewiesen, dass die Eingabe ein erkannten Ausdrucks entspricht, an.  
  
 Gibt zurück, die von der Spracherkennung Erkennungsergebnisse in einem <xref:System.Speech.Recognition.RecognitionResult> -Objekt, das erbt <xref:System.Speech.Recognition.RecognizedPhrase>. Das Erkennungsergebnis <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> Eigenschaft enthält eine geordnete Auflistung von <xref:System.Speech.Recognition.RecognizedPhrase> Objekte, von denen jedes eine mögliche Entsprechung für die Eingabe für die Erkennung ist.  
  
   
  
## Examples  
 Das folgende Beispiel zeigt einen Handler für ein <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized?displayProperty=nameWithType>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized?displayProperty=nameWithType>, oder <xref:System.Speech.Recognition.Grammar.SpeechRecognized?displayProperty=nameWithType> Ereignis und einige Informationen zum zugeordneten der <xref:System.Speech.Recognition.RecognitionResult> Objekt. Die <xref:System.Speech.Recognition.RecognitionResult>-Klasse wird aus der <xref:System.Speech.Recognition.RecognizedPhrase>-Klasse abgeleitet.  
  
```csharp  
void SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  
{  
  if (e.Result == null) return;  
  
  // Add event handler code here.  
  
  // The following code illustrates some of the information available  
  // in the recognition result.  
  Console.WriteLine("Recognition result summary:");  
  Console.WriteLine(  
    "  Recognized phrase: {0}\n" +   
    "  Confidence score {1}\n" +   
    "  Grammar used: {2}\n",   
    e.Result.Text, e.Result.Confidence, e.Result.Grammar.Name);  
  
  // Display the semantic values in the recognition result.  
  Console.WriteLine("  Semantic results:");  
  foreach (KeyValuePair<String, SemanticValue> child in e.Result.Semantics)  
  {  
    Console.WriteLine("    The {0} city is {1}",  
      child.Key, child.Value.Value ?? "null");  
  }  
  Console.WriteLine();  
  
  // Display information about the words in the recognition result.  
  Console.WriteLine("  Word summary: ");  
  foreach (RecognizedWordUnit word in e.Result.Words)  
  {  
    Console.WriteLine(  
      "    Lexical form ({1})" +  
      " Pronunciation ({0})" +  
      " Display form ({2})",  
      word.Pronunciation, word.LexicalForm, word.DisplayAttributes);  
  }  
  
  // Display information about the audio in the recognition result.  
  Console.WriteLine("  Input audio summary:\n" +  
    "    Candidate Phrase at:       {0} mSec\n" +  
    "    Phrase Length:             {1} mSec\n" +  
    "    Input State Time:          {2}\n" +  
    "    Input Format:              {3}\n",  
    e.Result.Audio.AudioPosition,  
    e.Result.Audio.Duration,  
    e.Result.Audio.StartTime,  
    e.Result.Audio.Format.EncodingFormat);  
  
  // Display information about the alternate recognitions in the recognition result.  
  Console.WriteLine("  Alternate phrase collection:");  
  foreach (RecognizedPhrase phrase in e.Result.Alternates)  
  {  
    Console.WriteLine("    Phrase: " + phrase.Text);  
    Console.WriteLine("    Confidence score: " + phrase.Confidence);  
  }  
}  
```  
  
 ]]></format>
    </remarks>
    <altmember cref="T:System.Speech.Recognition.RecognitionResult" />
    <altmember cref="T:System.Speech.Recognition.RecognizedWordUnit" />
  </Docs>
  <Members>
    <Member MemberName="Confidence">
      <MemberSignature Language="C#" Value="public float Confidence { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance float32 Confidence" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedPhrase.Confidence" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Confidence As Single" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property float Confidence { float get(); };" />
      <MemberSignature Language="F#" Value="member this.Confidence : single" Usage="System.Speech.Recognition.RecognizedPhrase.Confidence" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Single</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Gets a value, assigned by the recognizer, that represents the likelihood that a <see cref="T:System.Speech.Recognition.RecognizedPhrase" /> matches a given input.</summary>
        <value>Eine relative Maßnahme der Sicherheit der richtigen Erkennung eines Ausdrucks. Der Wert liegt zwischen 0,0 und 1,0 (geringes bis hohes Vertrauen).</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Vertrauensergebnisse nicht die absolute Wahrscheinlichkeit an, dass ein Ausdruck ordnungsgemäß erkannt wurde. Stattdessen geben vertrauensergebnisse einen Mechanismus für die relative Genauigkeit für mehrere Erkennungsalternativen für eine gegebene Eingabe verglichen. Dies erleichtert die genaueste Recognition Resultsets zurückgeben. Beispielsweise verfügt ein erkannten Ausdrucks ein vertrauensergebnis 0,8, bedeutet dies nicht, dass der Ausdruck wird die korrekte Übereinstimmung für die Eingabe einer 80 % Wahrscheinlichkeit hat.  Dies bedeutet, dass der Ausdruck ist wahrscheinlicher, dass der korrekte Übereinstimmung für die Eingabe als andere Ergebnisse, die vertrauen Bewertungen kleiner als 0,8.  
  
 Ein vertrauensergebnis selbst hat keine Bedeutung, es sei denn, Sie alternative Ergebnisse berücksichtigt werden sollen, aus der gleichen Erkennungsvorgang oder vorherigen Anerkennungen von derselben Eingabe vergleichen haben. Die Werte werden verwendet, um alternative Candidate Ausdrücke zurückgegebenes Rangfolge der <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> Eigenschaft <xref:System.Speech.Recognition.RecognitionResult> Objekte.  
  
 Vertrauenswerte sind relativ und eindeutige auf jede Audioeingabe. Vertrauen Rückgabewerte von zwei verschiedenen Erkennungsmodule können nicht sinnvoll verglichen werden.  
  
 Ein Spracherkennungsmodul möglicherweise Spracheingabe einschließlich Hintergrund Störungen, inarticulate-Sprache, oder bis zur servicebereitstellung Wörter oder Word Sequenzen aus verschiedenen Gründen ein niedriges vertrauensergebnis zuweisen. Wenn die Anwendung Parallelität mit einer <xref:System.Speech.Recognition.SpeechRecognitionEngine> Instanz können Sie den Vertrauensgrad, welche Sprache Eingabe akzeptiert oder abgelehnt wird, mit einem der, Ändern der <xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A> Methoden. Vertrauen Schwellenwerte für die freigegebenen Erkennung von verwalteten <xref:System.Speech.Recognition.SpeechRecognizer>, ein Benutzerprofil zugeordnet und in der Windows-Registrierung gespeichert sind. Anwendungen sollten keine Änderungen an der Registrierung für die Eigenschaften der freigegebenen Erkennung schreiben.  
  
 Die <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> Eigenschaft von der <xref:System.Speech.Recognition.RecognitionResult> Objekt enthält eine geordnete Auflistung von <xref:System.Speech.Recognition.RecognizedPhrase> Objekte, von denen jedes eine mögliche Entsprechung für die Eingabe für die Erkennung ist. Die Varianten sind vom höchsten zum niedrigsten vertrauen sortiert.  
  
   
  
## Examples  
 Das folgende Beispiel zeigt einen Handler für ein <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized?displayProperty=nameWithType>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized?displayProperty=nameWithType>, oder <xref:System.Speech.Recognition.Grammar.SpeechRecognized?displayProperty=nameWithType> Ereignis. Das Beispiel zeigt Informationen über die <xref:System.Speech.Recognition.RecognitionResult> Objekt, von denen einige stammt aus <xref:System.Speech.Recognition.RecognizedPhrase>. Der Ereignishandler zeigt vertrauensergebnisse für eines erkannten Ausdrucks sowie für Erkennungsalternativen an.  
  
```csharp  
void SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  
{  
  if (e.Result == null) return;  
  
  // Add event handler code here.  
  
  // The following code illustrates some of the information available  
  // in the recognition result.  
  Console.WriteLine("Recognition result summary:");  
  Console.WriteLine(  
    "  Recognized phrase: {0}\n" +   
    "  Confidence score {1}\n" +   
    "  Grammar used: {2}\n",   
    e.Result.Text, e.Result.Confidence, e.Result.Grammar.Name);  
  
  // Display the semantic values in the recognition result.  
  Console.WriteLine("  Semantic results:");  
  foreach (KeyValuePair<String, SemanticValue> child in e.Result.Semantics)  
  {  
    Console.WriteLine("    The {0} city is {1}",  
      child.Key, child.Value.Value ?? "null");  
  }  
  Console.WriteLine();  
  
  // Display information about the words in the recognition result.  
  Console.WriteLine("  Word summary: ");  
  foreach (RecognizedWordUnit word in e.Result.Words)  
  {  
    Console.WriteLine(  
      "    Lexical form ({1})" +  
      " Pronunciation ({0})" +  
      " Display form ({2})",  
      word.Pronunciation, word.LexicalForm, word.DisplayAttributes);  
  }  
  
  // Display information about the audio in the recognition result.  
  Console.WriteLine("  Input audio summary:\n" +  
    "    Candidate Phrase at:       {0} mSec\n" +  
    "    Phrase Length:             {1} mSec\n" +  
    "    Input State Time:          {2}\n" +  
    "    Input Format:              {3}\n",  
    e.Result.Audio.AudioPosition,  
    e.Result.Audio.Duration,  
    e.Result.Audio.StartTime,  
    e.Result.Audio.Format.EncodingFormat);  
  
  // Display information about the alternate recognitions in the recognition result.  
  Console.WriteLine("  Alternate phrase collection:");  
  foreach (RecognizedPhrase phrase in e.Result.Alternates)  
  {  
    Console.WriteLine("    Phrase: " + phrase.Text);  
    Console.WriteLine("    Confidence score: " + phrase.Confidence);  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognitionResult" />
        <altmember cref="P:System.Speech.Recognition.RecognitionResult.Alternates" />
        <altmember cref="T:System.Speech.Recognition.SpeechRecognitionEngine" />
        <altmember cref="T:System.Speech.Recognition.SpeechRecognizer" />
      </Docs>
    </Member>
    <Member MemberName="ConstructSmlFromSemantics">
      <MemberSignature Language="C#" Value="public System.Xml.XPath.IXPathNavigable ConstructSmlFromSemantics ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Xml.XPath.IXPathNavigable ConstructSmlFromSemantics() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.RecognizedPhrase.ConstructSmlFromSemantics" />
      <MemberSignature Language="VB.NET" Value="Public Function ConstructSmlFromSemantics () As IXPathNavigable" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; System::Xml::XPath::IXPathNavigable ^ ConstructSmlFromSemantics();" />
      <MemberSignature Language="F#" Value="member this.ConstructSmlFromSemantics : unit -&gt; System.Xml.XPath.IXPathNavigable" Usage="recognizedPhrase.ConstructSmlFromSemantics " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Xml.XPath.IXPathNavigable</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Returns a semantic markup language (SML) document for the semantic information in the <see cref="T:System.Speech.Recognition.RecognizedPhrase" /> object.</summary>
        <returns>Returns an SML description of the semantics of the <see cref="T:System.Speech.Recognition.RecognizedPhrase" /> as an [XPath](http://msdn.microsoft.com/library/ms256115.aspx) navigable object.</returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Informationen zu den semantic Markup Language (SML), finden Sie unter der [Semantic Markup Language Reference](http://msdn.microsoft.com/library/f9d83443-2cac-49bc-a447-210feda62f5d).  
  
   
  
## Examples  
 Im folgenden Beispiel gibt eine Methode eine Zeichenfolge, die das SML für die Semantik eines erkannten Ausdrucks enthält, zurück.  
  
```  
private string GetSemanticsSML(RecognizedPhrase result)  
{  
  if (result.Semantics.Count > 0)  
  {  
    return result.ConstructSmlFromSemantics().CreateNavigator().OuterXml;  
  }  
  else  
  {  
    return null;  
  }  
}  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="Grammar">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.Grammar Grammar { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Speech.Recognition.Grammar Grammar" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedPhrase.Grammar" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Grammar As Grammar" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::Recognition::Grammar ^ Grammar { System::Speech::Recognition::Grammar ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.Grammar : System.Speech.Recognition.Grammar" Usage="System.Speech.Recognition.RecognizedPhrase.Grammar" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.Grammar</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Gets the <see cref="T:System.Speech.Recognition.Grammar" /> that the speech recognizer used to return the <see cref="T:System.Speech.Recognition.RecognizedPhrase" />.</summary>
        <value>Das Grammatikobjekt, das die Spracherkennung verwendet, um die Eingabe zu identifizieren.</value>
        <remarks>To be added.</remarks>
        <altmember cref="T:System.Speech.Recognition.Grammar" />
        <altmember cref="T:System.Speech.Recognition.RecognitionResult" />
        <altmember cref="T:System.Speech.Recognition.SpeechRecognitionEngine" />
        <altmember cref="T:System.Speech.Recognition.SpeechRecognizer" />
      </Docs>
    </Member>
    <Member MemberName="HomophoneGroupId">
      <MemberSignature Language="C#" Value="public int HomophoneGroupId { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance int32 HomophoneGroupId" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedPhrase.HomophoneGroupId" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property HomophoneGroupId As Integer" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property int HomophoneGroupId { int get(); };" />
      <MemberSignature Language="F#" Value="member this.HomophoneGroupId : int" Usage="System.Speech.Recognition.RecognizedPhrase.HomophoneGroupId" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Int32</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Gets the identifier for the homophone group for the phrase.</summary>
        <value>Der Bezeichner für die Homophongruppe für den Ausdruck.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Die von der Spracherkennung weist eine Gruppen-ID zu allen Erkennungsalternativen, die dieselbe Aussprache verfügen. Für jede alternative, die über eine eindeutige Aussprache verfügt, erstellt die Erkennung einer homophongruppe. Die von der Spracherkennung generiert neue Gruppe von Bezeichnern für jeden Vorgang ausführen und die Bezeichner können nicht verwendet werden, um aus, die aus separaten Erkennungsvorgänge generiert.  
  
 Z. B. für eine Erkennungsergebnis, das die alternativen "Tale", "Tail" und "warnen" enthalten, die ersten beiden alternativen würde zu einer homophongruppe gehören, und die letzte Alternative wäre das einzige Element der eine zweite homophongruppe.  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.RecognitionResult.Alternates" />
        <altmember cref="P:System.Speech.Recognition.RecognizedPhrase.Homophones" />
      </Docs>
    </Member>
    <Member MemberName="Homophones">
      <MemberSignature Language="C#" Value="public System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.RecognizedPhrase&gt; Homophones { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Collections.ObjectModel.ReadOnlyCollection`1&lt;class System.Speech.Recognition.RecognizedPhrase&gt; Homophones" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedPhrase.Homophones" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Homophones As ReadOnlyCollection(Of RecognizedPhrase)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Collections::ObjectModel::ReadOnlyCollection&lt;System::Speech::Recognition::RecognizedPhrase ^&gt; ^ Homophones { System::Collections::ObjectModel::ReadOnlyCollection&lt;System::Speech::Recognition::RecognizedPhrase ^&gt; ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.Homophones : System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.RecognizedPhrase&gt;" Usage="System.Speech.Recognition.RecognizedPhrase.Homophones" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.RecognizedPhrase&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Gets a collection of the recognition alternates that have the same pronunciation as this recognized phrase.</summary>
        <value>Eine schreibgeschützte Auflistung von Erkennungsalternativen, die über dieselbe Aussprache verfügen wie dieser erkannte Ausdruck.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Diese Eigenschaft gibt alle anderen Erkennungsalternativen, die dieselbe Aussprache verfügen wie dieser erkannte Ausdruck.  
  
 Beispielsweise würde die Homophonen-Auflistung für die erste Alternative, "Tale" für eine Erkennungsergebnis, das die alternativen, "Tale" und "Ende" enthalten, der zweite Ausdruck "Tail" enthalten. Die Auflistung der Homophonen für die zweite Alternative, "Tail" würde der erste Ausdruck "Tale" enthalten.  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.RecognitionResult.Alternates" />
        <altmember cref="P:System.Speech.Recognition.RecognizedPhrase.HomophoneGroupId" />
      </Docs>
    </Member>
    <Member MemberName="ReplacementWordUnits">
      <MemberSignature Language="C#" Value="public System.Collections.ObjectModel.Collection&lt;System.Speech.Recognition.ReplacementText&gt; ReplacementWordUnits { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Collections.ObjectModel.Collection`1&lt;class System.Speech.Recognition.ReplacementText&gt; ReplacementWordUnits" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedPhrase.ReplacementWordUnits" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property ReplacementWordUnits As Collection(Of ReplacementText)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Collections::ObjectModel::Collection&lt;System::Speech::Recognition::ReplacementText ^&gt; ^ ReplacementWordUnits { System::Collections::ObjectModel::Collection&lt;System::Speech::Recognition::ReplacementText ^&gt; ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.ReplacementWordUnits : System.Collections.ObjectModel.Collection&lt;System.Speech.Recognition.ReplacementText&gt;" Usage="System.Speech.Recognition.RecognizedPhrase.ReplacementWordUnits" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Collections.ObjectModel.Collection&lt;System.Speech.Recognition.ReplacementText&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Gets information about the text that the speech recognizer changed as part of speech-to-text normalization.</summary>
        <value>Eine Auflistung der <see cref="T:System.Speech.Recognition.ReplacementText" />-Objekte, die Textabschnitte beschreiben, die die Spracherkennung ersetzt hat, als sie die erkannte Eingabe normalisierte.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Im Rahmen des Prozesses Recognition Spracherkennung normalisiert die Spracherkennung die erkannte Eingabe in einem Anzeigeformular.  
  
 Die Spracheingabe "25 Dollar", generiert z. B. ein Erkennungsergebnis, in dem die <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> Eigenschaft enthält, die Wörter "20", "5" und "Dollar", und die <xref:System.Speech.Recognition.RecognizedPhrase.Text%2A> Eigenschaft enthält den Ausdruck "25,00". Weitere Informationen zu textnormalisierung, finden Sie unter der <xref:System.Speech.Recognition.ReplacementText> Klasse.  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognizedWordUnit" />
        <altmember cref="T:System.Speech.Recognition.ReplacementText" />
        <altmember cref="P:System.Speech.Recognition.RecognizedPhrase.Text" />
        <altmember cref="P:System.Speech.Recognition.RecognizedPhrase.Words" />
      </Docs>
    </Member>
    <Member MemberName="Semantics">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.SemanticValue Semantics { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Speech.Recognition.SemanticValue Semantics" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedPhrase.Semantics" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Semantics As SemanticValue" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::Recognition::SemanticValue ^ Semantics { System::Speech::Recognition::SemanticValue ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.Semantics : System.Speech.Recognition.SemanticValue" Usage="System.Speech.Recognition.RecognizedPhrase.Semantics" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.SemanticValue</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Gets the semantic information that is associated with the recognized phrase.</summary>
        <value>Die semantischen Informationen, die dem erkannten Ausdruck zugeordnet sind.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Eine Sprache Recognition Grammatik kann semantischen Informationen enthalten. Wenn eine von der Spracherkennung ein Erkennungsergebnis für eine solche Grammatik generiert, kann die semantische Informationen im Ergebnis Recognition gemäß den Regeln der Grammatik und die Eingabe für die Erkennung von enthalten. Weitere Informationen zu semantischen Informationen finden Sie unter [semantische Grundlegendes zu den Ergebnissen](http://msdn.microsoft.com/library/2a9dbd8b-cf6d-42cd-bbb9-ca0b3e534005) und <xref:System.Speech.Recognition.SemanticResultKey> und <xref:System.Speech.Recognition.SemanticResultValue> Klassen.  
  
   
  
## Examples  
 Das folgende Beispiel definiert eine Methode, die bestimmte semantischen Informationen aus einer erkannten Ausdruck abruft. Bei Rückgabe dieser Methode enthält den Wert für die semantische Schlüssel oder Null, wenn der Wert nicht abgerufen wurde. Diese Methode überprüft nur für den Schlüssel der obersten Ebene. Da die semantische Informationen in einer Struktur von Werten enthalten ist, müssen auf niedrigerer Ebene Schlüssel über den zurückgegebenen semantische Wert zugegriffen werden.  
  
```  
static bool TryGetSemanticValue(  
      RecognizedPhrase phrase, string key, out SemanticValue value)  
{  
  value = null;  
  bool found = phrase.Semantics.ContainsKey(key);  
  if (found)  
  {  
    value = phrase.Semantics[key];  
  }  
  
  return found;  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.SemanticResultKey" />
        <altmember cref="T:System.Speech.Recognition.SemanticResultValue" />
        <altmember cref="T:System.Speech.Recognition.SemanticValue" />
      </Docs>
    </Member>
    <Member MemberName="Text">
      <MemberSignature Language="C#" Value="public string Text { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance string Text" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedPhrase.Text" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Text As String" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::String ^ Text { System::String ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.Text : string" Usage="System.Speech.Recognition.RecognizedPhrase.Text" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.String</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Gets the normalized text generated by a speech recognizer from recognized input.</summary>
        <value>Der normalisierte Text, der von einer Spracherkennung aus einer erkannten Eingabe generiert wurde.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Im Rahmen des Prozesses Recognition Spracherkennung führt die von der Spracherkennung Sprache-zu-Text-Normalisierung die erkannte Eingabe in einem Anzeigeformular.  
  
 Die Spracheingabe "25 Dollar", generiert z. B. ein Erkennungsergebnis, in dem die <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> Eigenschaft enthält, die Wörter "20", "5" und "Dollar", und die <xref:System.Speech.Recognition.RecognizedPhrase.Text%2A> Eigenschaft enthält den Ausdruck "25,00". Weitere Informationen zu textnormalisierung, finden Sie unter <xref:System.Speech.Recognition.ReplacementText>.  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.RecognizedPhrase.ReplacementWordUnits" />
        <altmember cref="P:System.Speech.Recognition.RecognizedPhrase.Words" />
      </Docs>
    </Member>
    <Member MemberName="Words">
      <MemberSignature Language="C#" Value="public System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.RecognizedWordUnit&gt; Words { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Collections.ObjectModel.ReadOnlyCollection`1&lt;class System.Speech.Recognition.RecognizedWordUnit&gt; Words" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedPhrase.Words" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Words As ReadOnlyCollection(Of RecognizedWordUnit)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Collections::ObjectModel::ReadOnlyCollection&lt;System::Speech::Recognition::RecognizedWordUnit ^&gt; ^ Words { System::Collections::ObjectModel::ReadOnlyCollection&lt;System::Speech::Recognition::RecognizedWordUnit ^&gt; ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.Words : System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.RecognizedWordUnit&gt;" Usage="System.Speech.Recognition.RecognizedPhrase.Words" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.RecognizedWordUnit&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Gets the words generated by a speech recognizer from recognized input.</summary>
        <value>Die Auflistung von <see cref="T:System.Speech.Recognition.RecognizedWordUnit" />-Objekten, die durch eine Spracherkennung für eine bekannte Eingabe generiert wurden.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Diese Eigenschaft enthält die Wörter, die aus der Eingabe durch die Spracherkennung vor der Erkennung Sprache-zu-Text-Normalisierung des Ergebnisses erzeugt.  
  
 Die Spracheingabe "25 Dollar", generiert z. B. ein Erkennungsergebnis, in dem die <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> Eigenschaft enthält, die Wörter "20", "5" und "Dollar", und die <xref:System.Speech.Recognition.RecognizedPhrase.Text%2A> Eigenschaft enthält den Ausdruck "25,00". Weitere Informationen zu textnormalisierung, finden Sie unter <xref:System.Speech.Recognition.ReplacementText>.  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognizedWordUnit" />
        <altmember cref="P:System.Speech.Recognition.RecognizedPhrase.ReplacementWordUnits" />
        <altmember cref="P:System.Speech.Recognition.RecognizedPhrase.Text" />
      </Docs>
    </Member>
  </Members>
</Type>