<Type Name="RecognizedPhrase" FullName="System.Speech.Recognition.RecognizedPhrase">
  <Metadata>
    <Meta Name="ms.openlocfilehash" Value="c794fbd660626f83c756861ebe64d7418019cd81" />
    <Meta Name="ms.sourcegitcommit" Value="434f60616a9793fa8436744549fc856e94f7a648" />
    <Meta Name="ms.translationtype" Value="HT" />
    <Meta Name="ms.contentlocale" Value="de-DE" />
    <Meta Name="ms.lasthandoff" Value="08/25/2018" />
    <Meta Name="ms.locfileid" Value="39866391" />
  </Metadata>
  <TypeSignature Language="C#" Value="public class RecognizedPhrase" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi serializable beforefieldinit RecognizedPhrase extends System.Object" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Recognition.RecognizedPhrase" />
  <TypeSignature Language="VB.NET" Value="Public Class RecognizedPhrase" />
  <TypeSignature Language="C++ CLI" Value="public ref class RecognizedPhrase" />
  <TypeSignature Language="F#" Value="type RecognizedPhrase = class" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>3.0.0.0</AssemblyVersion>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Object</BaseTypeName>
  </Base>
  <Interfaces />
  <Attributes>
    <Attribute FrameworkAlternate="netframework-3.0;netframework-3.5;netframework-4.0;netframework-4.5;netframework-4.5.1;netframework-4.5.2;netframework-4.6;netframework-4.6.1;netframework-4.6.2;netframework-4.7;netframework-4.7.1;netframework-4.7.2">
      <AttributeName>System.Diagnostics.DebuggerDisplay("{Text}")</AttributeName>
    </Attribute>
  </Attributes>
  <Docs>
    <summary>Enthält ausführliche Informationen, die von der Spracherkennung generiert wurden, über die erkannte Eingabe.</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Diese Klasse enthält ausführliche Informationen zu den Wörtern und Ausdrücken, die während der spracherkennungsvorgänge, einschließlich der folgenden verarbeitet:  
  
-   Die <xref:System.Speech.Recognition.RecognizedPhrase.Grammar%2A> Eigenschaftenverweise der <xref:System.Speech.Recognition.Grammar> , dass die Erkennung verwendet wird, um die Eingabe zu identifizieren.  
  
-   Die <xref:System.Speech.Recognition.RecognizedPhrase.Text%2A> Eigenschaft enthält den normalisierten Text für den Ausdruck.  
  
-   Die <xref:System.Speech.Recognition.RecognizedPhrase.Semantics%2A> -Eigenschaft verweist auf die semantischen Informationen, die im Resultset enthalten sind. Die semantische Informationen ist ein Wörterbuch mit den Schlüsselnamen und den zugehörigen semantische Daten.  
  
-   Die <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> Eigenschaft enthält eine geordnete Auflistung von <xref:System.Speech.Recognition.RecognizedWordUnit> jedes darstellende – Objekte erkannt Wort in der Eingabe. Jede Einheit Word enthält Anzeigeformat, lexikalische Format und Aussprache Informationen für das entsprechende Wort.  
  
-   Die <xref:System.Speech.Recognition.RecognizedPhrase.ReplacementWordUnits%2A> Eigenschaft enthält Informationen zu Ersetzung für spezielle Word.  
  
-   Die <xref:System.Speech.Recognition.RecognizedPhrase.Homophones%2A> und <xref:System.Speech.Recognition.RecognizedPhrase.HomophoneGroupId%2A> Eigenschaften enthalten Informationen über Erkennungsalternativen, die gleiche oder ähnliche Aussprache verfügen.  
  
-   Der Wert des der <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> Eigenschaft gibt das Maß an Sicherheit, von der Spracherkennung, zugewiesen, dass es sich bei der Eingabe ein erkannten Ausdrucks entspricht, an.  
  
 Die Spracherkennung gibt Ergebnisse in einem <xref:System.Speech.Recognition.RecognitionResult> -Objekt, das erbt <xref:System.Speech.Recognition.RecognizedPhrase>. Das Erkennungsergebnis <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> Eigenschaft enthält eine geordnete Auflistung von <xref:System.Speech.Recognition.RecognizedPhrase> -Objekte, von denen jede eine mögliche Entsprechung für die Eingabe für die Erkennung.  
  
   
  
## Examples  
 Das folgende Beispiel zeigt einen Handler für eine <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized?displayProperty=nameWithType>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized?displayProperty=nameWithType>, oder <xref:System.Speech.Recognition.Grammar.SpeechRecognized?displayProperty=nameWithType> Ereignis- und einige der zugeordneten Informationen der <xref:System.Speech.Recognition.RecognitionResult> Objekt. Die <xref:System.Speech.Recognition.RecognitionResult>-Klasse wird aus der <xref:System.Speech.Recognition.RecognizedPhrase>-Klasse abgeleitet.  
  
```csharp  
void SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  
{  
  if (e.Result == null) return;  
  
  // Add event handler code here.  
  
  // The following code illustrates some of the information available  
  // in the recognition result.  
  Console.WriteLine("Recognition result summary:");  
  Console.WriteLine(  
    "  Recognized phrase: {0}\n" +   
    "  Confidence score {1}\n" +   
    "  Grammar used: {2}\n",   
    e.Result.Text, e.Result.Confidence, e.Result.Grammar.Name);  
  
  // Display the semantic values in the recognition result.  
  Console.WriteLine("  Semantic results:");  
  foreach (KeyValuePair<String, SemanticValue> child in e.Result.Semantics)  
  {  
    Console.WriteLine("    The {0} city is {1}",  
      child.Key, child.Value.Value ?? "null");  
  }  
  Console.WriteLine();  
  
  // Display information about the words in the recognition result.  
  Console.WriteLine("  Word summary: ");  
  foreach (RecognizedWordUnit word in e.Result.Words)  
  {  
    Console.WriteLine(  
      "    Lexical form ({1})" +  
      " Pronunciation ({0})" +  
      " Display form ({2})",  
      word.Pronunciation, word.LexicalForm, word.DisplayAttributes);  
  }  
  
  // Display information about the audio in the recognition result.  
  Console.WriteLine("  Input audio summary:\n" +  
    "    Candidate Phrase at:       {0} mSec\n" +  
    "    Phrase Length:             {1} mSec\n" +  
    "    Input State Time:          {2}\n" +  
    "    Input Format:              {3}\n",  
    e.Result.Audio.AudioPosition,  
    e.Result.Audio.Duration,  
    e.Result.Audio.StartTime,  
    e.Result.Audio.Format.EncodingFormat);  
  
  // Display information about the alternate recognitions in the recognition result.  
  Console.WriteLine("  Alternate phrase collection:");  
  foreach (RecognizedPhrase phrase in e.Result.Alternates)  
  {  
    Console.WriteLine("    Phrase: " + phrase.Text);  
    Console.WriteLine("    Confidence score: " + phrase.Confidence);  
  }  
}  
```  
  
 ]]></format>
    </remarks>
    <altmember cref="T:System.Speech.Recognition.RecognitionResult" />
    <altmember cref="T:System.Speech.Recognition.RecognizedWordUnit" />
  </Docs>
  <Members>
    <Member MemberName="Confidence">
      <MemberSignature Language="C#" Value="public float Confidence { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance float32 Confidence" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedPhrase.Confidence" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Confidence As Single" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property float Confidence { float get(); };" />
      <MemberSignature Language="F#" Value="member this.Confidence : single" Usage="System.Speech.Recognition.RecognizedPhrase.Confidence" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>get: System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Single</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Ruft einen durch die Erkennung zugewiesenen Wert ab, der die Wahrscheinlichkeit angibt, dass ein <see cref="T:System.Speech.Recognition.RecognizedPhrase" />-Objekt mit einer angegebenen Eingabe übereinstimmt.</summary>
        <value>Eine relative Maßnahme der Sicherheit der richtigen Erkennung eines Ausdrucks. Der Wert liegt zwischen 0,0 und 1,0 (geringes bis hohes Vertrauen).</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Vertrauensergebnisse nicht die absolute Wahrscheinlichkeit an, dass ein Ausdruck ordnungsgemäß erkannt wurde. Vertrauensergebnisse wird stattdessen einen Mechanismus zum Vergleichen der relativen Genauigkeit von mehreren Erkennungsalternativen für eine angegebene Eingabe bereitstellen. Dies erleichtert die genaueste Erkennungsergebnis zurückgeben. Beispielsweise verfügt ein erkannten Ausdrucks ein vertrauensergebnis 0,8, bedeutet dies nicht, dass der Ausdruck eine 80 % Wahrscheinlichkeit der ordnungsgemäße Übereinstimmung für die Eingabe ist.  Dies bedeutet, dass der Ausdruck höherer Wahrscheinlichkeit, dass die ordnungsgemäße Übereinstimmung für die Eingabe als andere Ergebnisse, die darauf vertrauen, die kleiner als 0,8 bewertet.  
  
 Ein vertrauensergebnis allein ist nicht sinnvoll, es sei denn, Sie alternative Ergebnisse, berücksichtigt werden sollen, entweder über den gleichen Erkennungsvorgang oder über vorherige Erkennungsvorgänge von derselben Eingabe verglichen werden soll. Die Werte werden verwendet, um alternative möglichen Sätze von zurückgegebenen Rangfolge der <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> Eigenschaft <xref:System.Speech.Recognition.RecognitionResult> Objekte.  
  
 Konfidenzwerte werden jede erkennungs-Engine relative und eindeutig sind. Von zwei verschiedenen Erkennungsmodule zurückgegebenen konfidenzwerte können nicht Klassenmemberfunktionen verglichen werden.  
  
 Eine spracherkennungs-Engine kann gesprochener Eingabe ein niedriges vertrauensergebnis aus unterschiedlichen Gründen, z. B. Hintergrund Störungen, inarticulate-Sprache, oder unvorhergesehene Wörter oder wortsequenzen zuweisen. Wenn Ihre Anwendung verwendet eine <xref:System.Speech.Recognition.SpeechRecognitionEngine> Instanz können Sie ändern, den Vertrauensgrad, auf welche Sprache Eingabe akzeptiert oder abgelehnt, die mit einem, der <xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A> Methoden. Vertrauen Schwellenwerte für die freigegebene Erkennung, die von verwalteten <xref:System.Speech.Recognition.SpeechRecognizer>, ein Benutzerprofil zugeordnet und in der Windows-Registrierung gespeichert sind. Anwendungen sollten Änderungen an der Registrierung für die Eigenschaften der freigegebenen Erkennung nicht geschrieben werden.  
  
 Die <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> Eigenschaft der <xref:System.Speech.Recognition.RecognitionResult> Objekt enthält eine geordnete Auflistung von <xref:System.Speech.Recognition.RecognizedPhrase> -Objekte, von denen jede eine mögliche Entsprechung für die Eingabe für die Erkennung. Die Varianten werden vom höchsten zum niedrigsten KONFIDENZ sortiert.  
  
   
  
## Examples  
 Das folgende Beispiel zeigt einen Handler für eine <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized?displayProperty=nameWithType>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized?displayProperty=nameWithType>, oder <xref:System.Speech.Recognition.Grammar.SpeechRecognized?displayProperty=nameWithType> Ereignis. Das Beispiel zeigt Informationen im Zusammenhang mit der <xref:System.Speech.Recognition.RecognitionResult> Objekt, von denen einige ergibt sich aus <xref:System.Speech.Recognition.RecognizedPhrase>. Der Ereignishandler zeigt vertrauensergebnisse für eines erkannten Ausdrucks sowie für Erkennungsalternativen an.  
  
```csharp  
void SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  
{  
  if (e.Result == null) return;  
  
  // Add event handler code here.  
  
  // The following code illustrates some of the information available  
  // in the recognition result.  
  Console.WriteLine("Recognition result summary:");  
  Console.WriteLine(  
    "  Recognized phrase: {0}\n" +   
    "  Confidence score {1}\n" +   
    "  Grammar used: {2}\n",   
    e.Result.Text, e.Result.Confidence, e.Result.Grammar.Name);  
  
  // Display the semantic values in the recognition result.  
  Console.WriteLine("  Semantic results:");  
  foreach (KeyValuePair<String, SemanticValue> child in e.Result.Semantics)  
  {  
    Console.WriteLine("    The {0} city is {1}",  
      child.Key, child.Value.Value ?? "null");  
  }  
  Console.WriteLine();  
  
  // Display information about the words in the recognition result.  
  Console.WriteLine("  Word summary: ");  
  foreach (RecognizedWordUnit word in e.Result.Words)  
  {  
    Console.WriteLine(  
      "    Lexical form ({1})" +  
      " Pronunciation ({0})" +  
      " Display form ({2})",  
      word.Pronunciation, word.LexicalForm, word.DisplayAttributes);  
  }  
  
  // Display information about the audio in the recognition result.  
  Console.WriteLine("  Input audio summary:\n" +  
    "    Candidate Phrase at:       {0} mSec\n" +  
    "    Phrase Length:             {1} mSec\n" +  
    "    Input State Time:          {2}\n" +  
    "    Input Format:              {3}\n",  
    e.Result.Audio.AudioPosition,  
    e.Result.Audio.Duration,  
    e.Result.Audio.StartTime,  
    e.Result.Audio.Format.EncodingFormat);  
  
  // Display information about the alternate recognitions in the recognition result.  
  Console.WriteLine("  Alternate phrase collection:");  
  foreach (RecognizedPhrase phrase in e.Result.Alternates)  
  {  
    Console.WriteLine("    Phrase: " + phrase.Text);  
    Console.WriteLine("    Confidence score: " + phrase.Confidence);  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognitionResult" />
        <altmember cref="P:System.Speech.Recognition.RecognitionResult.Alternates" />
        <altmember cref="T:System.Speech.Recognition.SpeechRecognitionEngine" />
        <altmember cref="T:System.Speech.Recognition.SpeechRecognizer" />
      </Docs>
    </Member>
    <Member MemberName="ConstructSmlFromSemantics">
      <MemberSignature Language="C#" Value="public System.Xml.XPath.IXPathNavigable ConstructSmlFromSemantics ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Xml.XPath.IXPathNavigable ConstructSmlFromSemantics() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.RecognizedPhrase.ConstructSmlFromSemantics" />
      <MemberSignature Language="VB.NET" Value="Public Function ConstructSmlFromSemantics () As IXPathNavigable" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; System::Xml::XPath::IXPathNavigable ^ ConstructSmlFromSemantics();" />
      <MemberSignature Language="F#" Value="member this.ConstructSmlFromSemantics : unit -&gt; System.Xml.XPath.IXPathNavigable" Usage="recognizedPhrase.ConstructSmlFromSemantics " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Xml.XPath.IXPathNavigable</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Gibt ein semantisches Markupsprachen-Dokument (SML )zu der semantischen Informationen im <see cref="T:System.Speech.Recognition.RecognizedPhrase" />-Objekt zurück.</summary>
        <returns>Gibt eine SML-Beschreibung der Semantik des <see cref="T:System.Speech.Recognition.RecognizedPhrase" /> als ein Objekt zurück, in dem in [XPath](http://msdn.microsoft.com/library/ms256115.aspx) navigiert werden kann.</returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Weitere Informationen zu den semantic Markup Language (SML), finden Sie unter den [Semantic Markup Language Reference](http://msdn.microsoft.com/library/f9d83443-2cac-49bc-a447-210feda62f5d).  
  
   
  
## Examples  
 Im folgenden Beispiel gibt eine Methode eine Zeichenfolge, die SML für die Semantik eines erkannten Ausdrucks enthält, zurück.  
  
```  
private string GetSemanticsSML(RecognizedPhrase result)  
{  
  if (result.Semantics.Count > 0)  
  {  
    return result.ConstructSmlFromSemantics().CreateNavigator().OuterXml;  
  }  
  else  
  {  
    return null;  
  }  
}  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="Grammar">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.Grammar Grammar { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Speech.Recognition.Grammar Grammar" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedPhrase.Grammar" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Grammar As Grammar" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::Recognition::Grammar ^ Grammar { System::Speech::Recognition::Grammar ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.Grammar : System.Speech.Recognition.Grammar" Usage="System.Speech.Recognition.RecognizedPhrase.Grammar" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.Grammar</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Ruft die <see cref="T:System.Speech.Recognition.Grammar" /> ab, die von der Spracherkennung zum Zurückgeben der <see cref="T:System.Speech.Recognition.RecognizedPhrase" /> verwendet wurde.</summary>
        <value>Das Grammatikobjekt, das die Spracherkennung verwendet, um die Eingabe zu identifizieren.</value>
        <remarks>To be added.</remarks>
        <altmember cref="T:System.Speech.Recognition.Grammar" />
        <altmember cref="T:System.Speech.Recognition.RecognitionResult" />
        <altmember cref="T:System.Speech.Recognition.SpeechRecognitionEngine" />
        <altmember cref="T:System.Speech.Recognition.SpeechRecognizer" />
      </Docs>
    </Member>
    <Member MemberName="HomophoneGroupId">
      <MemberSignature Language="C#" Value="public int HomophoneGroupId { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance int32 HomophoneGroupId" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedPhrase.HomophoneGroupId" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property HomophoneGroupId As Integer" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property int HomophoneGroupId { int get(); };" />
      <MemberSignature Language="F#" Value="member this.HomophoneGroupId : int" Usage="System.Speech.Recognition.RecognizedPhrase.HomophoneGroupId" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>get: System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Int32</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Ruft den Bezeichner für die Homophongruppe für den Ausdruck ab.</summary>
        <value>Der Bezeichner für die Homophongruppe für den Ausdruck.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Die freigegebene Spracherkennung. alle Erkennungsalternativen, die dieselbe Aussprache verfügen eine Gruppen-ID zugewiesen. Für jede alternative, die über eine eindeutige Aussprache verfügt, wird die Erkennung einer homophongruppe erstellt. Die Spracherkennung generiert neue Gruppe von Bezeichnern für jeden Erkennungsvorgang, und die Bezeichner können nicht verwendet werden, um Varianten von vergleichen, die aus separaten Erkennungsvorgänge generiert.  
  
 Z. B. für ein Erkennungsergebnis, die den alternativen "Geschichte", "Tail" und "die Ale" enthalten, die ersten beiden alternativen würde zu einer homophongruppe gehören, und die letzte Alternative wäre das einzelne Mitglied einer zweiten homophongruppe.  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.RecognitionResult.Alternates" />
        <altmember cref="P:System.Speech.Recognition.RecognizedPhrase.Homophones" />
      </Docs>
    </Member>
    <Member MemberName="Homophones">
      <MemberSignature Language="C#" Value="public System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.RecognizedPhrase&gt; Homophones { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Collections.ObjectModel.ReadOnlyCollection`1&lt;class System.Speech.Recognition.RecognizedPhrase&gt; Homophones" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedPhrase.Homophones" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Homophones As ReadOnlyCollection(Of RecognizedPhrase)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Collections::ObjectModel::ReadOnlyCollection&lt;System::Speech::Recognition::RecognizedPhrase ^&gt; ^ Homophones { System::Collections::ObjectModel::ReadOnlyCollection&lt;System::Speech::Recognition::RecognizedPhrase ^&gt; ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.Homophones : System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.RecognizedPhrase&gt;" Usage="System.Speech.Recognition.RecognizedPhrase.Homophones" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.RecognizedPhrase&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Ruft eine Auflistung von Erkennungsalternativen ab, die über dieselbe Aussprache verfügen wie dieser erkannte Ausdruck.</summary>
        <value>Eine schreibgeschützte Auflistung von Erkennungsalternativen, die über dieselbe Aussprache verfügen wie dieser erkannte Ausdruck.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Diese Eigenschaft gibt alle anderen Erkennungsalternativen, die die über dieselbe Aussprache wie dieser erkannte Ausdruck verfügen.  
  
 Beispielsweise würde die Homophonen-Auflistung, für die erste Alternative, "Geschichte" für ein Erkennungsergebnis, die der alternativen, "Geschichte" und "Tail" enthalten, den zweite Ausdruck, "Tail" enthalten. Die Auflistung Homophonen für die zweite Alternative, "Tail", würde den erste Ausdruck, "Geschichte" enthalten.  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.RecognitionResult.Alternates" />
        <altmember cref="P:System.Speech.Recognition.RecognizedPhrase.HomophoneGroupId" />
      </Docs>
    </Member>
    <Member MemberName="ReplacementWordUnits">
      <MemberSignature Language="C#" Value="public System.Collections.ObjectModel.Collection&lt;System.Speech.Recognition.ReplacementText&gt; ReplacementWordUnits { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Collections.ObjectModel.Collection`1&lt;class System.Speech.Recognition.ReplacementText&gt; ReplacementWordUnits" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedPhrase.ReplacementWordUnits" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property ReplacementWordUnits As Collection(Of ReplacementText)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Collections::ObjectModel::Collection&lt;System::Speech::Recognition::ReplacementText ^&gt; ^ ReplacementWordUnits { System::Collections::ObjectModel::Collection&lt;System::Speech::Recognition::ReplacementText ^&gt; ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.ReplacementWordUnits : System.Collections.ObjectModel.Collection&lt;System.Speech.Recognition.ReplacementText&gt;" Usage="System.Speech.Recognition.RecognizedPhrase.ReplacementWordUnits" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Collections.ObjectModel.Collection&lt;System.Speech.Recognition.ReplacementText&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Ruft Informationen zu dem Text ab, der von der Spracherkennung als Teil der Sprache-zu-Text-Normalisierung geändert wurde.</summary>
        <value>Eine Auflistung der <see cref="T:System.Speech.Recognition.ReplacementText" />-Objekte, die Textabschnitte beschreiben, die die Spracherkennung ersetzt hat, als sie die erkannte Eingabe normalisierte.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Im Rahmen der Speech Recognition normalisiert die Spracherkennung die erkannte Eingabe in ein Formular zum Anzeigen.  
  
 Die gesprochene Eingabe "25 Dollar" generiert z. B. eine Erkennungsergebnis, in denen die <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> Eigenschaft enthält, die Wörter, "20", "fünf" und "Dollar", und die <xref:System.Speech.Recognition.RecognizedPhrase.Text%2A> Eigenschaft enthält die Spalte "25,00". Weitere Informationen zum Text-Normalisierung, finden Sie unter den <xref:System.Speech.Recognition.ReplacementText> Klasse.  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognizedWordUnit" />
        <altmember cref="T:System.Speech.Recognition.ReplacementText" />
        <altmember cref="P:System.Speech.Recognition.RecognizedPhrase.Text" />
        <altmember cref="P:System.Speech.Recognition.RecognizedPhrase.Words" />
      </Docs>
    </Member>
    <Member MemberName="Semantics">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.SemanticValue Semantics { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Speech.Recognition.SemanticValue Semantics" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedPhrase.Semantics" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Semantics As SemanticValue" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::Recognition::SemanticValue ^ Semantics { System::Speech::Recognition::SemanticValue ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.Semantics : System.Speech.Recognition.SemanticValue" Usage="System.Speech.Recognition.RecognizedPhrase.Semantics" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.SemanticValue</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Ruft die semantischen Informationen ab, die dem erkannten Ausdruck zugeordnet sind.</summary>
        <value>Die semantischen Informationen, die dem erkannten Ausdruck zugeordnet sind.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Eine spracherkennungsgrammatik kann es sich um semantische Informationen enthalten. Wenn eine Spracherkennung die Erkennung einer Erkennungsergebnis für eine solche Grammatik generiert, kann die semantische Informationen in das Erkennungsergebnis gemäß den Regeln der Grammatik und die Eingabe für die Erkennung von enthalten sein. Weitere Informationen zu semantischen Informationen, finden Sie unter [semantische Grundlegendes zu den Ergebnissen](http://msdn.microsoft.com/library/2a9dbd8b-cf6d-42cd-bbb9-ca0b3e534005) und <xref:System.Speech.Recognition.SemanticResultKey> und <xref:System.Speech.Recognition.SemanticResultValue> Klassen.  
  
   
  
## Examples  
 Das folgende Beispiel definiert eine Methode, die bestimmte semantischen Informationen aus eines erkannten Ausdrucks abruft. Bei der Rückgabe dieser Methode enthält den Wert für die semantische Schlüssel oder Null, wenn der Wert nicht abgerufen wurde. Diese Methode überprüft nur für den Schlüssel der obersten Ebene. Da die semantische Informationen in einer Struktur von Werten enthalten ist, müssen die Low-Level-Schlüssel über den zurückgegebenen semantischen Wert zugegriffen werden.  
  
```  
static bool TryGetSemanticValue(  
      RecognizedPhrase phrase, string key, out SemanticValue value)  
{  
  value = null;  
  bool found = phrase.Semantics.ContainsKey(key);  
  if (found)  
  {  
    value = phrase.Semantics[key];  
  }  
  
  return found;  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.SemanticResultKey" />
        <altmember cref="T:System.Speech.Recognition.SemanticResultValue" />
        <altmember cref="T:System.Speech.Recognition.SemanticValue" />
      </Docs>
    </Member>
    <Member MemberName="Text">
      <MemberSignature Language="C#" Value="public string Text { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance string Text" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedPhrase.Text" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Text As String" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::String ^ Text { System::String ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.Text : string" Usage="System.Speech.Recognition.RecognizedPhrase.Text" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.String</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Ruft den normalisierten Text ab, der von einer Spracherkennung aus einer erkannten Eingabe generiert wurde.</summary>
        <value>Der normalisierte Text, der von einer Spracherkennung aus einer erkannten Eingabe generiert wurde.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Als Teil der Speech Recognition-Prozess führt die Spracherkennung Sprache-zu-Text-Normalisierung, der die erkannte Eingabe in ein Formular zum Anzeigen.  
  
 Die gesprochene Eingabe "25 Dollar" generiert z. B. eine Erkennungsergebnis, in denen die <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> Eigenschaft enthält, die Wörter, "20", "fünf" und "Dollar", und die <xref:System.Speech.Recognition.RecognizedPhrase.Text%2A> Eigenschaft enthält die Spalte "25,00". Weitere Informationen zum Text-Normalisierung, finden Sie unter <xref:System.Speech.Recognition.ReplacementText>.  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.RecognizedPhrase.ReplacementWordUnits" />
        <altmember cref="P:System.Speech.Recognition.RecognizedPhrase.Words" />
      </Docs>
    </Member>
    <Member MemberName="Words">
      <MemberSignature Language="C#" Value="public System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.RecognizedWordUnit&gt; Words { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Collections.ObjectModel.ReadOnlyCollection`1&lt;class System.Speech.Recognition.RecognizedWordUnit&gt; Words" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedPhrase.Words" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Words As ReadOnlyCollection(Of RecognizedWordUnit)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Collections::ObjectModel::ReadOnlyCollection&lt;System::Speech::Recognition::RecognizedWordUnit ^&gt; ^ Words { System::Collections::ObjectModel::ReadOnlyCollection&lt;System::Speech::Recognition::RecognizedWordUnit ^&gt; ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.Words : System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.RecognizedWordUnit&gt;" Usage="System.Speech.Recognition.RecognizedPhrase.Words" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.RecognizedWordUnit&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Ruft die Wörter ab, die von einer Spracherkennung aus einer gültigen Eingabe generiert wurden.</summary>
        <value>Die Auflistung von <see cref="T:System.Speech.Recognition.RecognizedWordUnit" />-Objekten, die durch eine Spracherkennung für eine bekannte Eingabe generiert wurden.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Diese Eigenschaft enthält, die Wörter, die aus der Eingabe von der Spracherkennung vor der Erkennung Sprache-zu-Text-Normalisierung der das Ergebnis erzeugt wird.  
  
 Die gesprochene Eingabe "25 Dollar" generiert z. B. eine Erkennungsergebnis, in denen die <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> Eigenschaft enthält, die Wörter, "20", "fünf" und "Dollar", und die <xref:System.Speech.Recognition.RecognizedPhrase.Text%2A> Eigenschaft enthält die Spalte "25,00". Weitere Informationen zum Text-Normalisierung, finden Sie unter <xref:System.Speech.Recognition.ReplacementText>.  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognizedWordUnit" />
        <altmember cref="P:System.Speech.Recognition.RecognizedPhrase.ReplacementWordUnits" />
        <altmember cref="P:System.Speech.Recognition.RecognizedPhrase.Text" />
      </Docs>
    </Member>
  </Members>
</Type>