<Type Name="RecognizerState" FullName="System.Speech.Recognition.RecognizerState">
  <Metadata><Meta Name="ms.openlocfilehash" Value="901f51ceee11aec67ab120a0d0df3dca0820be4d" /><Meta Name="ms.sourcegitcommit" Value="397961a0164281b579f68064c3bb66c071f374d9" /><Meta Name="ms.translationtype" Value="MT" /><Meta Name="ms.contentlocale" Value="de-DE" /><Meta Name="ms.lasthandoff" Value="07/14/2020" /><Meta Name="ms.locfileid" Value="69101021" /></Metadata><TypeSignature Language="C#" Value="public enum RecognizerState" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi sealed RecognizerState extends System.Enum" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Recognition.RecognizerState" />
  <TypeSignature Language="VB.NET" Value="Public Enum RecognizerState" />
  <TypeSignature Language="C++ CLI" Value="public enum class RecognizerState" />
  <TypeSignature Language="F#" Value="type RecognizerState = " />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>3.0.0.0</AssemblyVersion>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Enum</BaseTypeName>
  </Base>
  <Docs>
    <summary>Listet Werte des Zustands der Erkennung auf.</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <xref:System.Speech.Recognition.RecognizerState>kapselt den Lauf Status der Standard Spracherkennungs-Engine für Clients, die für <xref:System.Speech.Recognition.SpeechRecognizer> den Zugriff auf den Windows Desktop Speech Recognition Technology-Dienst verwenden.  
  
 Anwendungen können den aktuellen Status der Desktop Erkennungs-Engine als-Objekt abrufen, <xref:System.Speech.Recognition.RecognizerState> indem Sie die- <xref:System.Speech.Recognition.SpeechRecognizer.State%2A> Eigenschaft einer-Instanz Abfragen <xref:System.Speech.Recognition.SpeechRecognizer> .  Zum Abrufen des Status der Desktop Erkennungs-Engine nach der Änderung können Anwendungen die- <xref:System.Speech.Recognition.StateChangedEventArgs.RecognizerState%2A> Eigenschaft des Objekts Abfragen, das <xref:System.Speech.Recognition.StateChangedEventArgs> an einen Handler für Ereignisse übermittelt wird <xref:System.Speech.Recognition.SpeechRecognizer.StateChanged> .  
  
> [!NOTE]
>  <xref:System.Speech.Recognition.SpeechRecognitionEngine>Instanzen werden innerhalb des Prozesses ausgeführt, und Ihr Status wird unter der Steuerung der Anwendung ausgeführt. Daher <xref:System.Speech.Recognition.SpeechRecognitionEngine> enthält keine-Eigenschaft, um ein-Objekt zurückzugeben <xref:System.Speech.Recognition.RecognizerState> .  
  
 Der Status eines Desktop sprach Erkennungs Servers ist eine schreibgeschützte Eigenschaft und kann nicht Programm gesteuert gesteuert werden. Benutzer können den Zustand der freigegebenen Spracherkennung mithilfe der sprach Erkennungs-Benutzeroberfläche oder über das **sprach Erkennungs** Element der Windows- **Systemsteuerung**ändern.  
  
 Die Einstellungen **on** und **Sleep** in der sprach Erkennungs Benutzeroberfläche entsprechen dem `Listening` Status. Die Einstellung **aus** in der Benutzeroberfläche für die Spracherkennung entspricht "beendet".  
  
 <xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A>die andere Eigenschaft, die sich auf die Bereitschaft einer freigegebenen Spracherkennungs-Engine auswirkt, Spracheingaben zu empfangen und zu verarbeiten. Sie können verwenden <xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A> , um zu steuern, ob die Grammatiken eines freigegebenen sprach Erkennungs Moduls für die Erkennung aktiv sind oder nicht. Das Ändern der <xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A> Eigenschaft wirkt sich jedoch nicht auf die <xref:System.Speech.Recognition.RecognizerState> Eigenschaft aus.  
  
 Informationen wie z. b. die Beschreibung, die unterstützte Kultur und Audioformate und der Name der Erkennungs-Engine werden im-Typ gekapselt <xref:System.Speech.Recognition.RecognizerInfo> .  
  
   
  
## Examples  
 Im folgenden Beispiel zeigt eine Anwendung den Status einer Erkennung in der Implementierung eines Handlers für das <xref:System.Speech.Recognition.SpeechRecognizer.StateChanged> Ereignis an.  
  
```  
  
_recognizer.StateChanged +=  
    delegate(object sender, StateChangedEventArgs eventArgs) {  
        _recognizerStateLabel.Text = "Speech Recognizer State: " + eventArgs.RecognizerState.ToString();  
    };  
  
```  
  
 ]]></format>
    </remarks>
    <altmember cref="P:System.Speech.Recognition.StateChangedEventArgs.RecognizerState" />
    <altmember cref="T:System.Speech.Recognition.SpeechRecognizer" />
    <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.Enabled" />
    <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.State" />
    <altmember cref="T:System.Speech.Recognition.StateChangedEventArgs" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.StateChanged" />
  </Docs>
  <Members>
    <Member MemberName="Listening">
      <MemberSignature Language="C#" Value="Listening" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype System.Speech.Recognition.RecognizerState Listening = int32(1)" />
      <MemberSignature Language="DocId" Value="F:System.Speech.Recognition.RecognizerState.Listening" />
      <MemberSignature Language="VB.NET" Value="Listening" />
      <MemberSignature Language="C++ CLI" Value="Listening" />
      <MemberSignature Language="F#" Value="Listening = 1" Usage="System.Speech.Recognition.RecognizerState.Listening" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognizerState</ReturnType>
      </ReturnValue>
      <MemberValue>1</MemberValue>
      <Docs>
        <summary>Die Erkennungs-Engine ist verfügbar, um Audioeingaben zu empfangen und zu analysieren.</summary>
      </Docs>
    </Member>
    <Member MemberName="Stopped">
      <MemberSignature Language="C#" Value="Stopped" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype System.Speech.Recognition.RecognizerState Stopped = int32(0)" />
      <MemberSignature Language="DocId" Value="F:System.Speech.Recognition.RecognizerState.Stopped" />
      <MemberSignature Language="VB.NET" Value="Stopped" />
      <MemberSignature Language="C++ CLI" Value="Stopped" />
      <MemberSignature Language="F#" Value="Stopped = 0" Usage="System.Speech.Recognition.RecognizerState.Stopped" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognizerState</ReturnType>
      </ReturnValue>
      <MemberValue>0</MemberValue>
      <Docs>
        <summary>Die Erkennungs-Engine empfängt oder analysiert keine Audioeingabe.</summary>
      </Docs>
    </Member>
  </Members>
</Type>
