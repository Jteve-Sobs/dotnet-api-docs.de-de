<Type Name="RecognitionResult" FullName="System.Speech.Recognition.RecognitionResult">
  <Metadata>
    <Meta Name="ms.openlocfilehash" Value="65b6c7b5ff0bb1cf40dbb5784aedfc69d84e0a2e" />
    <Meta Name="ms.sourcegitcommit" Value="c0c07dbd19cd7017243f9ac36915755f79bc8da6" />
    <Meta Name="ms.translationtype" Value="HT" />
    <Meta Name="ms.contentlocale" Value="de-DE" />
    <Meta Name="ms.lasthandoff" Value="11/27/2018" />
    <Meta Name="ms.locfileid" Value="52346432" />
  </Metadata>
  <TypeSignature Language="C#" Value="public sealed class RecognitionResult : System.Speech.Recognition.RecognizedPhrase, System.Runtime.Serialization.ISerializable" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi serializable sealed beforefieldinit RecognitionResult extends System.Speech.Recognition.RecognizedPhrase implements class System.Runtime.Serialization.ISerializable" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Recognition.RecognitionResult" />
  <TypeSignature Language="VB.NET" Value="Public NotInheritable Class RecognitionResult&#xA;Inherits RecognizedPhrase&#xA;Implements ISerializable" />
  <TypeSignature Language="C++ CLI" Value="public ref class RecognitionResult sealed : System::Speech::Recognition::RecognizedPhrase, System::Runtime::Serialization::ISerializable" />
  <TypeSignature Language="F#" Value="type RecognitionResult = class&#xA;    inherit RecognizedPhrase&#xA;    interface ISerializable" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>3.0.0.0</AssemblyVersion>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Speech.Recognition.RecognizedPhrase</BaseTypeName>
  </Base>
  <Interfaces>
    <Interface>
      <InterfaceName>System.Runtime.Serialization.ISerializable</InterfaceName>
    </Interface>
  </Interfaces>
  <Attributes>
    <Attribute FrameworkAlternate="netframework-3.0;netframework-3.5;netframework-4.0;netframework-4.5;netframework-4.5.1;netframework-4.5.2;netframework-4.6;netframework-4.6.1;netframework-4.6.2;netframework-4.7;netframework-4.7.1;netframework-4.7.2;netframework-4.8">
      <AttributeName>System.Diagnostics.DebuggerDisplay("{DebuggerDisplayString ()}")</AttributeName>
    </Attribute>
    <Attribute FrameworkAlternate="netframework-3.0;netframework-3.5;netframework-4.0;netframework-4.5;netframework-4.5.1;netframework-4.5.2;netframework-4.6;netframework-4.6.1;netframework-4.6.2;netframework-4.7;netframework-4.7.1;netframework-4.7.2;netframework-4.8">
      <AttributeName>System.Serializable</AttributeName>
    </Attribute>
  </Attributes>
  <Docs>
    <summary>Enthält ausführliche Informationen zur Eingabe, die von Instanzen der <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> oder <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> erkannt wurde.</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Diese Klasse wird von <xref:System.Speech.Recognition.RecognizedPhrase> und ausführliche Informationen zur Spracherkennung, einschließlich der folgenden:  
  
-   Die <xref:System.Speech.Recognition.RecognizedPhrase.Grammar%2A> Eigenschaftenverweise der <xref:System.Speech.Recognition.Grammar> , dass die Erkennung verwendet, um die Spracherkennung zu identifizieren.  
  
-   Die <xref:System.Speech.Recognition.RecognizedPhrase.Text%2A> Eigenschaft enthält den normalisierten Text für den Ausdruck. Weitere Informationen zum Text-Normalisierung, finden Sie unter <xref:System.Speech.Recognition.ReplacementText>.  
  
-   Die <xref:System.Speech.Recognition.RecognizedPhrase.Semantics%2A> -Eigenschaft verweist auf die semantischen Informationen, die im Resultset enthalten sind. Die semantische Informationen ist ein Wörterbuch mit den Schlüsselnamen und den zugehörigen semantische Daten.  
  
-   Die <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> Eigenschaft enthält eine Auflistung von <xref:System.Speech.Recognition.RecognizedPhrase> anderer Kandidat Interpretationen der Audioeingabe darstellende – Objekte. Weitere Informationen finden Sie unter <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>.  
  
-   Die <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> Eigenschaft enthält eine geordnete Auflistung von <xref:System.Speech.Recognition.RecognizedWordUnit> jedes darstellende – Objekte erkannt Wort in der Eingabe. Jede <xref:System.Speech.Recognition.RecognizedWordUnit> Anzeigeformat, lexikalische Format und Aussprache, zu dem entsprechenden Wort enthält.  
  
 Bestimmte Elemente der <xref:System.Speech.Recognition.SpeechRecognitionEngine>, <xref:System.Speech.Recognition.SpeechRecognizer>, und <xref:System.Speech.Recognition.Grammar> Klassen generieren können eine <xref:System.Speech.Recognition.RecognitionResult>. Weitere Informationen finden Sie in der folgenden Methoden und Ereignisse.  
  
-   Methoden und Ereignisse von den <xref:System.Speech.Recognition.SpeechRecognitionEngine> Klasse:  
  
    -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A>  
  
    -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A>  
  
    -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>  
  
    -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>  
  
    -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>  
  
-   Methoden und Ereignisse von den <xref:System.Speech.Recognition.SpeechRecognizer> Klasse:  
  
    -   <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A>  
  
    -   <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>  
  
    -   <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>  
  
    -   <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>  
  
    -   <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>  
  
-   Die <xref:System.Speech.Recognition.Grammar.SpeechRecognized> Ereignis die <xref:System.Speech.Recognition.Grammar> Klasse.  
  
 Weitere Informationen über spracherkennungsereignisse finden Sie unter [mit Speech Recognition Ereignissen](https://msdn.microsoft.com/library/01c598ca-2e0e-4e89-b303-cd1cef9e8482).  
  
   
  
## Examples  
 Das folgende Beispiel zeigt einen Handler für die `SpeechRecognized` Ereignis eine <xref:System.Speech.Recognition.SpeechRecognitionEngine> oder <xref:System.Speech.Recognition.SpeechRecognizer> -Objekt, und einige der Informationen über die zugeordnete <xref:System.Speech.Recognition.RecognitionResult>.  
  
```csharp  
  
// Handle the SpeechRecognized event.   
void SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  
{  
  if (e.Result == null) return;  
  
  // Add event handler code here.  
  
  // The following code illustrates some of the information available  
  // in the recognition result.  
  Console.WriteLine("Grammar({0}), {1}: {2}",  
    e.Result.Grammar.Name, e.Result.Audio.Duration, e.Result.Text);  
  
  // Display the semantic values in the recognition result.  
  foreach (KeyValuePair<String, SemanticValue> child in e.Result.Semantics)  
  {  
    Console.WriteLine(" {0} key: {1}",  
      child.Key, child.Value.Value ?? "null");  
  }  
  Console.WriteLine();  
  
  // Display information about the words in the recognition result.  
  foreach (RecognizedWordUnit word in e.Result.Words)  
  {  
    RecognizedAudio audio = e.Result.GetAudioForWordRange(word, word);  
    Console.WriteLine(" {0,-10} {1,-10} {2,-10} {3} ({4})",  
      word.Text, word.LexicalForm, word.Pronunciation,  
      audio.Duration, word.DisplayAttributes);  
  }  
  
  // Display the recognition alternates for the result.  
  foreach (RecognizedPhrase phrase in e.Result.Alternates)  
  {  
    Console.WriteLine(" alt({0}) {1}", phrase.Confidence, phrase.Text);  
  }  
}  
```  
  
 ]]></format>
    </remarks>
    <altmember cref="T:System.Speech.Recognition.RecognitionEventArgs" />
    <altmember cref="T:System.Speech.Recognition.RecognizedPhrase" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected" />
    <altmember cref="E:System.Speech.Recognition.Grammar.SpeechRecognized" />
  </Docs>
  <Members>
    <Member MemberName="Alternates">
      <MemberSignature Language="C#" Value="public System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.RecognizedPhrase&gt; Alternates { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Collections.ObjectModel.ReadOnlyCollection`1&lt;class System.Speech.Recognition.RecognizedPhrase&gt; Alternates" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognitionResult.Alternates" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Alternates As ReadOnlyCollection(Of RecognizedPhrase)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Collections::ObjectModel::ReadOnlyCollection&lt;System::Speech::Recognition::RecognizedPhrase ^&gt; ^ Alternates { System::Collections::ObjectModel::ReadOnlyCollection&lt;System::Speech::Recognition::RecognizedPhrase ^&gt; ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.Alternates : System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.RecognizedPhrase&gt;" Usage="System.Speech.Recognition.RecognitionResult.Alternates" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.RecognizedPhrase&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Ruft die Auflistung der möglichen Übereinstimmungen als Eingabe für die Spracherkennung ab.</summary>
        <value>Eine schreibgeschützte Auflistung von Anerkennungsalternativen.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Erkennung <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> werden sortiert nach den Werten ihrer <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> Eigenschaften. Die Vertrauenswert eines angegebenen Ausdrucks gibt die Wahrscheinlichkeit, dass es sich bei der Eingabe entspricht, der Ausdruck an. Der Ausdruck mit dem höchsten Wert für die Zuverlässigkeit ist der Ausdruck, der die Eingabe in den meisten Fällen entspricht.  
  
 Jede <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> Wert ausgewertet werden soll, individuell und ohne Verweis auf die konfidenzwerte anderer <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>. Die Eigenschaften, die die <xref:System.Speech.Recognition.RecognitionResult> erbt <xref:System.Speech.Recognition.RecognizedPhrase> bieten ausführliche Informationen zu den Ausdruck mit der höchsten zuverlässigkeitsbewertung.  
  
 Eine Verwendungsmöglichkeit für die <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> -Auflistung dient für automatisierte Fehlerkorrektur. Beispielsweise könnte beim Entwerfen ein Dialogfeld Verzeichnis eine Anwendung der Benutzer aufgefordert, überprüfen, verfügt die Anwendung die richtige Informationen aus einem Ereignis verwendet: "Sie"Anna"sagen hat?" Wenn der Benutzer sagt "Nein", und klicken Sie dann die Anwendung kann den Benutzer über alle Varianten, die eine hoch genug Abfragen <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> Bewertung.  
  
 Weitere Informationen über die Spracherkennung und die Verwendung von Erkennungsalternativen, finden Sie unter [Spracherkennung](https://docs.microsoft.com/previous-versions/office/developer/speech-technologies/hh361633(v=office.14)) und [mit Speech Recognition Ereignissen](https://msdn.microsoft.com/library/01c598ca-2e0e-4e89-b303-cd1cef9e8482).  
  
   
  
## Examples  
 Das folgende Beispiel zeigt einen Handler für die `SpeechRecognized` Ereignis- und einige der Informationen über die zugeordnete <xref:System.Speech.Recognition.RecognitionResult>.  
  
```csharp  
  
// Handle the SpeechRecognized event.   
void SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  
{  
  if (e.Result == null) return;  
  
  // Add event handler code here.  
  
  // The following code illustrates some of the information available  
  // in the recognition result.  
  Console.WriteLine("Grammar({0}), {1}: {2}",  
    e.Result.Grammar.Name, e.Result.Audio.Duration, e.Result.Text);  
  
  // Display the semantic values in the recognition result.  
  foreach (KeyValuePair<String, SemanticValue> child in e.Result.Semantics)  
  {  
    Console.WriteLine(" {0} key: {1}",  
      child.Key, child.Value.Value ?? "null");  
  }  
  Console.WriteLine();  
  
  // Display information about the words in the recognition result.  
  foreach (RecognizedWordUnit word in e.Result.Words)  
  {  
    RecognizedAudio audio = e.Result.GetAudioForWordRange(word, word);  
    Console.WriteLine(" {0,-10} {1,-10} {2,-10} {3} ({4})",  
      word.Text, word.LexicalForm, word.Pronunciation,  
      audio.Duration, word.DisplayAttributes);  
  }  
  
  // Display the recognition alternates for the result.  
  foreach (RecognizedPhrase phrase in e.Result.Alternates)  
  {  
    Console.WriteLine(" alt({0}) {1}", phrase.Confidence, phrase.Text);  
  }  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognitionEventArgs" />
        <altmember cref="T:System.Speech.Recognition.RecognizedPhrase" />
      </Docs>
    </Member>
    <Member MemberName="Audio">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.RecognizedAudio Audio { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Speech.Recognition.RecognizedAudio Audio" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognitionResult.Audio" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Audio As RecognizedAudio" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::Recognition::RecognizedAudio ^ Audio { System::Speech::Recognition::RecognizedAudio ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.Audio : System.Speech.Recognition.RecognizedAudio" Usage="System.Speech.Recognition.RecognitionResult.Audio" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognizedAudio</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Ruft das Audio ab, das dem Erkennungsergebnis zugeordnet ist.</summary>
        <value>Das Audio, das dem Erkennungsergebnis oder der <see langword="null" /> zugeordnet ist, wenn die Erkennung das Ergebnis aus einem Aufruf der  <see langword="EmulateRecognize" /> oder der  <see langword="EmulateRecognizeAsync" />-Methoden einer <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> oder einer <see cref="T:System.Speech.Recognition.SpeechRecognizer" />-Instanz generiert.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Um einen Abschnitt des Audios abzurufen, die einen bestimmten Bereich von Wörtern in das Erkennungsergebnis zugeordnet ist, verwenden die <xref:System.Speech.Recognition.RecognitionResult.GetAudioForWordRange%2A> Methode.  
  
   
  
## Examples  
 Das folgende Beispiel zeigt einen Handler für die **"speechrecognized"** Ereignis- und einige der Informationen über die zugeordnete <xref:System.Speech.Recognition.RecognitionResult>.  
  
```csharp  
  
// Handle the SpeechRecognized event.   
void SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  
{  
  if (e.Result == null) return;  
  
  // Add event handler code here.  
  
  // The following code illustrates some of the information available  
  // in the recognition result.  
      Console.WriteLine("Grammar({0}): {1}", e.Result.Grammar.Name, e.Result.Text);  
      Console.WriteLine("Audio for result:");  
      Console.WriteLine("  Start time: "+ e.Result.Audio.StartTime);  
      Console.WriteLine("  Duration: " + e.Result.Audio.Duration);  
      Console.WriteLine("  Format: " + e.Result.Audio.Format.EncodingFormat);  
  
  // Display the semantic values in the recognition result.  
  foreach (KeyValuePair<String, SemanticValue> child in e.Result.Semantics)  
  {  
    Console.WriteLine(" {0} key: {1}",  
      child.Key, child.Value.Value ?? "null");  
  }  
  Console.WriteLine();  
  
  // Display information about the words in the recognition result.  
  foreach (RecognizedWordUnit word in e.Result.Words)  
  {  
    RecognizedAudio audio = e.Result.GetAudioForWordRange(word, word);  
    Console.WriteLine(" {0,-10} {1,-10} {2,-10} {3} ({4})",  
      word.Text, word.LexicalForm, word.Pronunciation,  
      audio.Duration, word.DisplayAttributes);  
  }  
  
  // Display the recognition alternates for the result.  
  foreach (RecognizedPhrase phrase in e.Result.Alternates)  
  {  
    Console.WriteLine(" alt({0}) {1}", phrase.Confidence, phrase.Text);  
  }  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognitionEventArgs" />
        <altmember cref="T:System.Speech.Recognition.RecognizedPhrase" />
        <altmember cref="M:System.Speech.Recognition.RecognitionResult.GetAudioForWordRange(System.Speech.Recognition.RecognizedWordUnit,System.Speech.Recognition.RecognizedWordUnit)" />
      </Docs>
    </Member>
    <Member MemberName="GetAudioForWordRange">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.RecognizedAudio GetAudioForWordRange (System.Speech.Recognition.RecognizedWordUnit firstWord, System.Speech.Recognition.RecognizedWordUnit lastWord);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Speech.Recognition.RecognizedAudio GetAudioForWordRange(class System.Speech.Recognition.RecognizedWordUnit firstWord, class System.Speech.Recognition.RecognizedWordUnit lastWord) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.RecognitionResult.GetAudioForWordRange(System.Speech.Recognition.RecognizedWordUnit,System.Speech.Recognition.RecognizedWordUnit)" />
      <MemberSignature Language="VB.NET" Value="Public Function GetAudioForWordRange (firstWord As RecognizedWordUnit, lastWord As RecognizedWordUnit) As RecognizedAudio" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; System::Speech::Recognition::RecognizedAudio ^ GetAudioForWordRange(System::Speech::Recognition::RecognizedWordUnit ^ firstWord, System::Speech::Recognition::RecognizedWordUnit ^ lastWord);" />
      <MemberSignature Language="F#" Value="member this.GetAudioForWordRange : System.Speech.Recognition.RecognizedWordUnit * System.Speech.Recognition.RecognizedWordUnit -&gt; System.Speech.Recognition.RecognizedAudio" Usage="recognitionResult.GetAudioForWordRange (firstWord, lastWord)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognizedAudio</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="firstWord" Type="System.Speech.Recognition.RecognizedWordUnit" />
        <Parameter Name="lastWord" Type="System.Speech.Recognition.RecognizedWordUnit" />
      </Parameters>
      <Docs>
        <param name="firstWord">Das erste Wort im Bereich.</param>
        <param name="lastWord">Das letzte Wort im Bereich.</param>
        <summary>Ruft einen Audioabschnitt ab, der einem bestimmten Bereich von Wörtern im Erkennungsergebnis zugeordnet ist.</summary>
        <returns>Der Audioabschnitt, der dem Wortbereich zugeordnet ist.</returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Rufen Sie die vollständige Audioinhalte mit dem Erkennungsergebnis mit den <xref:System.Speech.Recognition.RecognitionResult.Audio%2A> Eigenschaft.  
  
   
  
## Examples  
 Im folgenden Beispiel erstellt eine Grammatik für Eingabe akzeptiert und ein Handler für angefügt, das die `SpeechRecognized` Ereignis. Die Grammatik verwendet einen Platzhalter für das Name-Element, von dem Ausdruck. Der Ereignishandler verwendet die Audiodaten aus dem Platzhalter erstellen und eine Eingabeaufforderung für die Grußformel bei der Wiedergabe.  
  
```csharp  
  
private Grammar CreateNameInputGrammar()  
{  
  GrammarBuilder wildcardBuilder = new GrammarBuilder();  
  wildcardBuilder.AppendWildcard();  
  SemanticResultKey nameKey =  
    new SemanticResultKey("Name", wildcardBuilder);  
  
  GrammarBuilder nameBuilder =  
    new GrammarBuilder("My name is");  
  nameBuilder.Append(nameKey);  
  
  Grammar nameGrammar = new Grammar(nameBuilder);  
  nameGrammar.Name = "Name input";  
  
  nameGrammar.SpeechRecognized +=  
    new EventHandler<SpeechRecognizedEventArgs>(  
      NameInputHandler);  
  
  return nameGrammar;  
}  
  
// Handle the SpeechRecognized event for the name grammar.  
private void NameInputHandler(object sender, SpeechRecognizedEventArgs e)  
{  
  if (e.Result == null) return;  
  
  RecognitionResult result = e.Result;  
  SemanticValue semantics = e.Result.Semantics;  
  
  if (semantics.ContainsKey("Name"))  
  {  
    RecognizedAudio nameAudio =  
      result.GetAudioForWordRange(  
        result.Words[3], result.Words[result.Words.Count - 1]);  
  
    // Save the audio. Create a directory and file as necessary.  
    FileInfo fi = new FileInfo(@"C:\temp\temp.wav");  
    if (!fi.Directory.Exists)  
    {  
      fi.Directory.Create();  
    }  
    FileStream stream = new FileStream(fi.FullName, FileMode.Create);  
    nameAudio.WriteToWaveStream(stream);  
    stream.Close();  
  
    // Greet the person using the saved audio.  
    SpeechSynthesizer synthesizer = new SpeechSynthesizer();  
    PromptBuilder builder = new PromptBuilder();  
    builder.AppendText("Hello");  
    builder.AppendAudio(fi.FullName);  
    synthesizer.Speak(builder);  
  }  
}  
```  
  
 ]]></format>
        </remarks>
        <exception cref="T:System.NullReferenceException">Die Erkennung generierte das Ergebnis aus einem Aufruf der <see langword="EmulateRecognize" />-Methode oder der <see langword="EmulateRecognizeAsync" />-Methode des <see cref="T:System.Speech.Recognition.SpeechRecognizer" />-Objekts oder des <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" />-Objekts.</exception>
        <altmember cref="T:System.Speech.Recognition.RecognitionEventArgs" />
        <altmember cref="T:System.Speech.Recognition.RecognizedPhrase" />
        <altmember cref="T:System.Speech.Recognition.RecognizedWordUnit" />
        <altmember cref="P:System.Speech.Recognition.RecognitionResult.Audio" />
        <altmember cref="P:System.Speech.Recognition.RecognizedPhrase.Words" />
      </Docs>
    </Member>
    <Member MemberName="System.Runtime.Serialization.ISerializable.GetObjectData">
      <MemberSignature Language="C#" Value="void ISerializable.GetObjectData (System.Runtime.Serialization.SerializationInfo info, System.Runtime.Serialization.StreamingContext context);" />
      <MemberSignature Language="ILAsm" Value=".method hidebysig newslot virtual instance void System.Runtime.Serialization.ISerializable.GetObjectData(class System.Runtime.Serialization.SerializationInfo info, valuetype System.Runtime.Serialization.StreamingContext context) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.RecognitionResult.System#Runtime#Serialization#ISerializable#GetObjectData(System.Runtime.Serialization.SerializationInfo,System.Runtime.Serialization.StreamingContext)" />
      <MemberSignature Language="VB.NET" Value="Sub GetObjectData (info As SerializationInfo, context As StreamingContext) Implements ISerializable.GetObjectData" />
      <MemberSignature Language="C++ CLI" Value=" virtual void System.Runtime.Serialization.ISerializable.GetObjectData(System::Runtime::Serialization::SerializationInfo ^ info, System::Runtime::Serialization::StreamingContext context) = System::Runtime::Serialization::ISerializable::GetObjectData;" />
      <MemberType>Method</MemberType>
      <Implements>
        <InterfaceMember>M:System.Runtime.Serialization.ISerializable.GetObjectData(System.Runtime.Serialization.SerializationInfo,System.Runtime.Serialization.StreamingContext)</InterfaceMember>
      </Implements>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="info" Type="System.Runtime.Serialization.SerializationInfo" />
        <Parameter Name="context" Type="System.Runtime.Serialization.StreamingContext" />
      </Parameters>
      <Docs>
        <param name="info">Das mit Daten zu füllende Objekt.</param>
        <param name="context">Das Ziel für die Serialisierung.</param>
        <summary>Füllt eine <see cref="T:System.Runtime.Serialization.SerializationInfo" />-Instanz mit den Daten auf, die zum Serialisieren des Zielobjekts erforderlich sind.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Bei diesem Member handelt es sich um eine explizite Schnittstellenmemberimplementierung. Er kann nur verwendet werden, wenn die <xref:System.Speech.Recognition.RecognitionResult>-Instanz in eine <xref:System.Runtime.Serialization.ISerializable>-Schnittstelle umgewandelt wird.  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Runtime.Serialization.ISerializable" />
        <altmember cref="T:System.Runtime.Serialization.SerializationInfo" />
        <altmember cref="T:System.Runtime.Serialization.StreamingContext" />
      </Docs>
    </Member>
  </Members>
</Type>