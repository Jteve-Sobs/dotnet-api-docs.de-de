<Type Name="SpeechRecognizedEventArgs" FullName="System.Speech.Recognition.SpeechRecognizedEventArgs">
  <Metadata>
    <Meta Name="ms.openlocfilehash" Value="7940e4fc991649f894d5bedfee2d8937926f8188" />
    <Meta Name="ms.sourcegitcommit" Value="c0c07dbd19cd7017243f9ac36915755f79bc8da6" />
    <Meta Name="ms.translationtype" Value="HT" />
    <Meta Name="ms.contentlocale" Value="de-DE" />
    <Meta Name="ms.lasthandoff" Value="11/27/2018" />
    <Meta Name="ms.locfileid" Value="52381103" />
  </Metadata>
  <TypeSignature Language="C#" Value="public class SpeechRecognizedEventArgs : System.Speech.Recognition.RecognitionEventArgs" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi serializable beforefieldinit SpeechRecognizedEventArgs extends System.Speech.Recognition.RecognitionEventArgs" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Recognition.SpeechRecognizedEventArgs" />
  <TypeSignature Language="VB.NET" Value="Public Class SpeechRecognizedEventArgs&#xA;Inherits RecognitionEventArgs" />
  <TypeSignature Language="C++ CLI" Value="public ref class SpeechRecognizedEventArgs : System::Speech::Recognition::RecognitionEventArgs" />
  <TypeSignature Language="F#" Value="type SpeechRecognizedEventArgs = class&#xA;    inherit RecognitionEventArgs" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>3.0.0.0</AssemblyVersion>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Speech.Recognition.RecognitionEventArgs</BaseTypeName>
  </Base>
  <Interfaces />
  <Attributes>
    <Attribute FrameworkAlternate="netframework-3.0;netframework-3.5;netframework-4.0;netframework-4.5;netframework-4.5.1;netframework-4.5.2;netframework-4.6;netframework-4.6.1;netframework-4.6.2;netframework-4.7;netframework-4.7.1;netframework-4.7.2;netframework-4.8">
      <AttributeName>System.Serializable</AttributeName>
    </Attribute>
  </Attributes>
  <Docs>
    <summary>Stellt Informationen für die Ereignisse <see cref="E:System.Speech.Recognition.Grammar.SpeechRecognized" />, <see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" /> und <see cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" /> bereit.</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Ein `SpeechRecognized` Ereignis wird ausgelöst, durch die <xref:System.Speech.Recognition.Grammar>, <xref:System.Speech.Recognition.SpeechRecognizer> und <xref:System.Speech.Recognition.SpeechRecognitionEngine> Klassen.  
  
 `SpeechRecognized` Ereignisse werden generiert, wenn eine oder mehrere an, der aus ein Erkennungsvorgang haben eine Bewertung der Vertrauenswürdigkeit der hoch genug ist, um akzeptiert zu werden. Um ausführliche Informationen zu eines erkannten Ausdrucks zu erhalten, Zugriff auf die <xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A> Eigenschaft im Ereignishandler für das Ereignis.  
  
 `SpeechRecognizedEventArgs` leitet sich von der <xref:System.Speech.Recognition.RecognitionEventArgs> Klasse.  
  
   
  
## Examples  
 Im folgende Beispiel ist Teil einer Konsolenanwendung, die lädt eine spracherkennungsgrammatik aus, und zeigt die Spracheingabe die freigegebene Erkennung, die zugehörigen Erkennungsergebnisse und die zugehörigen Ereignisse, die von der Spracherkennung ausgelöst. Wenn Windows-Spracherkennung nicht ausgeführt wird, wird Windows-Spracherkennung starten Sie dann auf diese Anwendung ebenfalls gestartet.  
  
 Eingabe gesprochen, wie z. B. "Ich möchte von Chicago nach Miami fliegen" ausgelöst werden, eine <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> Ereignis. Sprechen den Ausdruck "Fliegen me von Houston nach Chicago" wird nicht ausgelöst. eine <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> Ereignis.  
  
 Im Beispiel wird einen Handler für die <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> erfolgreich für anzuzeigende Ereignis erkannt wird, Ausdrücke und die Semantik, die sie in der Konsole enthalten.  
  
```csharp  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    static void Main(string[] args)  
  
    // Initialize a shared speech recognition engine.  
    {  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
  
        // Create SemanticResultValue objects that contain cities and airport codes.  
        SemanticResultValue chicago = new SemanticResultValue("Chicago", "ORD");  
        SemanticResultValue boston = new SemanticResultValue("Boston", "BOS");  
        SemanticResultValue miami = new SemanticResultValue("Miami", "MIA");  
        SemanticResultValue dallas = new SemanticResultValue("Dallas", "DFW");  
  
        // Create a Choices object and add the SemanticResultValue objects, using  
        // implicit conversion from SemanticResultValue to GrammarBuilder  
        Choices cities = new Choices();  
        cities.Add(new Choices(new GrammarBuilder[] { chicago, boston, miami, dallas }));  
  
        // Build the phrase and add SemanticResultKeys.  
        GrammarBuilder chooseCities = new GrammarBuilder();  
        chooseCities.Append("I want to fly from");  
        chooseCities.Append(new SemanticResultKey("origin", cities));  
        chooseCities.Append("to");  
        chooseCities.Append(new SemanticResultKey("destination", cities));  
  
        // Build a Grammar object from the GrammarBuilder.  
        Grammar bookFlight = new Grammar(chooseCities);  
        bookFlight.Name = "Book Flight";  
  
        // Add a handler for the LoadGrammarCompleted event.  
        recognizer.LoadGrammarCompleted +=  
          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
  
        // Add a handler for the SpeechRecognized event.  
        recognizer.SpeechRecognized +=   
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
  
        // Load the grammar object to the recognizer.  
        recognizer.LoadGrammarAsync(bookFlight);  
  
        // Keep the console window open.  
        Console.ReadLine();  
      }  
    }  
  
    // Handle the LoadGrammarCompleted event.  
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      Console.WriteLine("Grammar loaded: " + e.Grammar.Name);  
      Console.WriteLine();  
    }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("Speech recognized:  " + e.Result.Text);  
      Console.WriteLine();  
      Console.WriteLine("Semantic results:");  
      Console.WriteLine("  The flight origin is " + e.Result.Semantics["origin"].Value);  
      Console.WriteLine("  The flight destination is " + e.Result.Semantics["destination"].Value);  
    }  
  }  
}  
  
```  
  
 ]]></format>
    </remarks>
    <altmember cref="T:System.Speech.Recognition.SpeechRecognizedEventArgs" />
    <altmember cref="T:System.Speech.Recognition.RecognitionEventArgs" />
    <altmember cref="T:System.Speech.Recognition.RecognitionResult" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized" />
    <altmember cref="E:System.Speech.Recognition.Grammar.SpeechRecognized" />
    <altmember cref="T:System.Speech.Recognition.SpeechHypothesizedEventArgs" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected" />
    <altmember cref="T:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs" />
  </Docs>
  <Members />
</Type>