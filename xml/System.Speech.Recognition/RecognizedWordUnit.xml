<Type Name="RecognizedWordUnit" FullName="System.Speech.Recognition.RecognizedWordUnit">
  <Metadata>
    <Meta Name="ms.openlocfilehash" Value="4fa22cc79f82c78388e7443f19bd2b8fe32454f3" />
    <Meta Name="ms.sourcegitcommit" Value="0ec122ee5f3681159b8460ab15b409fd6e3d3ae0" />
    <Meta Name="ms.translationtype" Value="HT" />
    <Meta Name="ms.contentlocale" Value="de-DE" />
    <Meta Name="ms.lasthandoff" Value="10/04/2018" />
    <Meta Name="ms.locfileid" Value="48732217" />
  </Metadata>
  <TypeSignature Language="C#" Value="public class RecognizedWordUnit" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi serializable beforefieldinit RecognizedWordUnit extends System.Object" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Recognition.RecognizedWordUnit" />
  <TypeSignature Language="VB.NET" Value="Public Class RecognizedWordUnit" />
  <TypeSignature Language="C++ CLI" Value="public ref class RecognizedWordUnit" />
  <TypeSignature Language="F#" Value="type RecognizedWordUnit = class" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>3.0.0.0</AssemblyVersion>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Object</BaseTypeName>
  </Base>
  <Interfaces />
  <Attributes>
    <Attribute FrameworkAlternate="netframework-3.0;netframework-3.5;netframework-4.0;netframework-4.5;netframework-4.5.1;netframework-4.5.2;netframework-4.6;netframework-4.6.1;netframework-4.6.2;netframework-4.7;netframework-4.7.1;netframework-4.7.2;netframework-4.8">
      <AttributeName>System.Diagnostics.DebuggerDisplay("Text: {Text}")</AttributeName>
    </Attribute>
    <Attribute FrameworkAlternate="netframework-3.0;netframework-3.5;netframework-4.0;netframework-4.5;netframework-4.5.1;netframework-4.5.2;netframework-4.6;netframework-4.6.1;netframework-4.6.2;netframework-4.7;netframework-4.7.1;netframework-4.7.2;netframework-4.8">
      <AttributeName>Serializable</AttributeName>
    </Attribute>
  </Attributes>
  <Docs>
    <summary>Stellt die unteilbare Einheit der erkannten Sprache bereit.</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Alle von einer erkennungs-Engine zurückgegebenen Ergebnisse werden erstellt, der <xref:System.Speech.Recognition.RecognizedWordUnit> Objekte.  
  
 Ein Array von <xref:System.Speech.Recognition.RecognizedWordUnit> Objekte kann zugegriffen werden, für jeden Erkennungsvorgang über die <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> Eigenschaft für die <xref:System.Speech.Recognition.RecognizedPhrase> Objekt.  
  
 Zusätzlich zur Bereitstellung von ein Maß für die Zuverlässigkeit der Erkennung (<xref:System.Speech.Recognition.RecognizedWordUnit.Confidence%2A>) eine <xref:System.Speech.Recognition.RecognizedWordUnit> -Instanzen bieten:  
  
-   Normalisierte und genaue (oder lexikalische) Textdarstellungen für ein erkanntes Wort. Weitere Informationen finden Sie unter <xref:System.Speech.Recognition.ReplacementText>, <xref:System.Speech.Recognition.RecognizedWordUnit.Text%2A> und <xref:System.Speech.Recognition.RecognizedWordUnit.LexicalForm%2A>.  
  
-   Aussprache-Informationen, die mithilfe von Zeichen aus einem unterstützten Lautalphabet, wie z. B. dem internationalen Lautalphabet (IPA) oder dem universellen Sprachlautsatz (UPS). Weitere Informationen finden Sie unter <xref:System.Speech.Recognition.RecognizedWordUnit.Pronunciation%2A>.  
  
-   Formatierung für den Druck. Weitere Informationen finden Sie unter den <xref:System.Speech.Recognition.DisplayAttributes> Klasse und die zugehörige <xref:System.Speech.Recognition.RecognizedWordUnit.DisplayAttributes%2A> Eigenschaft.  
  
   
  
## Examples  
 Das folgende Beispiel zeigt eine Hilfsprogramm-Routine (`stringFromWordArray`), die Zeichenfolgen generiert. Die Zeichenfolgen enthalten lexikalische Ausgabe (mithilfe von <xref:System.Speech.Recognition.RecognizedWordUnit.LexicalForm%2A>), normalisierte Text (mit <xref:System.Speech.Recognition.RecognizedWordUnit.Text%2A>), oder phonetische Zeichen aus dem internationalen Lautalphabet (mit <xref:System.Speech.Recognition.RecognizedWordUnit.Pronunciation%2A>). Zeichenfolgen werden mithilfe von formatiert <xref:System.Speech.Recognition.DisplayAttributes> Objekte abgerufen, von der <xref:System.Speech.Recognition.RecognizedWordUnit.DisplayAttributes%2A> Eigenschaft aus einem <xref:System.Collections.ObjectModel.ReadOnlyCollection%601> von <xref:System.Speech.Recognition.RecognizedWordUnit> Objekte. Die <xref:System.Speech.Recognition.RecognizedWordUnit> Objekte erhalten Sie vom der <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> Eigenschaft für die <xref:System.Speech.Recognition.RecognizedPhrase> Objekt.  
  
```csharp  
  
internal enum WordType   
{  
  Text,  
  Normalized = Text,  
  Lexical,  
  Pronunciation  
}  
```  
  
```csharp  
internal static string stringFromWordArray(ReadOnlyCollection<RecognizedWordUnit> words, WordType type)   
{  
  string text = "";  
  foreach (RecognizedWordUnit word in words)   
  {  
    string wordText = "";  
    if (type == WordType.Text || type == WordType.Normalized)   
    {  
      wordText = word.Text;  
    }   
    else if (type == WordType.Lexical)   
    {  
      wordText = word.LexicalForm;  
    }   
    else if (type == WordType.Pronunciation)   
    {  
      wordText = word.Pronunciation;  
    }   
    else   
    {  
      throw new InvalidEnumArgumentException(String.Format("[0}: is not a valid input", type));  
    }  
    // Use display attribute  
  
    if ((word.DisplayAttributes & DisplayAttributes.OneTrailingSpace) != 0)   
    {  
      wordText += " ";  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.TwoTrailingSpaces) != 0)  
    {  
      wordText += "  ";  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.ConsumeLeadingSpaces) != 0)   
    {  
      wordText = wordText.TrimStart();  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.ZeroTrailingSpaces) != 0)  
    {  
      wordText = wordText.TrimEnd();  
    }  
  
    text += wordText;  
  
  }  
  return text;  
}  
```  
  
 ]]></format>
    </remarks>
    <altmember cref="T:System.Speech.Recognition.DisplayAttributes" />
  </Docs>
  <Members>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public RecognizedWordUnit (string text, float confidence, string pronunciation, string lexicalForm, System.Speech.Recognition.DisplayAttributes displayAttributes, TimeSpan audioPosition, TimeSpan audioDuration);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(string text, float32 confidence, string pronunciation, string lexicalForm, valuetype System.Speech.Recognition.DisplayAttributes displayAttributes, valuetype System.TimeSpan audioPosition, valuetype System.TimeSpan audioDuration) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.RecognizedWordUnit.#ctor(System.String,System.Single,System.String,System.String,System.Speech.Recognition.DisplayAttributes,System.TimeSpan,System.TimeSpan)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; RecognizedWordUnit(System::String ^ text, float confidence, System::String ^ pronunciation, System::String ^ lexicalForm, System::Speech::Recognition::DisplayAttributes displayAttributes, TimeSpan audioPosition, TimeSpan audioDuration);" />
      <MemberSignature Language="F#" Value="new System.Speech.Recognition.RecognizedWordUnit : string * single * string * string * System.Speech.Recognition.DisplayAttributes * TimeSpan * TimeSpan -&gt; System.Speech.Recognition.RecognizedWordUnit" Usage="new System.Speech.Recognition.RecognizedWordUnit (text, confidence, pronunciation, lexicalForm, displayAttributes, audioPosition, audioDuration)" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="text" Type="System.String" />
        <Parameter Name="confidence" Type="System.Single" />
        <Parameter Name="pronunciation" Type="System.String" />
        <Parameter Name="lexicalForm" Type="System.String" />
        <Parameter Name="displayAttributes" Type="System.Speech.Recognition.DisplayAttributes" />
        <Parameter Name="audioPosition" Type="System.TimeSpan" />
        <Parameter Name="audioDuration" Type="System.TimeSpan" />
      </Parameters>
      <Docs>
        <param name="text">Der normalisierte Text für ein erkanntes Wort.  
  
Dieser Wert kann <see langword="null" />, "" oder <see cref="F:System.String.Empty" /> sein.</param>
        <param name="confidence">Ein <see langword="float" />-Wert von 0,0 bis 1,0, der die Sicherheit der Worterkennung angibt.</param>
        <param name="pronunciation">Die Lautrechtschreibung eines erkannten Worts.  
  
Dieser Wert kann <see langword="null" />, "" oder <see cref="F:System.String.Empty" /> sein.</param>
        <param name="lexicalForm">Der nicht normalisierte Text für ein erkanntes Wort.  
  
Dieses Argument ist erforderlich und darf nicht <see langword="null" />, "" oder <see cref="F:System.String.Empty" /> sein.</param>
        <param name="displayAttributes">Definiert die Verwendung von Leerzeichen, um bekannte Wörter anzuzeigen.</param>
        <param name="audioPosition">Die Position des erkannten Worts im Audioeingabestream.  
  
Dieser Wert kann <see cref="F:System.TimeSpan.Zero" /> sein.</param>
        <param name="audioDuration">Die Länge der Audioeingabe entsprechend dem erkannten Wort.  
  
Dieser Wert kann <see cref="F:System.TimeSpan.Zero" /> sein.</param>
        <summary>Initialisiert eine neue Instanz der <see cref="T:System.Speech.Recognition.RecognizedWordUnit" />-Klasse.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Wenn `text` oder `pronunciation` sind `null`, "", oder <xref:System.String.Empty> und <xref:System.Speech.Recognition.RecognizedWordUnit> wird verwendet, bei der ein Erkennungsvorgang, generiert die erkennungs-Engine entsprechende Werte in der Ausgabe <xref:System.Speech.Recognition.RecognizedWordUnit> Instanz.  
  
 Direkte Erstellung von <xref:System.Speech.Recognition.RecognizedWordUnit> Instanzen wird normalerweise verwendet, nur dann, wenn mit Erkennungsvorgänge emulieren die <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A> oder <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> Methoden der <xref:System.Speech.Recognition.SpeechRecognitionEngine> Klasse und die <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A> oder <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> Methoden der <xref:System.Speech.Recognition.SpeechRecognizer> Klasse.  
  
 Für die eigentlichen Anwendungen werden nicht direkt erstellt <xref:System.Speech.Recognition.RecognizedWordUnit>, stattdessen erhalten Sie über die <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> Eigenschaft für die <xref:System.Speech.Recognition.RecognizedPhrase> Objekt.  
  
   
  
## Examples  
 Im folgende Beispiel wird ein etwas aus der Luft gegriffen Test Emulation ",", in dem neue Begriffe aus der Eingabe generiert und an den Emulator übergeben und dann überprüft.  
  
```csharp  
private void _emulateAndVerify_Click(object sender, EventArgs e)   
{  
  char[] delimiterChars = { ' ', ',', '.', ':', ';', '\t' };  
  string text = _emulateTextBox.Text;  
  string[] words = text.Split(delimiterChars);  
  
  RecognizedWordUnit[] InputWordUnits = new RecognizedWordUnit[words.Length];  
  for (int i = 0; i < words.Length; i++)   
  {  
    InputWordUnits[i] = new RecognizedWordUnit(  
        "",   
        0,   
        "",  
        words[i].ToLower(),   
        DisplayAttributes.OneTrailingSpace,   
        new TimeSpan(),   
        new TimeSpan());  
  }  
  
  RecognitionResult rec = _recognizer.EmulateRecognize(  
        InputWordUnits,   
        System.Globalization.CompareOptions.IgnoreCase);  
  if (rec == null)   
  {  
    MessageBox.Show(String.Format("Recognition emulation for {0} failed.\n", text));  
  }   
  else if (InputWordUnits.Length != rec.Words.Count)   
  {  
    MessageBox.Show(  
       String.Format("Length mismatch: Input was {0} words, Recognition has {1} words.\n}"));  
  }   
  else   
  {  
    for (int i = 0; i < InputWordUnits.Length; i++)   
    {  
  
      if (rec.Words[i].LexicalForm.ToLower() != InputWordUnits[i].LexicalForm.ToLower())   
      {  
        MessageBox.Show(  
          String.Format("Input word {0} \"{1}\" not found. Recognition output is {2}",  
          i, InputWordUnits[i].LexicalForm, rec.Words[i].LexicalForm));  
        continue;  
      }  
    }  
  }  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.DisplayAttributes" />
        <related type="ExternalDocumentation" href="http://go.microsoft.com/fwlink/?LinkId=58363">Internationalen Lautalphabet</related>
      </Docs>
    </Member>
    <Member MemberName="Confidence">
      <MemberSignature Language="C#" Value="public float Confidence { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance float32 Confidence" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedWordUnit.Confidence" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Confidence As Single" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property float Confidence { float get(); };" />
      <MemberSignature Language="F#" Value="member this.Confidence : single" Usage="System.Speech.Recognition.RecognizedWordUnit.Confidence" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>get: System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Single</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Ruft einen durch die Erkennung zugewiesenen Wert ab, der die Wahrscheinlichkeit angibt, dass ein erkanntes Wort mit einer angegebenen Eingabe übereinstimmt.</summary>
        <value>Eine relative Maßnahme der Sicherheit der richtigen Erkennung für ein Wort. Der Wert liegt zwischen 0,0 und 1,0 (geringes bis hohes Vertrauen).</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Vertrauensergebnisse nicht die absolute Wahrscheinlichkeit an, dass ein Wort richtig erkannt wurde. Vertrauensergebnisse wird stattdessen einen Mechanismus zum Vergleichen der relativen Genauigkeit von mehreren Erkennungsalternativen für eine angegebene Eingabe bereitstellen. Dies erleichtert die genaueste Erkennungsergebnis zurückgeben. Beispielsweise verfügt ein erkanntes Wort ein vertrauensergebnis 0,8, bedeutet dies nicht, dass das Wort ein 80 % Wahrscheinlichkeit der ordnungsgemäße Übereinstimmung für die Eingabe hat.  Dies bedeutet, dass das Wort höherer Wahrscheinlichkeit, dass die ordnungsgemäße Übereinstimmung für die Eingabe als andere Ergebnisse, die darauf vertrauen, die kleiner als 0,8 bewertet.  
  
 Ein vertrauensergebnis allein ist nicht sinnvoll, es sei denn, Sie alternative Ergebnisse, berücksichtigt werden sollen, entweder über den gleichen Erkennungsvorgang oder über vorherige Erkennungsvorgänge von derselben Eingabe verglichen werden soll.  
  
 Die Rückgabewerte <xref:System.Speech.Recognition.RecognizedWordUnit.Confidence%2A> jedes erkennungs-Engine relative und eindeutig sind. Es ist keine Definition konfidenzwerte zwischen zwei verschiedenen Erkennungsmodule wie vergleichen zu können, noch wie die <xref:System.Speech.Recognition.RecognizedWordUnit.Confidence%2A> einzelner <xref:System.Speech.Recognition.RecognizedWordUnit> Objekte definieren die <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> von einer <xref:System.Speech.Recognition.RecognizedPhrase>.  
  
 Eine spracherkennungs-Engine kann gesprochener Eingabe ein niedriges vertrauensergebnis aus unterschiedlichen Gründen, z. B. Hintergrund Störungen, inarticulate-Sprache, oder unvorhergesehene Wörter oder wortsequenzen zuweisen. Wenn Ihre Anwendung verwendet eine <xref:System.Speech.Recognition.SpeechRecognitionEngine> Instanz können Sie ändern, den Vertrauensgrad, auf welche Sprache Eingabe akzeptiert oder abgelehnt, die mit einem, der <xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A> Methoden. Vertrauen Schwellenwerte für die freigegebene Erkennung, die von verwalteten <xref:System.Speech.Recognition.SpeechRecognizer>, ein Benutzerprofil zugeordnet und in der Windows-Registrierung gespeichert sind. Anwendungen sollten Änderungen an der Registrierung für die Eigenschaften der freigegebenen Erkennung nicht geschrieben werden.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="DisplayAttributes">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.DisplayAttributes DisplayAttributes { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.Speech.Recognition.DisplayAttributes DisplayAttributes" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedWordUnit.DisplayAttributes" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property DisplayAttributes As DisplayAttributes" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::Recognition::DisplayAttributes DisplayAttributes { System::Speech::Recognition::DisplayAttributes get(); };" />
      <MemberSignature Language="F#" Value="member this.DisplayAttributes : System.Speech.Recognition.DisplayAttributes" Usage="System.Speech.Recognition.RecognizedWordUnit.DisplayAttributes" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>get: System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.DisplayAttributes</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Ruft die Formatierungsinformationen ab, die verwendet werden, um die Textausgabe aus der aktuellen <see cref="T:System.Speech.Recognition.RecognizedWordUnit" />-Instanz zu erstellen.</summary>
        <value>Bezeichnet die Verwendung von Leerstellen, die von den Inhalten eines <see cref="T:System.Speech.Recognition.RecognizedWordUnit" />-Objekts angezeigt werden.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Die <xref:System.Speech.Recognition.DisplayAttributes> zurückgegebenes Objekt der <xref:System.Speech.Recognition.RecognizedWordUnit.DisplayAttributes%2A> Eigenschaft gibt die führenden und nachgestellten Leerzeichen mit einem bestimmten Wort, verwendet werden, sofern vorhanden.  
  
 Weitere Informationen zur Verwendung dieser Formatierungsinformationen finden Sie unter den <xref:System.Speech.Recognition.DisplayAttributes> Enumeration.  
  
   
  
## Examples  
 Das folgende Beispiel zeigt eine Hilfsprogramm-Routine (`stringFromWordArray`), generiert eine Zeichenfolge, die formatiert wird, in einer von drei Methoden: lexikalisch (mit <xref:System.Speech.Recognition.RecognizedWordUnit.LexicalForm%2A>), normalisierte (mit <xref:System.Speech.Recognition.RecognizedWordUnit.Text%2A>), oder phonetisch (mit <xref:System.Speech.Recognition.RecognizedWordUnit.Pronunciation%2A>). Die Textausgabe aus einer der <xref:System.Speech.Recognition.RecognizedWordUnit.DisplayAttributes%2A> Eigenschaft für eine <xref:System.Collections.ObjectModel.ReadOnlyCollection%601> von <xref:System.Speech.Recognition.RecognizedWordUnit> -Objekte, die aus abgerufen werden die <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> Eigenschaft für eine <xref:System.Speech.Recognition.RecognizedPhrase> Objekt.  
  
```csharp  
  
internal enum WordType   
{  
  Text,  
  Normalized = Text,  
  Lexical,  
  Pronunciation  
}  
```  
  
```csharp  
internal static string stringFromWordArray(  
        ReadOnlyCollection<RecognizedWordUnit> words,   
        WordType type)   
{  
  string text = "";  
  foreach (RecognizedWordUnit word in words)   
  {  
    string wordText = "";  
    if (type == WordType.Text || type == WordType.Normalized)   
    {  
      wordText = word.Text;  
    }   
    else if (type == WordType.Lexical)   
    {  
      wordText = word.LexicalForm;  
    }  
    else if (type == WordType.Pronunciation)   
    {  
       wordText = word.Pronunciation;  
    }   
    else   
    {  
      throw new InvalidEnumArgumentException(  
         String.Format("[0}: is not a valid input", type));  
    }  
  
    // Use display attribute  
    if ((word.DisplayAttributes & DisplayAttributes.OneTrailingSpace) != 0)   
    {  
      wordText += " ";  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.TwoTrailingSpaces) != 0)  
    {  
      wordText += "  ";  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.ConsumeLeadingSpaces) != 0)   
    {  
      wordText = wordText.TrimStart();  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.ZeroTrailingSpaces) != 0)  
    {  
      wordText = wordText.TrimEnd();  
    }  
  
    text += wordText;  
  
  }  
  return text;  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.DisplayAttributes" />
      </Docs>
    </Member>
    <Member MemberName="LexicalForm">
      <MemberSignature Language="C#" Value="public string LexicalForm { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance string LexicalForm" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedWordUnit.LexicalForm" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property LexicalForm As String" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::String ^ LexicalForm { System::String ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.LexicalForm : string" Usage="System.Speech.Recognition.RecognizedWordUnit.LexicalForm" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>get: System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.String</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Ruft den nicht normalisierten Text eines erkannten Worts ab.</summary>
        <value>Gibt eine <see cref="T:System.String" /> zurück, das den Text eines erkannten Worts ohne eine Normalisierung enthält.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 In den meisten Fällen die Rückgabewerte <xref:System.Speech.Recognition.RecognizedWordUnit.Text%2A> und <xref:System.Speech.Recognition.RecognizedWordUnit.LexicalForm%2A> identisch sind. Allerdings können Erkennungsmodule Spracherkennung Normalisierung verwenden, mehr benutzerfreundliche oder Umgangssprachlich Textdarstellungen der Audioeingabe zurückgegeben.  
  
 Normalisierung der Sprache ist die Verwendung von sonderkonstrukte oder Symbole zum Sprache im Schreiben von Ausdrücken. Beispielsweise kann Normalisierung der gesprochenen Worte "einen Dollar und sechzehn Cent" mit "$1.16" in der Output-Text ersetzen.  
  
   
  
## Examples  
 Das folgende Beispiel zeigt eine Hilfsprogramm-Routine, die Text in einem der drei Formate generiert: lexikalische (mit <xref:System.Speech.Recognition.RecognizedWordUnit.LexicalForm%2A>), normalisierte (mit <xref:System.Speech.Recognition.RecognizedWordUnit.Text%2A>), und phonetische (mit <xref:System.Speech.Recognition.RecognizedWordUnit.Pronunciation%2A>). Die Textausgabe aus einer eine <xref:System.Collections.ObjectModel.ReadOnlyCollection%601> von <xref:System.Speech.Recognition.RecognizedWordUnit> -Objekte, die aus abgerufen werden die <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> Eigenschaft für die <xref:System.Speech.Recognition.RecognizedPhrase> Objekt.  
  
```csharp  
  
internal enum WordType   
{  
  Text,  
  Normalized = Text,  
  Lexical,  
  Pronunciation  
}  
```  
  
```csharp  
internal static string stringFromWordArray(  
         ReadOnlyCollection<RecognizedWordUnit> words,   
         WordType type)   
{  
  string text = "";  
  foreach (RecognizedWordUnit word in words)   
  {  
    string wordText = "";  
    if (type == WordType.Text || type == WordType.Normalized)   
    {  
      wordText = word.Text;  
    }   
    else if (type == WordType.Lexical)   
    {  
      wordText = word.LexicalForm;  
    }   
    else if (type == WordType.Pronunciation)   
    {  
      wordText = word.Pronunciation;  
    }   
    else   
    {  
      throw new InvalidEnumArgumentException(  
          String.Format("[0}: is not a valid input", type));  
    }  
  
    // Use display attribute  
    if ((word.DisplayAttributes & DisplayAttributes.OneTrailingSpace) != 0)   
    {  
      wordText += " ";  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.TwoTrailingSpaces) != 0)  
    {  
      wordText += "  ";  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.ConsumeLeadingSpaces) != 0)   
    {  
      wordText = wordText.TrimStart();  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.ZeroTrailingSpaces) != 0)  
    {  
    wordText = wordText.TrimEnd();  
    }  
  
    text += wordText;  
  
  }  
  return text;  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.DisplayAttributes" />
      </Docs>
    </Member>
    <Member MemberName="Pronunciation">
      <MemberSignature Language="C#" Value="public string Pronunciation { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance string Pronunciation" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedWordUnit.Pronunciation" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Pronunciation As String" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::String ^ Pronunciation { System::String ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.Pronunciation : string" Usage="System.Speech.Recognition.RecognizedWordUnit.Pronunciation" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>get: System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.String</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Ruft die Lautrechtschreibung eines erkannten Worts ab.</summary>
        <value>Eine Zeichenfolge von einem unterstützten Lautalphabet, wie dem internationalen Lautalphabet (IPA) oder dem universellen Sprachlautsatz (UPS).</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Der Inhalt des <xref:System.Speech.Recognition.RecognizedWordUnit.Pronunciation%2A> geben die Aussprache der spracherkennungs-Engine verwendet die Spracheingabe in eines seiner geladenen <xref:System.Speech.Recognition.Grammar> Objekte. Aussprache können definiert werden, in das Spracherkennungsmodul im internen Lexikon vorhanden, in ein Lexikon-Dokument, das über eine Grammatik für die Erkennung einer geladenen verlinkt sind <xref:System.Speech.Recognition.Grammar> Objekt oder Inline in einer Grammatik Erkennung einer geladenen <xref:System.Speech.Recognition.Grammar> Objekt. Eine spracherkennungs-Engine erstellt auch möglicherweise die Aussprache für ungewöhnlich, dass Wörter, deren Aussprache nicht definiert sind, in ein Lexikon oder Grammatik, die auf die die spracherkennungs-Engine derzeit Zugriff hat.  
  
 Viele Windows-basierten Unicode-Schriftarten, z. B. Courier New, unterstützen die Anzeige der IPA-Zeichenfolgen. Weitere Informationen finden Sie unter [internationalen Lautalphabet](http://go.microsoft.com/fwlink/?LinkId=58363).  
  
   
  
## Examples  
 Das folgende Beispiel zeigt eine Hilfsprogramm-Routine, die eine Zeichenfolge mit einem der drei möglichen Formate generiert: lexikalische (mit <xref:System.Speech.Recognition.RecognizedWordUnit.LexicalForm%2A>), normalisierte (mit <xref:System.Speech.Recognition.RecognizedWordUnit.Text%2A>), und phonetische (mit <xref:System.Speech.Recognition.RecognizedWordUnit.Pronunciation%2A>). Die Textausgabe aus einer eine <xref:System.Collections.ObjectModel.ReadOnlyCollection%601> von <xref:System.Speech.Recognition.RecognizedWordUnit> -Objekte, die aus abgerufen werden die <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> Eigenschaft für die <xref:System.Speech.Recognition.RecognizedPhrase> Objekt.  
  
```csharp  
  
internal enum WordType   
{  
  Text,  
  Normalized = Text,  
  Lexical,  
  Pronunciation  
}  
```  
  
```csharp  
internal static string stringFromWordArray(  
          ReadOnlyCollection<RecognizedWordUnit> words,   
          WordType type)   
{  
  string text = "";  
  foreach (RecognizedWordUnit word in words)   
  {  
    string wordText = "";  
    if (type == WordType.Text || type == WordType.Normalized)   
    {  
      wordText = word.Text;  
    }   
    else if (type == WordType.Lexical)   
    {  
      wordText = word.LexicalForm;  
    }   
    else if (type == WordType.Pronunciation)   
    {  
      wordText = word.Pronunciation;  
    }   
    else   
    {  
      throw new InvalidEnumArgumentException(  
          String.Format("[0}: is not a valid input", type));  
    }  
    // Use display attribute  
  
    if ((word.DisplayAttributes & DisplayAttributes.OneTrailingSpace) != 0)   
    {  
      wordText += " ";  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.TwoTrailingSpaces) != 0)   
    {  
      wordText += "  ";  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.ConsumeLeadingSpaces) != 0)   
    {  
      wordText = wordText.TrimStart();  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.ZeroTrailingSpaces) != 0)   
    {  
      wordText = wordText.TrimEnd();  
    }  
  
    text += wordText;  
  }  
  return text;  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.DisplayAttributes" />
        <related type="ExternalDocumentation" href="http://go.microsoft.com/fwlink/?LinkId=58363">Internationalen Lautalphabet</related>
      </Docs>
    </Member>
    <Member MemberName="Text">
      <MemberSignature Language="C#" Value="public string Text { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance string Text" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedWordUnit.Text" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Text As String" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::String ^ Text { System::String ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.Text : string" Usage="System.Speech.Recognition.RecognizedWordUnit.Text" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>get: System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.String</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Ruft den normalisierten Text für ein erkanntes Wort ab.</summary>
        <value>Eine Zeichenfolge, die die normalisierte Textausgabe für ein angegebenes Eingabewort enthält.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 In den meisten Fällen die Rückgabewerte <xref:System.Speech.Recognition.RecognizedWordUnit.Text%2A> und <xref:System.Speech.Recognition.RecognizedWordUnit.LexicalForm%2A> identisch. Allerdings können Erkennungsmodule Spracherkennung Normalisierung verwenden, mehr benutzerfreundliche oder Umgangssprachlich Textdarstellungen der Audioeingabe zurückgegeben.  
  
 Normalisierung der Sprache ist die Verwendung von sonderkonstrukte oder Symbole zum Sprache im Schreiben von Ausdrücken. Beispielsweise kann Normalisierung der gesprochenen Worte "einen Dollar und sechzehn Cent" mit "$1.16" in der Output-Text ersetzen.  
  
   
  
## Examples  
 Das folgende Beispiel zeigt eine Hilfsprogramm-Routine, die eine Zeichenfolge in einem der drei Formate generiert: lexikalische (mit <xref:System.Speech.Recognition.RecognizedWordUnit.LexicalForm%2A>), normalisierte (mit <xref:System.Speech.Recognition.RecognizedWordUnit.Text%2A>), und phonetische (mit <xref:System.Speech.Recognition.RecognizedWordUnit.Pronunciation%2A>). Die Textausgabe aus einer eine <xref:System.Collections.ObjectModel.ReadOnlyCollection%601> von <xref:System.Speech.Recognition.RecognizedWordUnit> -Objekte, die aus abgerufen werden die <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> Eigenschaft für die <xref:System.Speech.Recognition.RecognizedPhrase> Objekt.  
  
```csharp  
  
internal enum WordType   
{  
  Text,  
  Normalized = Text,  
  Lexical,  
  Pronunciation  
}  
```  
  
```csharp  
internal static string stringFromWordArray(  
          ReadOnlyCollection<RecognizedWordUnit> words,   
          WordType type)   
{  
  string text = "";  
  foreach (RecognizedWordUnit word in words)   
  {  
    string wordText = "";  
    if (type == WordType.Text || type == WordType.Normalized)   
    {  
      wordText = word.Text;  
    }   
    else if (type == WordType.Lexical)   
    {  
      wordText = word.LexicalForm;  
    }   
    else if (type == WordType.Pronunciation)   
    {  
      wordText = word.Pronunciation;  
    }   
    else   
    {  
      throw new InvalidEnumArgumentException(  
           String.Format("[0}: is not a valid input", type));  
    }  
  
    // Use display attribute  
    if ((word.DisplayAttributes & DisplayAttributes.OneTrailingSpace) != 0)   
    {  
      wordText += " ";  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.TwoTrailingSpaces) != 0)   
    {  
      wordText += "  ";  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.ConsumeLeadingSpaces) != 0)   
    {  
      wordText = wordText.TrimStart();  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.ZeroTrailingSpaces) != 0)   
    {  
      wordText = wordText.TrimEnd();  
    }  
  
    text += wordText;  
  
  }  
  return text;  
}  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
  </Members>
</Type>