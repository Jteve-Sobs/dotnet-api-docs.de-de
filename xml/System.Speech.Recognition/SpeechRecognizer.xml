<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" version="1.2" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="SpeechRecognizer.xml" source-language="en-US" target-language="de-DE">
    <header>
      <tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-15c36f0" tool-company="Microsoft" />
      <xliffext:skl_file_name xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">02cd5861-7ce2-4a82-b358-31f8435a0ac5bc77257cd77c3fc2c078698df4cc6e968d3bf09a.skl</xliffext:skl_file_name>
      <xliffext:version xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">1.2</xliffext:version>
      <xliffext:ms.openlocfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">bc77257cd77c3fc2c078698df4cc6e968d3bf09a</xliffext:ms.openlocfilehash>
      <xliffext:ms.sourcegitcommit xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">d31dc2ede16f6f7bc64e90d9f897ff54c4e3869b</xliffext:ms.sourcegitcommit>
      <xliffext:ms.lasthandoff xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">04/03/2018</xliffext:ms.lasthandoff>
      <xliffext:moniker_ids xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">netframework-4.5.1,netframework-4.5.2,netframework-4.5,netframework-4.6.1,netframework-4.6.2,netframework-4.6,netframework-4.7.1,netframework-4.7</xliffext:moniker_ids>
    </header>
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>Provides access to the shared speech recognition service available on the Windows desktop.</source>
          <target state="translated">Bietet Zugriff auf den freigegebenen Spracherkennungsdienst, der auf dem Windows-Desktop verfügbar ist.</target>       </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>Applications use the shared recognizer to access Windows Speech Recognition.</source>
          <target state="translated">Anwendungen verwenden freigegebene Erkennungsmodul für Windows-Spracherkennung zugreifen.</target>       </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>Use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> object to add to the Windows speech user experience.</source>
          <target state="translated">Verwenden der <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> Objekt, für die Benutzeroberfläche der Windows-Sprache hinzugefügt werden.</target>       </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>This class provides control over various aspects of the speech recognition process:</source>
          <target state="translated">Diese Klasse stellt die Kontrolle über verschiedene Aspekte des Prozesses Recognition Spracherkennung bereit:</target>       </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>To manage speech recognition grammars, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A&gt;</ph>, <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A&gt;</ph>, and <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A&gt;</ph>.</source>
          <target state="translated">Verwenden Sie zum Verwalten der Sprache Recognition Grammatiken der <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A&gt;</ph>, <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A&gt;</ph>, und <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>To get information about current speech recognition operations, subscribe to the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>’s <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph>, <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph>, and <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> events.</source>
          <target state="translated">Zum Abrufen von Informationen über aktuelle Sprache Erkennungsvorgänge Abonnieren der <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>des <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph>, <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph>, und <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> Ereignisse.</target>       </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>To view or modify the number of alternate results the recognizer returns, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.MaxAlternates%2A&gt;</ph> property.</source>
          <target state="translated">Verwenden Sie zum Anzeigen oder ändern die Anzahl der alternativen Ergebnisse, die die Erkennung gibt zurück, die <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.MaxAlternates%2A&gt;</ph> Eigenschaft.</target>       </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The recognizer returns recognition results in a <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object.</source>
          <target state="translated">Das Erkennungsmodul gibt Ergebnisse in einem <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> Objekt.</target>       </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>To access or monitor the state of the shared recognizer, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A&gt;</ph>, <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</ph>, <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A&gt;</ph>, <ph id="ph6">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph>, and <ph id="ph7">&lt;xref:System.Speech.Recognition.SpeechRecognizer.State%2A&gt;</ph> properties and the <ph id="ph8">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated&gt;</ph>, <ph id="ph9">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred&gt;</ph>, <ph id="ph10">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged&gt;</ph>, and <ph id="ph11">&lt;xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt;</ph> events.</source>
          <target state="translated">Um zugreifen, oder Überwachen des Status von freigegebenen Erkennungsmodul, verwenden die <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A&gt;</ph>, <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</ph>, <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A&gt;</ph>, <ph id="ph6">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph>, und <ph id="ph7">&lt;xref:System.Speech.Recognition.SpeechRecognizer.State%2A&gt;</ph> Eigenschaften und die <ph id="ph8">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated&gt;</ph>, <ph id="ph9">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred&gt;</ph>, <ph id="ph10">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged&gt;</ph>, und <ph id="ph11">&lt;xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt;</ph> Ereignisse.</target>       </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>To synchronize changes to the recognizer, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> method.</source>
          <target state="translated">Verwenden Sie zum Synchronisieren der Änderungen an die Erkennung der <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> Methode.</target>       </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The shared recognizer uses more than one thread to perform tasks.</source>
          <target state="translated">Das freigegebene Erkennungsmodul verwendet mehrere Threads, um Aufgaben auszuführen.</target>       </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>To emulate input to the shared recognizer, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> methods.</source>
          <target state="translated">Zum Emulieren der Eingabe für das freigegebene Erkennungsmodul verwenden die <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A&gt;</ph> und <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> Methoden.</target>       </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The configuration of Windows Speech Recognition is managed by the use of the <bpt id="p1">**</bpt>Speech Properties<ept id="p1">**</ept> dialog in the <bpt id="p2">**</bpt>Control Panel<ept id="p2">**</ept>.</source>
          <target state="translated">Die Konfiguration der Windows-Spracherkennung wird durch die Verwendung von verwaltet die <bpt id="p1">**</bpt>Spracheigenschaften<ept id="p1">**</ept> Dialogfeld in der <bpt id="p2">**</bpt>Systemsteuerung<ept id="p2">**</ept>.</target>       </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>This interface is used to select the default desktop speech recognition engine and language, the audio input device, and the sleep behavior of speech recognition.</source>
          <target state="translated">Diese Schnittstelle wird verwendet, um desktop-Spracherkennungsmoduls Standard und Sprache, die Audioeingabegeräts und das Verhalten dem Standbymodus Spracherkennung auszuwählen.</target>       </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>If the configuration of Windows Speech Recognition is changed while the application is running, (for instance, if speech recognition is disabled or the input language is changed), the change affects all <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> objects.</source>
          <target state="translated">Wenn die Konfiguration der Windows-Spracherkennung geändert wird, während die Anwendung ausgeführt wird, (z. B. wenn die Spracherkennung deaktiviert ist, oder die Eingabesprache geändert wird), die Änderung wirkt sich auf alle <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> Objekte.</target>       </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>To create an in-process speech recognizer that is independent of Windows Speech Recognition, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> class.</source>
          <target state="translated">Verwenden Sie zum Erstellen, die unabhängig von der Windows-Spracherkennung ist ein in-Process-Spracherkennung der <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> Klasse.</target>       </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>Always call <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Dispose%2A&gt;</ph> before you release your last reference to the speech recognizer.</source>
          <target state="translated">Rufen Sie immer <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Dispose%2A&gt;</ph> , bevor Sie den letzten Verweis auf die von der Spracherkennung freigeben.</target>       </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>Otherwise, the resources it is using will not be freed until the garbage collector calls the recognizer object's <ph id="ph1">`Finalize`</ph> method.</source>
          <target state="translated">Andernfalls werden die verwendeten Ressourcen werden nicht reserviert, bis der Garbage Collector des Erkennungsmodul-Objekts aufruft <ph id="ph1">`Finalize`</ph> Methode.</target>       </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer.</source>
          <target state="translated">Im folgende Beispiel ist Teil einer Konsolenanwendung, die lädt eine Spracherkennung Recognition Grammatik und asynchrone emulierten Eingabe, die zugeordneten Erkennungsergebnisse und die zugehörigen Ereignisse ausgelöst, die für die von der Spracherkennung veranschaulicht.</target>       </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.</source>
          <target state="translated">Wenn Windows-Spracherkennung nicht ausgeführt wird, wird Windows-Spracherkennung starten Sie dann auf diese Anwendung auch gestartet.</target>       </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>If Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state, then <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> always returns null.</source>
          <target state="translated">Wenn Windows die Spracherkennung in ist die <bpt id="p1">**</bpt>im Standbymodus<ept id="p1">**</ept> Zustand befindet, klicken Sie dann <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> gibt immer null zurück.</target>       </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.#ctor">
          <source>Initializes a new instance of the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> class.</source>
          <target state="translated">Initialisiert eine neue Instanz der <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph>-Klasse.</target>       </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.#ctor">
          <source>Each <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> object maintains a separate set of speech recognition grammars.</source>
          <target state="translated">Jede <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> -Objekt verwaltet einen separaten Satz von Spracherkennung Recognition Grammatiken.</target>       </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.#ctor">
          <source>The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer.</source>
          <target state="translated">Im folgende Beispiel ist Teil einer Konsolenanwendung, die lädt eine Spracherkennung Recognition Grammatik und asynchrone emulierten Eingabe, die zugeordneten Erkennungsergebnisse und die zugehörigen Ereignisse ausgelöst, die für die von der Spracherkennung veranschaulicht.</target>       </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.#ctor">
          <source>If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.</source>
          <target state="translated">Wenn Windows-Spracherkennung nicht ausgeführt wird, wird Windows-Spracherkennung starten Sie dann auf diese Anwendung auch gestartet.</target>       </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.#ctor">
          <source>If Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state, then <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> always returns null.</source>
          <target state="translated">Wenn Windows die Spracherkennung in ist die <bpt id="p1">**</bpt>im Standbymodus<ept id="p1">**</ept> Zustand befindet, klicken Sie dann <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> gibt immer null zurück.</target>       </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioFormat">
          <source>Gets the format of the audio being received by the speech recognizer.</source>
          <target state="translated">Ruft das Audioformat ab, das von der Spracherkennung empfangen wird.</target>       </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioFormat">
          <source>The audio input format for the speech recognizer, or <ph id="ph1">&lt;see langword="null" /&gt;</ph> if the input to the recognizer is not configured.</source>
          <target state="translated">Das Audioeingabeformat für die Spracherkennung oder die <ph id="ph1">&lt;see langword="null" /&gt;</ph>, wenn die Eingabe für die Erkennung nicht konfiguriert ist.</target>       </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioLevel">
          <source>Gets the level of the audio being received by the speech recognizer.</source>
          <target state="translated">Ruft den Level des Audiosignals ab, das von der Spracherkennung empfangen wird.</target>       </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioLevel">
          <source>The audio level of the input to the speech recognizer, from 0 through 100.</source>
          <target state="translated">Der Audiopegel der Eingabe an die Spracherkennung, von 0 bis 100.</target>       </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>Occurs when the shared recognizer reports the level of its audio input.</source>
          <target state="translated">Tritt auf, wenn die freigegebene Erkennung die Ebene ihrer Audioeingabe meldet.</target>       </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>The recognizer raises this event multiple times per second.</source>
          <target state="translated">Das Erkennungsmodul löst dieses Ereignis mehrere Male pro Sekunde.</target>       </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>The frequency with which the event is raised depends on the computer on which the application is running.</source>
          <target state="translated">Die Häufigkeit, mit der das Ereignis ausgelöst wird, hängt von dem Computer, auf dem die Anwendung ausgeführt wird.</target>       </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>To get the audio level at the time of the event, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs.AudioLevel%2A&gt;</ph> property of the associated <ph id="ph2">&lt;xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt;</ph>.</source>
          <target state="translated">Verwenden Sie zum Abrufen der audio Ebene zum Zeitpunkt des Ereignisses die <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs.AudioLevel%2A&gt;</ph> Eigenschaft der zugeordneten <ph id="ph2">&lt;xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>To get the current audio level of the input to the recognizer, use the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A&gt;</ph> property.</source>
          <target state="translated">Um die aktuelle audio Ebene der Eingabe für die Erkennung zu erhalten, verwenden Sie der Erkennung <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A&gt;</ph> Eigenschaft.</target>       </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>When you create a delegate for an <ph id="ph1">`AudioLevelUpdated`</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">Beim Erstellen eines Delegaten für ein <ph id="ph1">`AudioLevelUpdated`</ph> Ereignis, bestimmen Sie die Methode für die Ereignisbehandlung.</target>       </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Um dem Ereignishandler das Ereignis zuzuordnen, fügen Sie dem Ereignis eine Instanz des Delegaten hinzu.</target>       </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Der Ereignishandler wird bei jedem Eintreten des Ereignisses aufgerufen, sofern der Delegat nicht entfernt wird.</target>       </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Weitere Informationen über Delegaten für Ereignishandler finden Sie unter <bpt id="p1">[</bpt>Ereignissen und Delegaten<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>The following example adds a handler for the <ph id="ph1">`AudioLevelUpdated`</ph> event to a <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> object.</source>
          <target state="translated">Das folgende Beispiel fügt einen Handler für das <ph id="ph1">`AudioLevelUpdated`</ph> Ereignis, um eine <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> Objekt.</target>       </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>The handler outputs the new audio level to the console.</source>
          <target state="translated">Der Handler gibt die neue audio Ebene in der Konsole aus.</target>       </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition">
          <source>Gets the current location in the audio stream being generated by the device that is providing input to the speech recognizer.</source>
          <target state="translated">Ruft die aktuelle Position im Audiostream ab, die durch das Gerät generiert wird, das die Spracherkennung mit Eingaben versorgt.</target>       </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition">
          <source>The current location in the speech recognizer's audio input stream through which it has received input.</source>
          <target state="translated">Die aktuelle Position im Audioeingabestream der Spracherkennung, durch den die Eingabe empfangen wurde.</target>       </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition">
          <source>The shared recognizer receives input while the desktop speech recognition is running.</source>
          <target state="translated">Das freigegebene Erkennungsmodul empfängt Eingaben während der desktop Spracherkennung ausgeführt wird.</target>       </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition">
          <source>The <ph id="ph1">`AudioPosition`</ph> property references the input device's position in its generated audio stream.</source>
          <target state="translated">Die <ph id="ph1">`AudioPosition`</ph> -Eigenschaft verweist auf das Eingabegerät Position in der generierten Audiostream.</target>       </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition">
          <source>By contrast, the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> property references the recognizer's position in processing audio input.</source>
          <target state="translated">Im Gegensatz dazu, die <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> Eigenschaft verweist auf die Erkennung Position bei der Verarbeitung der Audioeingabe.</target>       </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition">
          <source>These positions can be different.</source>
          <target state="translated">Diese Positionen können unterschiedlich sein.</target>       </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition">
          <source>For example, if the recognizer has received input for which it has not yet generated a recognition result then the value of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> property is less than the value of the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> property.</source>
          <target state="translated">Z. B. wenn die Erkennung erhalten hat Eingabe nicht für die It hat noch erzeugt ein Erkennungsergebnis wird der Wert der die <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> -Eigenschaft muss kleiner als der Wert von der <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> Eigenschaft.</target>       </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition">
          <source>In the following example, the shared speech recognizer uses a dictation grammar to match speech input.</source>
          <target state="translated">Im folgenden Beispiel verwendet die freigegebenen von der Spracherkennung diktieren Grammatik Spracheingabe entsprechend an.</target>       </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition">
          <source>A handler for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph> event writes to the console the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph>, and  <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A&gt;</ph> when the speech recognizer detects speech at its input.</source>
          <target state="translated">Einen Handler für das <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph> Ereignis in die Konsole schreibt die <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph>, und <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A&gt;</ph> Wenn erkennt die von der Spracherkennung Sprache bei der Eingabe.</target>       </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred">
          <source>Occurs when the recognizer encounters a problem in the audio signal.</source>
          <target state="translated">Tritt auf, wenn in der Erkennung ein Problem beim Audiosignal auftritt.</target>       </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred">
          <source>To get which problem occurred, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem%2A&gt;</ph> property of the associated <ph id="ph2">&lt;xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt;</ph>.</source>
          <target state="translated">Verwenden Sie zum Abrufen, welches Problem ist aufgetreten, der <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem%2A&gt;</ph> Eigenschaft der zugeordneten <ph id="ph2">&lt;xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred">
          <source>When you create a delegate for an <ph id="ph1">`AudioSignalProblemOccurred`</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">Beim Erstellen eines Delegaten für ein <ph id="ph1">`AudioSignalProblemOccurred`</ph> Ereignis, bestimmen Sie die Methode für die Ereignisbehandlung.</target>       </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Um dem Ereignishandler das Ereignis zuzuordnen, fügen Sie dem Ereignis eine Instanz des Delegaten hinzu.</target>       </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Der Ereignishandler wird bei jedem Eintreten des Ereignisses aufgerufen, sofern der Delegat nicht entfernt wird.</target>       </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Weitere Informationen über Delegaten für Ereignishandler finden Sie unter <bpt id="p1">[</bpt>Ereignissen und Delegaten<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred">
          <source>The following example defines an event handler that gathers information about an <ph id="ph1">`AudioSignalProblemOccurred`</ph> event.</source>
          <target state="translated">Das folgende Beispiel definiert einen Ereignishandler, die sammelt Informationen über ein <ph id="ph1">`AudioSignalProblemOccurred`</ph> Ereignis.</target>       </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioState">
          <source>Gets the state of the audio being received by the speech recognizer.</source>
          <target state="translated">Ruft den Status des von der Spracherkennung empfangenen Audiosignals ab.</target>       </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioState">
          <source>The state of the audio input to the speech recognizer.</source>
          <target state="translated">Der Zustand der Audioeingabe für die Spracherkennung.</target>       </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged">
          <source>Occurs when the state changes in the audio being received by the recognizer.</source>
          <target state="translated">Tritt bei Zustandsänderungen im Audio auf, das von der Erkennung empfangen wird.</target>       </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged">
          <source>To get the audio state at the time of the event, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState%2A&gt;</ph> property of the associated <ph id="ph2">&lt;xref:System.Speech.Recognition.AudioStateChangedEventArgs&gt;</ph>.</source>
          <target state="translated">Verwenden Sie zum Abrufen des audio Zustands zum Zeitpunkt des Ereignisses die <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState%2A&gt;</ph> Eigenschaft der zugeordneten <ph id="ph2">&lt;xref:System.Speech.Recognition.AudioStateChangedEventArgs&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged">
          <source>To get the current audio state of the input to the recognizer, use the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A&gt;</ph> property.</source>
          <target state="translated">Um den aktuellen audio-Status, der die Eingabe für die Erkennung zu erhalten, verwenden Sie der Erkennung <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A&gt;</ph> Eigenschaft.</target>       </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged">
          <source>For more information about audio state, see the <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioState&gt;</ph> enumeration.</source>
          <target state="translated">Weitere Informationen zum audio-Status finden Sie unter der <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioState&gt;</ph> Enumeration.</target>       </trans-unit>
        <trans-unit id="164" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged">
          <source>When you create a delegate for an <ph id="ph1">`AudioStateChanged`</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">Beim Erstellen eines Delegaten für ein <ph id="ph1">`AudioStateChanged`</ph> Ereignis, bestimmen Sie die Methode für die Ereignisbehandlung.</target>       </trans-unit>
        <trans-unit id="165" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Um dem Ereignishandler das Ereignis zuzuordnen, fügen Sie dem Ereignis eine Instanz des Delegaten hinzu.</target>       </trans-unit>
        <trans-unit id="166" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Der Ereignishandler wird bei jedem Eintreten des Ereignisses aufgerufen, sofern der Delegat nicht entfernt wird.</target>       </trans-unit>
        <trans-unit id="167" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Weitere Informationen über Delegaten für Ereignishandler finden Sie unter <bpt id="p1">[</bpt>Ereignissen und Delegaten<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="168" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged">
          <source>The following example uses a handler for the <ph id="ph1">`AudioStateChanged`</ph> event to write the recognizer's new <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A&gt;</ph> to the console each time it changes using a member of the <ph id="ph3">&lt;xref:System.Speech.Recognition.AudioState&gt;</ph> enumeration.</source>
          <target state="translated">Im folgenden Beispiel wird einen Handler für das <ph id="ph1">`AudioStateChanged`</ph> Ereignis, um die Erkennung Schreiben des neuen <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A&gt;</ph> an die Konsole jedes Mal, wenn sie Änderungen mithilfe eines Members der <ph id="ph3">&lt;xref:System.Speech.Recognition.AudioState&gt;</ph> Enumeration.</target>       </trans-unit>
        <trans-unit id="169" translate="yes" xml:space="preserve" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>Disposes the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> object.</source>
          <target state="translated">Gibt das <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph>-Objekt frei.</target>       </trans-unit>
        <trans-unit id="170" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.Dispose">
          <source>Disposes the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> object.</source>
          <target state="translated">Gibt das <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph>-Objekt frei.</target>       </trans-unit>
        <trans-unit id="171" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.Dispose(System.Boolean)">
          <source><ph id="ph1">&lt;see langword="true" /&gt;</ph> to release both managed and unmanaged resources; <ph id="ph2">&lt;see langword="false" /&gt;</ph> to release only unmanaged resources.</source>
          <target state="translated"><ph id="ph1">&lt;see langword="true" /&gt;</ph>, um sowohl verwaltete als auch nicht verwaltete Ressourcen freizugeben, <ph id="ph2">&lt;see langword="false" /&gt;</ph>, um ausschließlich nicht verwaltete Ressourcen freizugeben.</target>       </trans-unit>
        <trans-unit id="172" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.Dispose(System.Boolean)">
          <source>Disposes the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> object and releases resources used during the session.</source>
          <target state="translated">Verwirft das <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph>-Objekt und gibt Ressourcen frei, die während der Sitzung verwendet werden.</target>       </trans-unit>
        <trans-unit id="173" translate="yes" xml:space="preserve" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>Emulates input to the shared speech recognizer, using text instead of audio for synchronous speech recognition.</source>
          <target state="translated">Emuliert die Eingabe für die freigegebene Spracherkennung. Dabei wird Text statt Audio für die synchrone Spracherkennung verwendet.</target>       </trans-unit>
        <trans-unit id="174" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>These methods bypass the system audio input.</source>
          <target state="translated">Diese Methoden umgehen der System-Audioeingabe.</target>       </trans-unit>
        <trans-unit id="175" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>This can be helpful when you are testing or debugging an application or grammar.</source>
          <target state="translated">Dies kann hilfreich sein, wenn Sie testen oder Debuggen einer Anwendung oder Grammatik.</target>       </trans-unit>
        <trans-unit id="176" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>If Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state, then these methods return <ph id="ph1">`null`</ph>.</source>
          <target state="translated">Wenn Windows die Spracherkennung in ist die <bpt id="p1">**</bpt>im Standbymodus<ept id="p1">**</ept> Zustand befindet, und klicken Sie dann diese Methoden geben <ph id="ph1">`null`</ph>.</target>       </trans-unit>
        <trans-unit id="177" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The shared recognizer raises the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph>, and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> events as if the recognition operation is not emulated.</source>
          <target state="translated">Der freigegebene Erkennungsmodul löst die <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph>, und <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> Ereignisse wie bei der Erkennungsvorgang nicht emuliert wird.</target>       </trans-unit>
        <trans-unit id="178" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The recognizer ignores new lines and extra white space and treats punctuation as literal input.</source>
          <target state="translated">Das Erkennungsmodul neue Zeilen und zusätzlichen Leerraum ignoriert und Interpunktion als literal Eingabe behandelt.</target>       </trans-unit>
        <trans-unit id="179" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object generated by the shared recognizer in response to emulated input has a value of <ph id="ph2">`null`</ph> for its <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult.Audio%2A&gt;</ph> property.</source>
          <target state="translated">Die <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> Objekt, durch die gemeinsame Erkennung als Antwort auf "emuliert" Eingabe generiert hat den Wert der <ph id="ph2">`null`</ph> für seine <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult.Audio%2A&gt;</ph> Eigenschaft.</target>       </trans-unit>
        <trans-unit id="180" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>To emulate asynchronous recognition, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> method.</source>
          <target state="translated">Zum Emulieren der asynchronen Recognition verwenden die <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> Methode.</target>       </trans-unit>
        <trans-unit id="181" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)">
          <source>The input for the recognition operation.</source>
          <target state="translated">Die Eingabe für den Erkennungsvorgang.</target>       </trans-unit>
        <trans-unit id="182" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)">
          <source>Emulates input of a phrase to the shared speech recognizer, using text instead of audio for synchronous speech recognition.</source>
          <target state="translated">Emuliert die Eingabe eines Ausdrucks für die freigegebene Spracherkennung. Dabei wird Text statt Audio für die synchrone Spracherkennung verwendet.</target>       </trans-unit>
        <trans-unit id="183" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)">
          <source>The recognition result for the recognition operation, or <ph id="ph1">&lt;see langword="null" /&gt;</ph>, if the operation is not successful or Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state.</source>
          <target state="translated">Das Erkennungsergebnis des Erkennungsvorgangs oder <ph id="ph1">&lt;see langword="null" /&gt;</ph>, wenn der Vorgang nicht erfolgreich war oder wenn sich die Windows-Spracherkennung im <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept>-Zustand befindet.</target>       </trans-unit>
        <trans-unit id="184" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)">
          <source>The recognizers that ship with Vista and Windows 7 ignore case and character width when applying grammar rules to the input phrase.</source>
          <target state="translated">Die Merkmale, die mit Vista und Windows 7 ausgeliefert Groß-/Kleinschreibung ignorieren und Breite Zeichen, beim Anwenden der Grammatikregeln für den auf der input-Ausdruck.</target>       </trans-unit>
        <trans-unit id="185" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)">
          <source>For more information about this type of comparison, see the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumeration values <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> and <ph id="ph3">&lt;xref:System.Globalization.CompareOptions.IgnoreWidth&gt;</ph>.</source>
          <target state="translated">Weitere Informationen über diese Art von Vergleich finden Sie unter der <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> Enumerationswerte <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> und <ph id="ph3">&lt;xref:System.Globalization.CompareOptions.IgnoreWidth&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="186" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)">
          <source>The recognizers also ignore new lines and extra white space and treat punctuation as literal input.</source>
          <target state="translated">Der Prüfer ist außerdem neue Zeilen und zusätzlichen Leerraum zu ignorieren und Interpunktion als literal Eingabe behandelt.</target>       </trans-unit>
        <trans-unit id="187" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)">
          <source>The following example loads a sample grammar to the shared recognizer and emulates input to the recognizer.</source>
          <target state="translated">Im folgenden Beispiel lädt eine Beispiel-Grammatik an die freigegebene Erkennung und Eingabe für die Erkennung emuliert.</target>       </trans-unit>
        <trans-unit id="188" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)">
          <source>If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.</source>
          <target state="translated">Wenn Windows-Spracherkennung nicht ausgeführt wird, wird Windows-Spracherkennung starten Sie dann auf diese Anwendung auch gestartet.</target>       </trans-unit>
        <trans-unit id="189" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)">
          <source>If Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state, then <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A&gt;</ph> always returns null.</source>
          <target state="translated">Wenn Windows die Spracherkennung in ist die <bpt id="p1">**</bpt>im Standbymodus<ept id="p1">**</ept> Zustand befindet, klicken Sie dann <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A&gt;</ph> gibt immer null zurück.</target>       </trans-unit>
        <trans-unit id="190" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>An array of word units that contains the input for the recognition operation.</source>
          <target state="translated">Ein Array von Worteinheiten, das die Eingabe für den Erkennungsvorgang enthält.</target>       </trans-unit>
        <trans-unit id="191" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</source>
          <target state="translated">Eine bitweise Kombination der Enumerationswerte, die den Typ des Vergleichs beschreiben, der für den emulierten Erkennungsvorgang verwendet wird.</target>       </trans-unit>
        <trans-unit id="192" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>Emulates input of specific words to the shared speech recognizer, using text instead of audio for synchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the words and the loaded speech recognition grammars.</source>
          <target state="translated">Emuliert die Eingabe bestimmter Wörter für die freigegebene Spracherkennung. Dabei wird Text statt Audio für die synchrone Spracherkennung verwendet und festgelegt, wie die Erkennung Unicode-Vergleich zwischen den Wörtern und den geladenen Spracherkennungsgrammatiken behandelt.</target>       </trans-unit>
        <trans-unit id="193" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognition result for the recognition operation, or <ph id="ph1">&lt;see langword="null" /&gt;</ph>, if the operation is not successful or Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state.</source>
          <target state="translated">Das Erkennungsergebnis des Erkennungsvorgangs oder <ph id="ph1">&lt;see langword="null" /&gt;</ph>, wenn der Vorgang nicht erfolgreich war oder wenn sich die Windows-Spracherkennung im <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept>-Zustand befindet.</target>       </trans-unit>
        <trans-unit id="194" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>This method creates a <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object using the information provided in the <ph id="ph2">`wordUnits`</ph> parameter.</source>
          <target state="translated">Diese Methode erstellt eine <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> -Objekt mit den Angaben in der <ph id="ph2">`wordUnits`</ph> Parameter.</target>       </trans-unit>
        <trans-unit id="195" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizer uses the <ph id="ph1">`compareOptions`</ph> when it applies grammar rules to the input phrase.</source>
          <target state="translated">Das Erkennungsmodul verwendet die <ph id="ph1">`compareOptions`</ph> Wenn der input-Ausdruck als Grammatikregeln anwendet.</target>       </trans-unit>
        <trans-unit id="196" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizers that ship with Vista and Windows 7 ignore case if the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> or <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> value is present.</source>
          <target state="translated">Die Merkmale, die mit Vista und Windows 7 ausgeliefert Groß-/Kleinschreibung ignorieren, wenn die <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> oder <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> Wert vorhanden ist.</target>       </trans-unit>
        <trans-unit id="197" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizers always ignore the character width and never ignore the Kana type.</source>
          <target state="translated">Der Prüfer immer die Zeichenbreite ignoriert und nie den Kanatyp ignorieren.</target>       </trans-unit>
        <trans-unit id="198" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizers also ignore new lines and extra white space and treats punctuation as literal input.</source>
          <target state="translated">Der Prüfer ist außerdem neue Zeilen und zusätzlichen Leerraum zu ignorieren und Interpunktion als literal Eingabe behandelt.</target>       </trans-unit>
        <trans-unit id="199" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>For more information about character width and Kana type, see the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumeration.</source>
          <target state="translated">Weitere Informationen zu der Zeichenbreite und Kanatyp, finden Sie unter der <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> Enumeration.</target>       </trans-unit>
        <trans-unit id="200" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>The input phrase for the recognition operation.</source>
          <target state="translated">Der Eingabebegriff für den Erkennungsvorgang.</target>       </trans-unit>
        <trans-unit id="201" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</source>
          <target state="translated">Eine bitweise Kombination der Enumerationswerte, die den Typ des Vergleichs beschreiben, der für den emulierten Erkennungsvorgang verwendet wird.</target>       </trans-unit>
        <trans-unit id="202" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>Emulates input of a phrase to the shared speech recognizer, using text instead of audio for synchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the phrase and the loaded speech recognition grammars.</source>
          <target state="translated">Emuliert die Eingabe eines Ausdrucks für die freigegebene Spracherkennung. Dabei wird Text statt Audio für die synchrone Spracherkennung verwendet und festgelegt, wie die Erkennung Unicode-Vergleich zwischen dem Ausdruck und den geladenen Spracherkennungsgrammatiken behandelt.</target>       </trans-unit>
        <trans-unit id="203" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>The recognition result for the recognition operation, or <ph id="ph1">&lt;see langword="null" /&gt;</ph>, if the operation is not successful or Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state.</source>
          <target state="translated">Das Erkennungsergebnis des Erkennungsvorgangs oder <ph id="ph1">&lt;see langword="null" /&gt;</ph>, wenn der Vorgang nicht erfolgreich war oder wenn sich die Windows-Spracherkennung im <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept>-Zustand befindet.</target>       </trans-unit>
        <trans-unit id="204" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>The recognizer uses the <ph id="ph1">`compareOptions`</ph> when it applies grammar rules to the input phrase.</source>
          <target state="translated">Das Erkennungsmodul verwendet die <ph id="ph1">`compareOptions`</ph> Wenn der input-Ausdruck als Grammatikregeln anwendet.</target>       </trans-unit>
        <trans-unit id="205" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>The recognizers that ship with Vista and Windows 7 ignore case if the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> or <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> value is present.</source>
          <target state="translated">Die Merkmale, die mit Vista und Windows 7 ausgeliefert Groß-/Kleinschreibung ignorieren, wenn die <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> oder <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> Wert vorhanden ist.</target>       </trans-unit>
        <trans-unit id="206" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>The recognizers always ignore the character width and never ignore the Kana type.</source>
          <target state="translated">Der Prüfer immer die Zeichenbreite ignoriert und nie den Kanatyp ignorieren.</target>       </trans-unit>
        <trans-unit id="207" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>The recognizers also ignore new lines and extra white space and treats punctuation as literal input.</source>
          <target state="translated">Der Prüfer ist außerdem neue Zeilen und zusätzlichen Leerraum zu ignorieren und Interpunktion als literal Eingabe behandelt.</target>       </trans-unit>
        <trans-unit id="208" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>For more information about character width and Kana type, see the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumeration.</source>
          <target state="translated">Weitere Informationen zu der Zeichenbreite und Kanatyp, finden Sie unter der <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> Enumeration.</target>       </trans-unit>
        <trans-unit id="209" translate="yes" xml:space="preserve" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>Emulates input to the shared speech recognizer, using text instead of audio for asynchronous speech recognition.</source>
          <target state="translated">Emuliert die Eingabe für die freigegebene Spracherkennung. Dabei wird Text statt Audio für die asynchrone Spracherkennung verwendet.</target>       </trans-unit>
        <trans-unit id="210" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>These methods bypass the system audio input.</source>
          <target state="translated">Diese Methoden umgehen der System-Audioeingabe.</target>       </trans-unit>
        <trans-unit id="211" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>This can be helpful when you are testing or debugging an application or grammar.</source>
          <target state="translated">Dies kann hilfreich sein, wenn Sie testen oder Debuggen einer Anwendung oder Grammatik.</target>       </trans-unit>
        <trans-unit id="212" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The shared recognizer raises the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph>, and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> events as if the recognition operation is not emulated.</source>
          <target state="translated">Der freigegebene Erkennungsmodul löst die <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph>, und <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> Ereignisse wie bei der Erkennungsvorgang nicht emuliert wird.</target>       </trans-unit>
        <trans-unit id="213" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>When the recognizer completes the asynchronous recognition operation, it raises the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted&gt;</ph> event.</source>
          <target state="translated">Wenn die Erkennung der asynchronen Recognition-Vorgang abgeschlossen ist, löst die <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted&gt;</ph> Ereignis.</target>       </trans-unit>
        <trans-unit id="214" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The recognizer ignores new lines and extra white space and treats punctuation as literal input.</source>
          <target state="translated">Das Erkennungsmodul neue Zeilen und zusätzlichen Leerraum ignoriert und Interpunktion als literal Eingabe behandelt.</target>       </trans-unit>
        <trans-unit id="215" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>If Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state, then the shared recognizer does not process input and does not raise the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph> and related events, but still raises the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted&gt;</ph> event.</source>
          <target state="translated">Ist Spracherkennung Windows die <bpt id="p1">**</bpt>im Standbymodus<ept id="p1">**</ept> Zustand befindet, und klicken Sie dann das freigegebene Erkennungsmodul keine Eingabe verarbeitet und keine löst der <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph> und verwandten Ereignissen, aber dennoch löst die <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted&gt;</ph> Ereignis.</target>       </trans-unit>
        <trans-unit id="216" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object generated by the shared recognizer in response to emulated input has a value of <ph id="ph2">`null`</ph> for its <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult.Audio%2A&gt;</ph> property.</source>
          <target state="translated">Die <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> Objekt, durch die gemeinsame Erkennung als Antwort auf "emuliert" Eingabe generiert hat den Wert der <ph id="ph2">`null`</ph> für seine <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult.Audio%2A&gt;</ph> Eigenschaft.</target>       </trans-unit>
        <trans-unit id="217" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>To emulate synchronous recognition, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A&gt;</ph> method.</source>
          <target state="translated">Zum emulieren synchrone Recognition verwenden die <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A&gt;</ph> Methode.</target>       </trans-unit>
        <trans-unit id="218" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)">
          <source>The input for the recognition operation.</source>
          <target state="translated">Die Eingabe für den Erkennungsvorgang.</target>       </trans-unit>
        <trans-unit id="219" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)">
          <source>Emulates input of a phrase to the shared speech recognizer, using text instead of audio for asynchronous speech recognition.</source>
          <target state="translated">Emuliert die Eingabe eines Ausdrucks für die freigegebene Spracherkennung. Dabei wird Text statt Audio für die asynchrone Spracherkennung verwendet.</target>       </trans-unit>
        <trans-unit id="220" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)">
          <source>The recognizers that ship with Vista and Windows 7 ignore case and character width when applying grammar rules to the input phrase.</source>
          <target state="translated">Die Merkmale, die mit Vista und Windows 7 ausgeliefert Groß-/Kleinschreibung ignorieren und Breite Zeichen, beim Anwenden der Grammatikregeln für den auf der input-Ausdruck.</target>       </trans-unit>
        <trans-unit id="221" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)">
          <source>For more information about this type of comparison, see the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumeration values <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> and <ph id="ph3">&lt;xref:System.Globalization.CompareOptions.IgnoreWidth&gt;</ph>.</source>
          <target state="translated">Weitere Informationen über diese Art von Vergleich finden Sie unter der <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> Enumerationswerte <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> und <ph id="ph3">&lt;xref:System.Globalization.CompareOptions.IgnoreWidth&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="222" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)">
          <source>The recognizers also ignore new lines and extra white space and treat punctuation as literal input.</source>
          <target state="translated">Der Prüfer ist außerdem neue Zeilen und zusätzlichen Leerraum zu ignorieren und Interpunktion als literal Eingabe behandelt.</target>       </trans-unit>
        <trans-unit id="223" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)">
          <source>The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer.</source>
          <target state="translated">Im folgende Beispiel ist Teil einer Konsolenanwendung, die lädt eine Spracherkennung Recognition Grammatik und asynchrone emulierten Eingabe, die zugeordneten Erkennungsergebnisse und die zugehörigen Ereignisse ausgelöst, die für die von der Spracherkennung veranschaulicht.</target>       </trans-unit>
        <trans-unit id="224" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)">
          <source>If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.</source>
          <target state="translated">Wenn Windows-Spracherkennung nicht ausgeführt wird, wird Windows-Spracherkennung starten Sie dann auf diese Anwendung auch gestartet.</target>       </trans-unit>
        <trans-unit id="225" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)">
          <source>If Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state, then <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> always returns null.</source>
          <target state="translated">Wenn Windows die Spracherkennung in ist die <bpt id="p1">**</bpt>im Standbymodus<ept id="p1">**</ept> Zustand befindet, klicken Sie dann <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> gibt immer null zurück.</target>       </trans-unit>
        <trans-unit id="226" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>An array of word units that contains the input for the recognition operation.</source>
          <target state="translated">Ein Array von Worteinheiten, das die Eingabe für den Erkennungsvorgang enthält.</target>       </trans-unit>
        <trans-unit id="227" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</source>
          <target state="translated">Eine bitweise Kombination der Enumerationswerte, die den Typ des Vergleichs beschreiben, der für den emulierten Erkennungsvorgang verwendet wird.</target>       </trans-unit>
        <trans-unit id="228" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>Emulates input of specific words to the shared speech recognizer, using text instead of audio for asynchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the words and the loaded speech recognition grammars.</source>
          <target state="translated">Emuliert die Eingabe bestimmter Wörter für die freigegebene Spracherkennung. Dabei wird Text statt Audio für die asynchrone Spracherkennung verwendet und festgelegt, wie die Erkennung Unicode-Vergleich zwischen den Wörtern und den geladenen Spracherkennungsgrammatiken behandelt.</target>       </trans-unit>
        <trans-unit id="229" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>This method creates a <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object using the information provided in the <ph id="ph2">`wordUnits`</ph> parameter.</source>
          <target state="translated">Diese Methode erstellt eine <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> -Objekt mit den Angaben in der <ph id="ph2">`wordUnits`</ph> Parameter.</target>       </trans-unit>
        <trans-unit id="230" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizer uses the <ph id="ph1">`compareOptions`</ph> when it applies grammar rules to the input phrase.</source>
          <target state="translated">Das Erkennungsmodul verwendet die <ph id="ph1">`compareOptions`</ph> Wenn der input-Ausdruck als Grammatikregeln anwendet.</target>       </trans-unit>
        <trans-unit id="231" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizers that ship with Vista and Windows 7 ignore case if the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> or <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> value is present.</source>
          <target state="translated">Die Merkmale, die mit Vista und Windows 7 ausgeliefert Groß-/Kleinschreibung ignorieren, wenn die <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> oder <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> Wert vorhanden ist.</target>       </trans-unit>
        <trans-unit id="232" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizers always ignore the character width and never ignore the Kana type.</source>
          <target state="translated">Der Prüfer immer die Zeichenbreite ignoriert und nie den Kanatyp ignorieren.</target>       </trans-unit>
        <trans-unit id="233" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizers also ignore new lines and extra white space and treats punctuation as literal input.</source>
          <target state="translated">Der Prüfer ist außerdem neue Zeilen und zusätzlichen Leerraum zu ignorieren und Interpunktion als literal Eingabe behandelt.</target>       </trans-unit>
        <trans-unit id="234" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>For more information about character width and Kana type, see the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumeration.</source>
          <target state="translated">Weitere Informationen zu der Zeichenbreite und Kanatyp, finden Sie unter der <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> Enumeration.</target>       </trans-unit>
        <trans-unit id="235" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>The input phrase for the recognition operation.</source>
          <target state="translated">Der Eingabebegriff für den Erkennungsvorgang.</target>       </trans-unit>
        <trans-unit id="236" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</source>
          <target state="translated">Eine bitweise Kombination der Enumerationswerte, die den Typ des Vergleichs beschreiben, der für den emulierten Erkennungsvorgang verwendet wird.</target>       </trans-unit>
        <trans-unit id="237" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>Emulates input of a phrase to the shared speech recognizer, using text instead of audio for asynchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the phrase and the loaded speech recognition grammars.</source>
          <target state="translated">Emuliert die Eingabe eines Ausdrucks für die freigegebene Spracherkennung. Dabei wird Text statt Audio für die asynchrone Spracherkennung verwendet und festgelegt, wie die Erkennung Unicode-Vergleich zwischen dem Ausdruck und den geladenen Spracherkennungsgrammatiken behandelt.</target>       </trans-unit>
        <trans-unit id="238" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>The recognizer uses the <ph id="ph1">`compareOptions`</ph> when it applies grammar rules to the input phrase.</source>
          <target state="translated">Das Erkennungsmodul verwendet die <ph id="ph1">`compareOptions`</ph> Wenn der input-Ausdruck als Grammatikregeln anwendet.</target>       </trans-unit>
        <trans-unit id="239" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>The recognizers that ship with Vista and Windows 7 ignore case if the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> or <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> value is present.</source>
          <target state="translated">Die Merkmale, die mit Vista und Windows 7 ausgeliefert Groß-/Kleinschreibung ignorieren, wenn die <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> oder <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> Wert vorhanden ist.</target>       </trans-unit>
        <trans-unit id="240" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>The recognizers always ignore the character width and never ignore the Kana type.</source>
          <target state="translated">Der Prüfer immer die Zeichenbreite ignoriert und nie den Kanatyp ignorieren.</target>       </trans-unit>
        <trans-unit id="241" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>The recognizers also ignore new lines and extra white space and treats punctuation as literal input.</source>
          <target state="translated">Der Prüfer ist außerdem neue Zeilen und zusätzlichen Leerraum zu ignorieren und Interpunktion als literal Eingabe behandelt.</target>       </trans-unit>
        <trans-unit id="242" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>For more information about character width and Kana type, see the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumeration.</source>
          <target state="translated">Weitere Informationen zu der Zeichenbreite und Kanatyp, finden Sie unter der <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> Enumeration.</target>       </trans-unit>
        <trans-unit id="243" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>Occurs when the shared recognizer finalizes an asynchronous recognition operation for emulated input.</source>
          <target state="translated">Tritt auf, wenn die freigegebene Erkennung einen asynchronen Erkennungsvorgang für emulierte Eingabe abgeschlossen hat.</target>       </trans-unit>
        <trans-unit id="244" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>Each <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> method begins an asynchronous recognition operation.</source>
          <target state="translated">Jede <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> Methode startet einen asynchronen Recognition-Vorgang.</target>       </trans-unit>
        <trans-unit id="245" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>The recognizer raises the <ph id="ph1">`EmulateRecognizeCompleted`</ph> event when it finalizes the asynchronous operation.</source>
          <target state="translated">Das Erkennungsmodul löst die <ph id="ph1">`EmulateRecognizeCompleted`</ph> Ereignis aus, wenn sie den asynchronen Vorgang abschließt.</target>       </trans-unit>
        <trans-unit id="246" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>The asynchronous recognition operation can raise the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph>, and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> events.</source>
          <target state="translated">Die asynchrone Erkennungsvorgang auslösen kann die <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph>, und <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> Ereignisse.</target>       </trans-unit>
        <trans-unit id="247" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted&gt;</ph> event is the last such event that the recognizer raises for a given operation.</source>
          <target state="translated">Die <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted&gt;</ph> Ereignis ist die letzte einem solchen Fall, dass die Erkennung für einen angegebenen Vorgang löst.</target>       </trans-unit>
        <trans-unit id="248" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>When you create a delegate for an <ph id="ph1">`EmulateRecognizeCompleted`</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">Beim Erstellen eines Delegaten für ein <ph id="ph1">`EmulateRecognizeCompleted`</ph> Ereignis, bestimmen Sie die Methode für die Ereignisbehandlung.</target>       </trans-unit>
        <trans-unit id="249" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Um dem Ereignishandler das Ereignis zuzuordnen, fügen Sie dem Ereignis eine Instanz des Delegaten hinzu.</target>       </trans-unit>
        <trans-unit id="250" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Der Ereignishandler wird bei jedem Eintreten des Ereignisses aufgerufen, sofern der Delegat nicht entfernt wird.</target>       </trans-unit>
        <trans-unit id="251" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Weitere Informationen über Delegaten für Ereignishandler finden Sie unter <bpt id="p1">[</bpt>Ereignissen und Delegaten<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="252" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer.</source>
          <target state="translated">Im folgende Beispiel ist Teil einer Konsolenanwendung, die lädt eine Spracherkennung Recognition Grammatik und asynchrone emulierten Eingabe, die zugeordneten Erkennungsergebnisse und die zugehörigen Ereignisse ausgelöst, die für die von der Spracherkennung veranschaulicht.</target>       </trans-unit>
        <trans-unit id="253" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.</source>
          <target state="translated">Wenn Windows-Spracherkennung nicht ausgeführt wird, wird Windows-Spracherkennung starten Sie dann auf diese Anwendung auch gestartet.</target>       </trans-unit>
        <trans-unit id="254" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>If Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> mode, then <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> always returns null.</source>
          <target state="translated">Wenn Windows die Spracherkennung in ist die <bpt id="p1">**</bpt>im Standbymodus<ept id="p1">**</ept> Modus, klicken Sie dann <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> gibt immer null zurück.</target>       </trans-unit>
        <trans-unit id="255" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.Enabled">
          <source>Gets or sets a value that indicates whether this <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> object is ready to process speech.</source>
          <target state="translated">Ruft einen Wert ab bzw. legt einen Wert fest, der angibt, ob dieses <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph>-Objekt für die Sprachverarbeitung bereit ist.</target>       </trans-unit>
        <trans-unit id="256" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.Enabled">
          <source><ph id="ph1">&lt;see langword="true" /&gt;</ph> if this <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> object is performing speech recognition; otherwise, <ph id="ph3">&lt;see langword="false" /&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;see langword="true" /&gt;</ph>, wenn dieses <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph>-Objekt Spracherkennung ausführt; andernfalls <ph id="ph3">&lt;see langword="false" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="257" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.Enabled">
          <source>Changes to this property do not affect other instances of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> class.</source>
          <target state="translated">Änderungen an dieser Eigenschaft wirken sich nicht auf andere Instanzen von der <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> Klasse.</target>       </trans-unit>
        <trans-unit id="258" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.Enabled">
          <source>By default, the value of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</ph> property is <ph id="ph2">`true`</ph> for a newly instantiated instance of <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>.</source>
          <target state="translated">Standardmäßig wird der Wert des der <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</ph> Eigenschaft ist <ph id="ph2">`true`</ph> für ein neu instanziiertes Instanz von <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="259" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.Enabled">
          <source>While the recognizer is disabled, none of the recognizer's speech recognition grammars are available for recognition operations.</source>
          <target state="translated">Während die Erkennung deaktiviert ist, wird keine der die Erkennung Speech Recognition Grammatiken für Erkennungsvorgänge verfügbar.</target>       </trans-unit>
        <trans-unit id="260" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.Enabled">
          <source>Setting the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</ph> property has no effect on the recognizer's <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.State%2A&gt;</ph> property.</source>
          <target state="translated">Festlegen der Erkennung <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</ph> Eigenschaft hat keine Auswirkung auf der Erkennung <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.State%2A&gt;</ph> Eigenschaft.</target>       </trans-unit>
        <trans-unit id="261" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.Grammars">
          <source>Gets a collection of the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.Grammar" /&gt;</ph> objects that are loaded in this <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> instance.</source>
          <target state="translated">Ruft eine Auflistung der <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.Grammar" /&gt;</ph>-Objekte ab, die in diese <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph>-Instanz geladen werden.</target>       </trans-unit>
        <trans-unit id="262" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.Grammars">
          <source>A collection of the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.Grammar" /&gt;</ph> objects that the application loaded into the current instance of the shared recognizer.</source>
          <target state="translated">Eine Auflistung der <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.Grammar" /&gt;</ph>-Objekte, die die Anwendung in die aktuelle Instanz der freigegebenen Erkennung geladen hat.</target>       </trans-unit>
        <trans-unit id="263" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.Grammars">
          <source>This property does not return any speech recognition grammars loaded by another application.</source>
          <target state="translated">Diese Eigenschaft gibt keine Speech Recognition Grammatiken geladen, die von einer anderen Anwendung zurück.</target>       </trans-unit>
        <trans-unit id="264" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.Grammars">
          <source>The following example outputs information to the console for each speech recognition grammar loaded into the shared speech recognizer.</source>
          <target state="translated">Das folgende Beispiel gibt Informationen an die Konsole für jede Sprache Recognition-Grammatik, die in der freigegebenen von der Spracherkennung geladen.</target>       </trans-unit>
        <trans-unit id="265" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>The speech recognition grammar to load.</source>
          <target state="translated">Die zu ladende Spracherkennungsgrammatik.</target>       </trans-unit>
        <trans-unit id="266" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>Loads a speech recognition grammar.</source>
          <target state="translated">Lädt eine Spracherkennungsgrammatik.</target>       </trans-unit>
        <trans-unit id="267" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>The shared recognizer throws an exception if the speech recognition grammar is already loaded, is being asynchronously loaded, or has failed to load into any recognizer.</source>
          <target state="translated">Das freigegebene Erkennungsmodul löst eine Ausnahme aus, wenn die Spracherkennung Recognition Grammatik bereits geladen wird, asynchron geladen wird oder nicht in jeder Erkennungsmodul geladen konnte.</target>       </trans-unit>
        <trans-unit id="268" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>If the recognizer is running, applications must use <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> to pause the speech recognition engine before loading, unloading,  enabling, or disabling a grammar.</source>
          <target state="translated">Wenn die Erkennung ausgeführt wird, müssen Anwendungen verwenden <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> der Spracherkennungsmoduls vor dem Laden, entladen, aktivieren oder deaktivieren eine Grammatik anhalten.</target>       </trans-unit>
        <trans-unit id="269" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>To load a speech recognition grammar asynchronously, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A&gt;</ph> method.</source>
          <target state="translated">Um eine Sprache Recognition Grammatik asynchron zu laden, verwenden die <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A&gt;</ph> Methode.</target>       </trans-unit>
        <trans-unit id="270" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer.</source>
          <target state="translated">Im folgende Beispiel ist Teil einer Konsolenanwendung, die lädt eine Spracherkennung Recognition Grammatik und asynchrone emulierten Eingabe, die zugeordneten Erkennungsergebnisse und die zugehörigen Ereignisse ausgelöst, die für die von der Spracherkennung veranschaulicht.</target>       </trans-unit>
        <trans-unit id="271" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.</source>
          <target state="translated">Wenn Windows-Spracherkennung nicht ausgeführt wird, wird Windows-Spracherkennung starten Sie dann auf diese Anwendung auch gestartet.</target>       </trans-unit>
        <trans-unit id="272" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>If Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state, then <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> always returns null.</source>
          <target state="translated">Wenn Windows die Spracherkennung in ist die <bpt id="p1">**</bpt>im Standbymodus<ept id="p1">**</ept> Zustand befindet, klicken Sie dann <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> gibt immer null zurück.</target>       </trans-unit>
        <trans-unit id="273" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source>The speech recognition grammar to load.</source>
          <target state="translated">Die zu ladende Spracherkennungsgrammatik.</target>       </trans-unit>
        <trans-unit id="274" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source>Asynchronously loads a speech recognition grammar.</source>
          <target state="translated">Lädt asynchron eine Spracherkennungsgrammatik.</target>       </trans-unit>
        <trans-unit id="275" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source>When the recognizer completes this asynchronous operation, it raises a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted&gt;</ph> event.</source>
          <target state="translated">Wenn die Erkennung dieser asynchrone Vorgang abgeschlossen ist, löst eine <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted&gt;</ph> Ereignis.</target>       </trans-unit>
        <trans-unit id="276" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source>The recognizer throws an exception if the speech recognition grammar is already loaded, is being asynchronously loaded, or has failed to load into any recognizer.</source>
          <target state="translated">Das Erkennungsmodul löst eine Ausnahme aus, wenn die Spracherkennung Recognition Grammatik bereits geladen wird, asynchron geladen wird oder nicht in jeder Erkennungsmodul geladen konnte.</target>       </trans-unit>
        <trans-unit id="277" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source>If the recognizer is running, applications must use <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> to pause the speech recognition engine before loading, unloading,  enabling, or disabling a grammar.</source>
          <target state="translated">Wenn die Erkennung ausgeführt wird, müssen Anwendungen verwenden <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> der Spracherkennungsmoduls vor dem Laden, entladen, aktivieren oder deaktivieren eine Grammatik anhalten.</target>       </trans-unit>
        <trans-unit id="278" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source>To load a speech recognition grammar synchronously, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A&gt;</ph> method.</source>
          <target state="translated">Um eine Sprache Recognition Grammatik synchron zu laden, verwenden die <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A&gt;</ph> Methode.</target>       </trans-unit>
        <trans-unit id="279" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>Occurs when the recognizer finishes the asynchronous loading of a speech recognition grammar.</source>
          <target state="translated">Tritt auf, wenn die Erkennung das asynchrone Laden einer Spracherkennungsgrammatik beendet.</target>       </trans-unit>
        <trans-unit id="280" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>The recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A&gt;</ph> method initiates an asynchronous operation.</source>
          <target state="translated">Des Erkennungsmodul <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A&gt;</ph> Methode initiiert einen asynchronen Vorgang.</target>       </trans-unit>
        <trans-unit id="281" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>The recognizer raises the <ph id="ph1">`LoadGrammarCompleted`</ph> event when it completes the operation.</source>
          <target state="translated">Das Erkennungsmodul löst die <ph id="ph1">`LoadGrammarCompleted`</ph> Ereignis aus, wenn sie den Vorgang abgeschlossen ist.</target>       </trans-unit>
        <trans-unit id="282" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>To get the <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object that the recognizer loaded, use the <ph id="ph2">&lt;xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs.Grammar%2A&gt;</ph> property of the associated <ph id="ph3">&lt;xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt;</ph>.</source>
          <target state="translated">Zum Abrufen der <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> Objekt, das die Erkennung laden, verwenden Sie die <ph id="ph2">&lt;xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs.Grammar%2A&gt;</ph> Eigenschaft der zugeordneten <ph id="ph3">&lt;xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="283" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>To get the current <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects the recognizer has loaded, use the recognizer's <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A&gt;</ph> property.</source>
          <target state="translated">Abrufen des aktuellen <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> Objekte, die die Erkennung geladen wurde, verwenden Sie der Erkennung <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A&gt;</ph> Eigenschaft.</target>       </trans-unit>
        <trans-unit id="284" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>When you create a delegate for a <ph id="ph1">`LoadGrammarCompleted`</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">Beim Erstellen eines Delegaten für eine <ph id="ph1">`LoadGrammarCompleted`</ph> Ereignis, bestimmen Sie die Methode für die Ereignisbehandlung.</target>       </trans-unit>
        <trans-unit id="285" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Um dem Ereignishandler das Ereignis zuzuordnen, fügen Sie dem Ereignis eine Instanz des Delegaten hinzu.</target>       </trans-unit>
        <trans-unit id="286" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Der Ereignishandler wird bei jedem Eintreten des Ereignisses aufgerufen, sofern der Delegat nicht entfernt wird.</target>       </trans-unit>
        <trans-unit id="287" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Weitere Informationen über Delegaten für Ereignishandler finden Sie unter <bpt id="p1">[</bpt>Ereignissen und Delegaten<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="288" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>The following example creates a shared speech recognizer, and then creates two types of grammars for recognizing specific words and for accepting free dictation.</source>
          <target state="translated">Im folgende Beispiel erstellt eine freigegebene Spracherkennung und erstellt dann auf zwei Arten von Grammatiken für die Erkennung von bestimmten Wörtern und kostenlose diktieren annimmt.</target>       </trans-unit>
        <trans-unit id="289" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>The example asynchronously loads all the created grammars to the recognizer.</source>
          <target state="translated">Im Beispiel werden alle erstellten Grammatiken an die Erkennung asynchron geladen.</target>       </trans-unit>
        <trans-unit id="290" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>Handlers for the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> events write to the console the name of the grammar that was used to perform the recognition and the text of the recognition result, respectively.</source>
          <target state="translated">Handler für der Erkennung <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted&gt;</ph> und <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> Schreiben von Ereignissen in der Konsole den Namen der Grammatik, die verwendet wurde, bzw. die Freihand- und den Text des Ergebnisses Recognition ausführen.</target>       </trans-unit>
        <trans-unit id="291" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.MaxAlternates">
          <source>Gets or sets the maximum number of alternate recognition results that the shared recognizer returns for each recognition operation.</source>
          <target state="translated">Ruft die Höchstzahl alternativer Erkennungsergebnisse ab, welche die gemeinsame Erkennung für jeden Erkennungsvorgang zurückgibt, oder legt diese fest.</target>       </trans-unit>
        <trans-unit id="292" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.MaxAlternates">
          <source>The maximum number of alternate results that the speech recognizer returns for each recognition operation.</source>
          <target state="translated">Die maximale Anzahl alternativer Ergebnisse, die die Spracherkennung für jeden Erkennungsvorgang zurückgibt.</target>       </trans-unit>
        <trans-unit id="293" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.MaxAlternates">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;</ph> property of the <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> class contains the collection of <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizedPhrase&gt;</ph> objects that represent other candidate interpretations of the input.</source>
          <target state="translated">Die <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;</ph> Eigenschaft von der <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> Klasse enthält die Auflistung der <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizedPhrase&gt;</ph> Objekte, die andere Candidate Interpretationen der Eingabe darstellen.</target>       </trans-unit>
        <trans-unit id="294" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.MaxAlternates">
          <source>The default value for <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.MaxAlternates%2A&gt;</ph> is 10.</source>
          <target state="translated">Der Standardwert für <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.MaxAlternates%2A&gt;</ph> ist 10.</target>       </trans-unit>
        <trans-unit id="295" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition">
          <source>Gets or sets a value that indicates whether the shared recognizer pauses recognition operations while an application is handling a <ph id="ph1">&lt;see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" /&gt;</ph> event.</source>
          <target state="translated">Ruft einen Wert ab, bzw. legt diesen fest, der angibt, ob das gemeinsame Erkennungsmodul Erkennungsvorgänge anhält, während eine Anwendung ein <ph id="ph1">&lt;see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" /&gt;</ph>-Ereignis verarbeitet.</target>       </trans-unit>
        <trans-unit id="296" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition">
          <source><ph id="ph1">&lt;see langword="true" /&gt;</ph> if the shared recognizer waits to process input while any application is handling the <ph id="ph2">&lt;see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" /&gt;</ph> event; otherwise, <ph id="ph3">&lt;see langword="false" /&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;see langword="true" /&gt;</ph>, wenn die freigegebene Erkennungsmodul wartet, um Eingaben zu verarbeiten, während eine beliebige Anwendung das Ereignis <ph id="ph2">&lt;see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" /&gt;</ph> behandelt; andernfalls <ph id="ph3">&lt;see langword="false" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="297" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition">
          <source>Set this property to <ph id="ph1">`true`</ph>, if within the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> event handler your application needs to change the state of the speech recognition service or change the loaded or enabled speech recognition grammars before the speech recognition service processes more input.</source>
          <target state="translated">Legen Sie diese Eigenschaft auf <ph id="ph1">`true`</ph>, wenn innerhalb der <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> Ereignishandler, die Ihre Anwendung benötigt werden, ändern Sie den Status des Diensts Recognition Spracherkennung oder ändern vor dem Speech Recognition Dienst Grammatiken Recognition geladen oder aktivierte Sprache Prozesse, die weitere Eingabe.</target>       </trans-unit>
        <trans-unit id="298" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition">
          <source>Setting the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> property to <ph id="ph2">`true`</ph> causes each <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> event handler in every application to block the Windows speech recognition service.</source>
          <target state="translated">Festlegen der <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> Eigenschaft <ph id="ph2">`true`</ph> bewirkt, dass jede <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> -Ereignishandler in jeder Anwendung den Windows-Sprache Recognition Dienst blockiert.</target>       </trans-unit>
        <trans-unit id="299" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition">
          <source>To synchronize the changes to the shared recognizer with your application state, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> method.</source>
          <target state="translated">Um die Änderungen an den freigegebenen Erkennung mit Ihrer Anwendungsstatus zu synchronisieren, verwenden die <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> Methode.</target>       </trans-unit>
        <trans-unit id="300" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition">
          <source>When <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A&gt;</ph> is <ph id="ph2">`true`</ph>, during the execution of the <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> handler the speech recognition service pauses and buffers new audio input as it arrives.</source>
          <target state="translated">Wenn <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A&gt;</ph> ist <ph id="ph2">`true`</ph>, während der Ausführung der <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> Handler die Spracherkennung Recognition Dienst anhält und puffert neue Audioeingabe bei eintreffen.</target>       </trans-unit>
        <trans-unit id="301" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition">
          <source>Once the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> event handler exits, the speech recognition service resumes recognition and starts processing information from its input buffer.</source>
          <target state="translated">Sobald die <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> Ereignishandler beendet wird, die Erkennung Dienst setzt die Spracherkennung und beginnt die Verarbeitung von Informationen aus dem Eingabepuffer.</target>       </trans-unit>
        <trans-unit id="302" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition">
          <source>To enable or disable the speech recognition service, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</ph> property.</source>
          <target state="translated">Verwenden Sie zum Aktivieren oder deaktivieren die Spracherkennung Recognition-Dienst, der <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</ph> Eigenschaft.</target>       </trans-unit>
        <trans-unit id="303" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition">
          <source>Gets the current location of the recognizer in the audio input that it is processing.</source>
          <target state="translated">Ruft die aktuelle Position der Erkennung in der Audioeingabe ab, die verarbeitet wird.</target>       </trans-unit>
        <trans-unit id="304" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition">
          <source>The position of the recognizer in the audio input that it is processing.</source>
          <target state="translated">Die Position der Erkennung in der Audioeingabe, die sie verarbeitet.</target>       </trans-unit>
        <trans-unit id="305" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition">
          <source>The <ph id="ph1">`RecognizerAudioPosition`</ph> property references the recognizer's position in processing its audio input.</source>
          <target state="translated">Die <ph id="ph1">`RecognizerAudioPosition`</ph> -Eigenschaft verweist auf die Erkennung Position bei der Verarbeitung der Audioeingabe.</target>       </trans-unit>
        <trans-unit id="306" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition">
          <source>By contrast, the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> property references the input device's position in its generated audio stream.</source>
          <target state="translated">Im Gegensatz dazu, die <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> Eigenschaft verweist auf das Eingabegerät Position in der generierten Audiostream.</target>       </trans-unit>
        <trans-unit id="307" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition">
          <source>These positions can be different.</source>
          <target state="translated">Diese Positionen können unterschiedlich sein.</target>       </trans-unit>
        <trans-unit id="308" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition">
          <source>For example, if the recognizer has received input for which it has not yet generated a recognition result then the value of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> property is less than the value of the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> property.</source>
          <target state="translated">Z. B. wenn die Erkennung erhalten hat Eingabe nicht für die It hat noch erzeugt ein Erkennungsergebnis wird der Wert der die <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> -Eigenschaft muss kleiner als der Wert von der <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> Eigenschaft.</target>       </trans-unit>
        <trans-unit id="309" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.RecognizerInfo">
          <source>Gets information about the shared speech recognizer.</source>
          <target state="translated">Ruft Informationen über die freigegebene Spracherkennung ab.</target>       </trans-unit>
        <trans-unit id="310" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.RecognizerInfo">
          <source>Information about the shared speech recognizer.</source>
          <target state="translated">Informationen über die freigegebene Spracherkennung.</target>       </trans-unit>
        <trans-unit id="311" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.RecognizerInfo">
          <source>This property returns information about the speech recognizer in use by Windows Speech Recognition.</source>
          <target state="translated">Diese Eigenschaft gibt Informationen zu der von der Spracherkennung verwendet, durch die Windows-Spracherkennung.</target>       </trans-unit>
        <trans-unit id="312" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.RecognizerInfo">
          <source>The following example sends information about the shared recognizer to the console.</source>
          <target state="translated">Im folgende Beispiel sendet die Informationen über das freigegebene Erkennungsmodul an die Konsole.</target>       </trans-unit>
        <trans-unit id="313" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>Occurs when the recognizer pauses to synchronize recognition and other operations.</source>
          <target state="translated">Tritt auf, wenn die Erkennung anhält, um Erkennungs- und andere Vorgänge zu synchronisieren.</target>       </trans-unit>
        <trans-unit id="314" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>Applications must use <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> to pause a running instance of <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> before modifying its <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects.</source>
          <target state="translated">Anwendungen müssen verwenden <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> anhalten eine laufende Instanz von <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> vor der Änderung seiner <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> Objekte.</target>       </trans-unit>
        <trans-unit id="315" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>For example, while the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> is paused, you can load, unload, enable, and disable <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects.</source>
          <target state="translated">Während beispielsweise die <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> wird angehalten, Sie können zu laden, entladen, aktivieren und deaktivieren <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> Objekte.</target>       </trans-unit>
        <trans-unit id="316" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> raises this event when it is ready to accept modifications.</source>
          <target state="translated">Die <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> löst dieses Ereignis, wenn er Änderungen akzeptieren kann.</target>       </trans-unit>
        <trans-unit id="317" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>When you create a delegate for a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">Beim Erstellen eines Delegaten für eine <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> Ereignis, bestimmen Sie die Methode für die Ereignisbehandlung.</target>       </trans-unit>
        <trans-unit id="318" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Um dem Ereignishandler das Ereignis zuzuordnen, fügen Sie dem Ereignis eine Instanz des Delegaten hinzu.</target>       </trans-unit>
        <trans-unit id="319" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Der Ereignishandler wird bei jedem Eintreten des Ereignisses aufgerufen, sofern der Delegat nicht entfernt wird.</target>       </trans-unit>
        <trans-unit id="320" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Weitere Informationen über Delegaten für Ereignishandler finden Sie unter <bpt id="p1">[</bpt>Ereignissen und Delegaten<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="321" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>The following example shows a console application that loads and unloads <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects.</source>
          <target state="translated">Das folgende Beispiel zeigt eine Konsolenanwendung, die geladen und entladen wird <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> Objekte.</target>       </trans-unit>
        <trans-unit id="322" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>The application uses the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> method to request the speech recognition engine to pause so it can receive an update.</source>
          <target state="translated">Die Anwendung verwendet die <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> Methode zum Anfordern der Spracherkennungsmoduls anhalten, damit sie ein Update empfangen kann.</target>       </trans-unit>
        <trans-unit id="323" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>The application then loads or unloads a <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object.</source>
          <target state="translated">Die Anwendung dann lädt oder Entlädt eine <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> Objekt.</target>       </trans-unit>
        <trans-unit id="324" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>At each update, a handler for <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event writes the name and status of the currently loaded <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects to the console.</source>
          <target state="translated">Bei jeder Aktualisierung, einen Handler für <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> Ereignis schreibt den Namen und den Status der derzeit geladenen <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> Objekte in die Konsole.</target>       </trans-unit>
        <trans-unit id="325" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>As grammars are loaded and unloaded, the application first recognizes the names of farm animals, then the names of farm animals and the names of fruits, then only the names of fruits.</source>
          <target state="translated">Wie Grammatiken geladen und entladen werden, erkennt die Anwendung zuerst die Namen der Farm Tieren auf die Namen von Tieren sowie die Namen der Früchte und dann nur die Namen von Früchten.</target>       </trans-unit>
        <trans-unit id="326" translate="yes" xml:space="preserve" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>Requests that the shared recognizer pause and update its state.</source>
          <target state="translated">Fordert an, dass die freigegebene Erkennung anhält und ihren Zustand aktualisiert.</target>       </trans-unit>
        <trans-unit id="327" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>Use this method to synchronize changes to the shared recognizer.</source>
          <target state="translated">Verwenden Sie diese Methode zur Synchronisierung von Änderungen an den freigegebenen Erkennung.</target>       </trans-unit>
        <trans-unit id="328" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>For example, if you load or unload a speech recognition grammar while the recognizer is processing input, use this method and the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event to synchronize your application behavior with the state of the recognizer.</source>
          <target state="translated">Beispielsweise, wenn Sie laden oder Entladen von Spracherkennung Recognition Grammatik während die Erkennung Eingabe verarbeitet wird, verwenden Sie diese Methode und die <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> Ereignis, um das Verhalten Ihrer Anwendung mit dem Status der Erkennung zu synchronisieren.</target>       </trans-unit>
        <trans-unit id="329" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>When this method is called, the recognizer pauses or completes asynchronous operations and generates a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event.</source>
          <target state="translated">Wenn diese Methode aufgerufen wird, die Erkennung hält oder asynchrone Vorgänge abgeschlossen und generiert eine <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> Ereignis.</target>       </trans-unit>
        <trans-unit id="330" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>A <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event handler can then modify the state of the recognizer in between recognition operations.</source>
          <target state="translated">Ein <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> -Ereignishandler können Sie den Status der Erkennung zwischen Erkennungsvorgänge ändern.</target>       </trans-unit>
        <trans-unit id="331" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>When this method is called:</source>
          <target state="translated">Wenn diese Methode aufgerufen wird:</target>       </trans-unit>
        <trans-unit id="332" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>If the recognizer is not processing input, the recognizer immediately generates the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event.</source>
          <target state="translated">Die Erkennung nicht Eingabe verarbeitet, generiert die Erkennung sofort die <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> Ereignis.</target>       </trans-unit>
        <trans-unit id="333" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>If the recognizer is processing input that consists of silence or background noise, the recognizer pauses the recognition operation and generates the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event.</source>
          <target state="translated">Das Erkennungsmodul Eingabe verarbeitet, der Pausen oder Hintergrundgeräuschen besteht, wird die Erkennung hält den Erkennungsvorgang und generiert die <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> Ereignis.</target>       </trans-unit>
        <trans-unit id="334" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>If the recognizer is processing input that does not consist of silence or background noise, the recognizer completes the recognition operation and then generates the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event.</source>
          <target state="translated">Das Erkennungsmodul Eingabe verarbeitet, die nicht der stille oder Hintergrundgeräuschen besteht, wird die Erkennung Erkennungsvorgang abgeschlossen und generiert dann das <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> Ereignis.</target>       </trans-unit>
        <trans-unit id="335" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>While the recognizer is handling the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event:</source>
          <target state="translated">Während die Erkennung verarbeitet die <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> Ereignis:</target>       </trans-unit>
        <trans-unit id="336" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The recognizer does not process input, and the value of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> property remains the same.</source>
          <target state="translated">Das Erkennungsmodul verarbeitet keine Eingabe, und der Wert von der <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> Eigenschaft bleibt unverändert.</target>       </trans-unit>
        <trans-unit id="337" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The recognizer continues to collect input, and the value of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> property can change.</source>
          <target state="translated">Das Erkennungsmodul weiterhin erfassen, die Eingabe, und der Wert von der <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> -Eigenschaft ändern.</target>       </trans-unit>
        <trans-unit id="338" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>To change whether the shared recognizer pauses recognition operations while an application is handling a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> event, use the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A&gt;</ph> property.</source>
          <target state="translated">So ändern Sie, ob das freigegebene Erkennungsmodul Erkennungsvorgänge hält, während eine Anwendung behandelt einen <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> -Ereignis können Sie mithilfe der <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A&gt;</ph> Eigenschaft.</target>       </trans-unit>
        <trans-unit id="339" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The following example shows a console application that loads and unloads <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects.</source>
          <target state="translated">Das folgende Beispiel zeigt eine Konsolenanwendung, die geladen und entladen wird <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> Objekte.</target>       </trans-unit>
        <trans-unit id="340" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The application uses the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> method to request the speech recognition engine to pause so it can receive an update.</source>
          <target state="translated">Die Anwendung verwendet die <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> Methode zum Anfordern der Spracherkennungsmoduls anhalten, damit sie ein Update empfangen kann.</target>       </trans-unit>
        <trans-unit id="341" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The application then loads or unloads a <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object.</source>
          <target state="translated">Die Anwendung dann lädt oder Entlädt eine <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> Objekt.</target>       </trans-unit>
        <trans-unit id="342" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>At each update, a handler for <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event writes the name and status of the currently loaded <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects to the console.</source>
          <target state="translated">Bei jeder Aktualisierung, einen Handler für <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> Ereignis schreibt den Namen und den Status der derzeit geladenen <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> Objekte in die Konsole.</target>       </trans-unit>
        <trans-unit id="343" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>As grammars are loaded and unloaded, the application first recognizes the names of farm animals, then the names of farm animals and the names of fruits, then only the names of fruits.</source>
          <target state="translated">Wie Grammatiken geladen und entladen werden, erkennt die Anwendung zuerst die Namen der Farm Tieren auf die Namen von Tieren sowie die Namen der Früchte und dann nur die Namen von Früchten.</target>       </trans-unit>
        <trans-unit id="344" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate">
          <source>Requests that the shared recognizer pause and update its state.</source>
          <target state="translated">Fordert an, dass die freigegebene Erkennung anhält und ihren Zustand aktualisiert.</target>       </trans-unit>
        <trans-unit id="345" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate">
          <source>When the recognizer generates the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event, the <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;</ph> property of the <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;</ph> is <ph id="ph4">`null`</ph>.</source>
          <target state="translated">Bei die Erkennung generiert die <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> -Ereignis der <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;</ph> Eigenschaft von der <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;</ph> ist <ph id="ph4">`null`</ph>.</target>       </trans-unit>
        <trans-unit id="346" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate">
          <source>To provide a user token, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> method.</source>
          <target state="translated">Um ein Benutzertoken bereitzustellen, verwenden Sie die <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> oder <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> Methode.</target>       </trans-unit>
        <trans-unit id="347" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate">
          <source>To specify an audio position offset, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> method.</source>
          <target state="translated">Verwenden Sie zum Angeben eines audioposition-Offsets der <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> Methode.</target>       </trans-unit>
        <trans-unit id="348" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object)">
          <source>User-defined information that contains information for the operation.</source>
          <target state="translated">Benutzerdefinierte Informationen, die Informationen für den Vorgang enthalten.</target>       </trans-unit>
        <trans-unit id="349" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object)">
          <source>Requests that the shared recognizer pause and update its state and provides a user token for the associated event.</source>
          <target state="translated">Fordert an, dass die freigegebene Erkennung anhält, um den Zustand zu aktualisieren und stellt ein Benutzertoken für das zugeordnete Ereignis bereit.</target>       </trans-unit>
        <trans-unit id="350" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object)">
          <source>When the recognizer generates the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event, the <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;</ph> property of the <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;</ph> contains the value of the <ph id="ph4">`userToken`</ph> parameter.</source>
          <target state="translated">Bei die Erkennung generiert die <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> -Ereignis der <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;</ph> Eigenschaft von der <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;</ph> enthält den Wert des der <ph id="ph4">`userToken`</ph> Parameter.</target>       </trans-unit>
        <trans-unit id="351" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object)">
          <source>To specify an audio position offset, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> method.</source>
          <target state="translated">Verwenden Sie zum Angeben eines audioposition-Offsets der <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> Methode.</target>       </trans-unit>
        <trans-unit id="352" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object,System.TimeSpan)">
          <source>User-defined information that contains information for the operation.</source>
          <target state="translated">Benutzerdefinierte Informationen, die Informationen für den Vorgang enthalten.</target>       </trans-unit>
        <trans-unit id="353" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object,System.TimeSpan)">
          <source>The offset from the current <ph id="ph1">&lt;see cref="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" /&gt;</ph> to delay the request.</source>
          <target state="translated">Der Offset von der aktuellen <ph id="ph1">&lt;see cref="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" /&gt;</ph>, um die Anforderung zu verzögern.</target>       </trans-unit>
        <trans-unit id="354" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object,System.TimeSpan)">
          <source>Requests that the shared recognizer pause and update its state and provides an offset and a user token for the associated event.</source>
          <target state="translated">Fordert an, dass die freigegebene Erkennung anhält, um den Zustand zu aktualisieren und stellt ein Offset für das zugeordnete Ereignis bereit.</target>       </trans-unit>
        <trans-unit id="355" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object,System.TimeSpan)">
          <source>The recognizer does not initiate the recognizer update request until the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> equals the current <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> plus the value of the <ph id="ph3">`audioPositionAheadToRaiseUpdate`</ph> parameter.</source>
          <target state="translated">Initiiert die Erkennung nicht die Erkennung updateanforderung bis der Erkennung <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> ist gleich den aktuellen <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> plus der Wert, der die <ph id="ph3">`audioPositionAheadToRaiseUpdate`</ph> Parameter.</target>       </trans-unit>
        <trans-unit id="356" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object,System.TimeSpan)">
          <source>When the recognizer generates the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event, the <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;</ph> property of the <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;</ph> contains the value of the <ph id="ph4">`userToken`</ph> parameter.</source>
          <target state="translated">Bei die Erkennung generiert die <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> -Ereignis der <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;</ph> Eigenschaft von der <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;</ph> enthält den Wert des der <ph id="ph4">`userToken`</ph> Parameter.</target>       </trans-unit>
        <trans-unit id="357" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>Occurs when the recognizer detects input that it can identify as speech.</source>
          <target state="translated">Tritt auf, wenn die Erkennung eine Eingabe erkennt, die sie als Sprache identifizieren kann.</target>       </trans-unit>
        <trans-unit id="358" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>The shared recognizer can raise this event in response to input.</source>
          <target state="translated">Das freigegebene Erkennungsmodul auslösen kann dieses Ereignis als Antwort auf die Eingabe.</target>       </trans-unit>
        <trans-unit id="359" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition%2A&gt;</ph> property of the associated <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechDetectedEventArgs&gt;</ph> object indicates location in the input stream where the recognizer detected speech.</source>
          <target state="translated">Die <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition%2A&gt;</ph> Eigenschaft der zugeordneten <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechDetectedEventArgs&gt;</ph> Objekt gibt an, Speicherort im Eingabedatenstrom, auf denen die Erkennung Spracherkennung erkannt.</target>       </trans-unit>
        <trans-unit id="360" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>For more information see the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> properties and the <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A&gt;</ph> and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> methods.</source>
          <target state="translated">Weitere Informationen finden Sie unter der <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> und <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> Eigenschaften und die <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A&gt;</ph> und <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> Methoden.</target>       </trans-unit>
        <trans-unit id="361" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>When you create a delegate for a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">Beim Erstellen eines Delegaten für eine <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph> Ereignis, bestimmen Sie die Methode für die Ereignisbehandlung.</target>       </trans-unit>
        <trans-unit id="362" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Um dem Ereignishandler das Ereignis zuzuordnen, fügen Sie dem Ereignis eine Instanz des Delegaten hinzu.</target>       </trans-unit>
        <trans-unit id="363" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Der Ereignishandler wird bei jedem Eintreten des Ereignisses aufgerufen, sofern der Delegat nicht entfernt wird.</target>       </trans-unit>
        <trans-unit id="364" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Weitere Informationen über Delegaten für Ereignishandler finden Sie unter <bpt id="p1">[</bpt>Ereignissen und Delegaten<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="365" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>The following example is part of a console application for choosing origin and destination cities for a flight.</source>
          <target state="translated">Im folgende Beispiel ist Teil einer Konsolenanwendung für ein Flug Ursprungs- und Zielort Orte auswählen.</target>       </trans-unit>
        <trans-unit id="366" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>The application recognizes phrases such as "I want to fly from Miami to Chicago."</source>
          <target state="translated">Die Anwendung erkennt Ausdrücke an, wie z. B. "Ich möchte von Miami aus Chicago, fliegen."</target>       </trans-unit>
        <trans-unit id="367" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>The example uses the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph> event to report the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> each time speech is detected.</source>
          <target state="translated">Im Beispiel wird die <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph> Ereignis Bericht die <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> jedes Mal Sprache erkannt wird.</target>       </trans-unit>
        <trans-unit id="368" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized">
          <source>Occurs when the recognizer has recognized a word or words that may be a component of multiple complete phrases in a grammar.</source>
          <target state="translated">Tritt auf, wenn die Erkennung ein Wort oder Wörter erkannt hat, die möglicherweise eine Komponente von mehreren vollständigen Ausdrücken in einer Grammatik sind.</target>       </trans-unit>
        <trans-unit id="369" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized">
          <source>The shared recognizer can raise this event when the input is ambiguous.</source>
          <target state="translated">Das freigegebene Erkennungsmodul auslösen kann dieses Ereignis, wenn die Eingabe nicht eindeutig ist.</target>       </trans-unit>
        <trans-unit id="370" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized">
          <source>For example, for a speech recognition grammar that supports recognition of either "new game please" or "new game", "new game please" is an unambiguous input, and "new game" is an ambiguous input.</source>
          <target state="translated">Z. B. für eine Sprache Recognition-Grammatik, mit der Erkennung von beidem unterstützt "neue Bitte game" oder "new Game", "neue Bitte game" ist eine eindeutige Eingabe, und "new Game" ist eine mehrdeutige Eingabe.</target>       </trans-unit>
        <trans-unit id="371" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized">
          <source>When you create a delegate for a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">Beim Erstellen eines Delegaten für eine <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph> Ereignis, bestimmen Sie die Methode für die Ereignisbehandlung.</target>       </trans-unit>
        <trans-unit id="372" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Um dem Ereignishandler das Ereignis zuzuordnen, fügen Sie dem Ereignis eine Instanz des Delegaten hinzu.</target>       </trans-unit>
        <trans-unit id="373" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Der Ereignishandler wird bei jedem Eintreten des Ereignisses aufgerufen, sofern der Delegat nicht entfernt wird.</target>       </trans-unit>
        <trans-unit id="374" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Weitere Informationen über Delegaten für Ereignishandler finden Sie unter <bpt id="p1">[</bpt>Ereignissen und Delegaten<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="375" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized">
          <source>The following example recognizes phrases such as "Display the list of artists in the jazz category".</source>
          <target state="translated">Im folgende Beispiel erkennt Ausdrücke wie z. B. "Die Liste der Künstler in der Kategorie" jazz "anzeigen".</target>       </trans-unit>
        <trans-unit id="376" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized">
          <source>The example uses the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph> event to display incomplete phrase fragments in the console as they are recognized.</source>
          <target state="translated">Im Beispiel wird die <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph> Ereignis, um unvollständige Ausdruck Fragmente in der Konsole angezeigt, wie sie erkannt werden.</target>       </trans-unit>
        <trans-unit id="377" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>Occurs when the recognizer receives input that does not match any of the speech recognition grammars it has loaded.</source>
          <target state="translated">Tritt auf, wenn die Erkennung Eingaben empfängt, die mit keiner der Spracherkennungsgrammatiken übereinstimmen, die sie geladen hat.</target>       </trans-unit>
        <trans-unit id="378" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>The shared recognizer raises this event if it determines that input does not match with sufficient confidence any of the loaded speech recognition grammars.</source>
          <target state="translated">Das freigegebene Erkennungsmodul löst dieses Ereignis aus, wenn es feststellt, dass die Eingabe mit ausreichend geladenen Speech Recognition Grammatiken entspricht keiner.</target>       </trans-unit>
        <trans-unit id="379" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;</ph> property of the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt;</ph> contains the rejected <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object.</source>
          <target state="translated">Die <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;</ph> Eigenschaft von der <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt;</ph> enthält die abgelehnte <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> Objekt.</target>       </trans-unit>
        <trans-unit id="380" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>Confidence thresholds for the shared recognizer, managed by <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>, are associated with a user profile and stored in the Windows registry.</source>
          <target state="translated">Vertrauen Schwellenwerte für die freigegebenen Erkennung von verwalteten <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>, ein Benutzerprofil zugeordnet und in der Windows-Registrierung gespeichert sind.</target>       </trans-unit>
        <trans-unit id="381" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>Applications should not write changes to the registry for the properties of the shared recognizer.</source>
          <target state="translated">Anwendungen sollten keine Änderungen an der Registrierung für die Eigenschaften der freigegebenen Erkennung schreiben.</target>       </trans-unit>
        <trans-unit id="382" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>When you create a delegate for a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">Beim Erstellen eines Delegaten für eine <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph> Ereignis, bestimmen Sie die Methode für die Ereignisbehandlung.</target>       </trans-unit>
        <trans-unit id="383" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Um dem Ereignishandler das Ereignis zuzuordnen, fügen Sie dem Ereignis eine Instanz des Delegaten hinzu.</target>       </trans-unit>
        <trans-unit id="384" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Der Ereignishandler wird bei jedem Eintreten des Ereignisses aufgerufen, sofern der Delegat nicht entfernt wird.</target>       </trans-unit>
        <trans-unit id="385" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Weitere Informationen über Delegaten für Ereignishandler finden Sie unter <bpt id="p1">[</bpt>Ereignissen und Delegaten<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="386" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>The following example recognizes phrases such as "Display the list of artists in the jazz category" or "Display albums gospel".</source>
          <target state="translated">Im folgende Beispiel erkennt Ausdrücke wie z. B. "Zeigt eine Liste der Künstler in der Kategorie jazz" oder "Alben Gospel anzeigen".</target>       </trans-unit>
        <trans-unit id="387" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>The example uses a handler for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph> event to display a notification in the console when the speech input cannot be matched to the contents of the grammar with sufficient confidence to produce a successful recognition.</source>
          <target state="translated">Im Beispiel wird einen Handler für das <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph> Ereignis, um eine Benachrichtigung in der Konsole angezeigt, wenn die Spracherkennung kann nicht auf den Inhalt der Grammatik zugeordnet werden, mit ausreichend Vertrauen Eingabe, um einen erfolgreichen Erkennung zu erzeugen.</target>       </trans-unit>
        <trans-unit id="388" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>Occurs when the recognizer receives input that matches one of its speech recognition grammars.</source>
          <target state="translated">Tritt auf, wenn die Erkennung Eingaben empfängt, die mit einer ihrer Spracherkennungsgrammatiken übereinstimmen.</target>       </trans-unit>
        <trans-unit id="389" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>The recognizer raises the <ph id="ph1">`SpeechRecognized`</ph> event if it determines with sufficient confidence that input matches one of the loaded and enabled speech recognition grammars.</source>
          <target state="translated">Das Erkennungsmodul löst die <ph id="ph1">`SpeechRecognized`</ph> Ereignis, wenn es mit ausreichend ermittelt Eingabe eine Grammatiken Recognition geladen und aktiviert Sprache übereinstimmt.</target>       </trans-unit>
        <trans-unit id="390" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;</ph> property of the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt;</ph> contains the accepted <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object.</source>
          <target state="translated">Die <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;</ph> Eigenschaft von der <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt;</ph> enthält die akzeptierte <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> Objekt.</target>       </trans-unit>
        <trans-unit id="391" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>Confidence thresholds for the shared recognizer, managed by <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>, are associated with a user profile and stored in the Windows registry.</source>
          <target state="translated">Vertrauen Schwellenwerte für die freigegebenen Erkennung von verwalteten <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>, ein Benutzerprofil zugeordnet und in der Windows-Registrierung gespeichert sind.</target>       </trans-unit>
        <trans-unit id="392" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>Applications should not write changes to the registry for the properties of the shared recognizer.</source>
          <target state="translated">Anwendungen sollten keine Änderungen an der Registrierung für die Eigenschaften der freigegebenen Erkennung schreiben.</target>       </trans-unit>
        <trans-unit id="393" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>When the recognizer receives input that matches a grammar, the <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object can raise the <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt;</ph> event.</source>
          <target state="translated">Wenn die Erkennung Eingabe erhält, die eine Grammatik entspricht der <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> Objekt auslösen kann die <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt;</ph> Ereignis.</target>       </trans-unit>
        <trans-unit id="394" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object's <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt;</ph> event is raised prior to the speech recognizer's <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> event.</source>
          <target state="translated">Die <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> des Objekts <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt;</ph> Ereignis wird ausgelöst, bevor der Spracherkennung <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> Ereignis.</target>       </trans-unit>
        <trans-unit id="395" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>When you create a delegate for a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">Beim Erstellen eines Delegaten für eine <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> Ereignis, bestimmen Sie die Methode für die Ereignisbehandlung.</target>       </trans-unit>
        <trans-unit id="396" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Um dem Ereignishandler das Ereignis zuzuordnen, fügen Sie dem Ereignis eine Instanz des Delegaten hinzu.</target>       </trans-unit>
        <trans-unit id="397" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Der Ereignishandler wird bei jedem Eintreten des Ereignisses aufgerufen, sofern der Delegat nicht entfernt wird.</target>       </trans-unit>
        <trans-unit id="398" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Weitere Informationen über Delegaten für Ereignishandler finden Sie unter <bpt id="p1">[</bpt>Ereignissen und Delegaten<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="399" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>The following example is part of a console application that loads a speech recognition grammar and demonstrates speech input to the shared recognizer, the associated recognition results, and the associated events raised by the speech recognizer.</source>
          <target state="translated">Im folgende Beispiel ist Teil einer Konsolenanwendung, die lädt eine Spracherkennung Recognition Grammatik und Spracheingabe für das freigegebene Erkennungsmodul, die zugehörigen Erkennungsergebnisse und die zugehörigen Ereignisse ausgelöst, die für die von der Spracherkennung veranschaulicht.</target>       </trans-unit>
        <trans-unit id="400" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.</source>
          <target state="translated">Wenn Windows-Spracherkennung nicht ausgeführt wird, wird Windows-Spracherkennung starten Sie dann auf diese Anwendung auch gestartet.</target>       </trans-unit>
        <trans-unit id="401" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>Spoken input such as "I want to fly from Chicago to Miami" will trigger a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> event.</source>
          <target state="translated">Eingabe gesprochen, z. B. "Ich möchte von Chicago nach Miami fliegen" ausgelöst werden ein <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> Ereignis.</target>       </trans-unit>
        <trans-unit id="402" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>Speaking the phrase "Fly me from Houston to Chicago " will not trigger a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> event.</source>
          <target state="translated">Sprechen den Ausdruck "Fliegen me aus Houston nach Chicago" wird nicht ausgelöst, eine <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> Ereignis.</target>       </trans-unit>
        <trans-unit id="403" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>The example uses a handler for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> event to display successfully recognized phrases and the semantics they contain in the console.</source>
          <target state="translated">Im Beispiel wird einen Handler für das <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> Ereignis anzuzeigenden erfolgreich erkannt wird, Ausdrücke und die Semantik, die sie in der Konsole enthalten.</target>       </trans-unit>
        <trans-unit id="404" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.State">
          <source>Gets the state of a <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> object.</source>
          <target state="translated">Ruft den Zustand eines <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph>-Objekts ab.</target>       </trans-unit>
        <trans-unit id="405" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.State">
          <source>The state of the <ph id="ph1">&lt;see langword="SpeechRecognizer" /&gt;</ph> object.</source>
          <target state="translated">Der Zustand des <ph id="ph1">&lt;see langword="SpeechRecognizer" /&gt;</ph>-Objekts.</target>       </trans-unit>
        <trans-unit id="406" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.State">
          <source>This read-only property indicates whether the shared recognizer resident in Windows is in the <ph id="ph1">`Stopped`</ph> or the <ph id="ph2">`Listening`</ph> state.</source>
          <target state="translated">Diese schreibgeschützte Eigenschaft angibt, ob das freigegebene Erkennungsmodul residenten in Windows wird die <ph id="ph1">`Stopped`</ph> oder <ph id="ph2">`Listening`</ph> Zustand.</target>       </trans-unit>
        <trans-unit id="407" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.State">
          <source>For more information, see the <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizerState&gt;</ph> enumeration.</source>
          <target state="translated">Weitere Informationen finden Sie unter der <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizerState&gt;</ph>-Enumeration.</target>       </trans-unit>
        <trans-unit id="408" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>Occurs when the running state of the Windows Desktop Speech Technology recognition engine changes.</source>
          <target state="translated">Tritt auf, wenn sich der Ausführzustand des Erkennungsmoduls von Windows Desktop Speech Technology ändert.</target>       </trans-unit>
        <trans-unit id="409" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>The shared recognizer raises this event when the state of Windows Speech Recognition changes to the <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizerState.Listening&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerState.Stopped&gt;</ph> state.</source>
          <target state="translated">Das freigegebene Erkennungsmodul löst dieses Ereignis, wenn der Status der Windows-Spracherkennung zu ändert die <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizerState.Listening&gt;</ph> oder <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerState.Stopped&gt;</ph> Zustand.</target>       </trans-unit>
        <trans-unit id="410" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>To get the state of the shared recognizer at the time of the event, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.StateChangedEventArgs.RecognizerState%2A&gt;</ph> property of the associated <ph id="ph2">&lt;xref:System.Speech.Recognition.StateChangedEventArgs&gt;</ph>.</source>
          <target state="translated">Verwenden Sie zum Abrufen des Zustands der freigegebenen Erkennungsmodul zum Zeitpunkt des Ereignisses die <ph id="ph1">&lt;xref:System.Speech.Recognition.StateChangedEventArgs.RecognizerState%2A&gt;</ph> Eigenschaft der zugeordneten <ph id="ph2">&lt;xref:System.Speech.Recognition.StateChangedEventArgs&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="411" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>To get the current state of the shared recognizer, use the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.State%2A&gt;</ph> property.</source>
          <target state="translated">Um den aktuellen Zustand der freigegebenen Erkennung zu erhalten, verwenden Sie der Erkennung <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.State%2A&gt;</ph> Eigenschaft.</target>       </trans-unit>
        <trans-unit id="412" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>When you create a delegate for a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt;</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">Beim Erstellen eines Delegaten für eine <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt;</ph> Ereignis, bestimmen Sie die Methode für die Ereignisbehandlung.</target>       </trans-unit>
        <trans-unit id="413" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Um dem Ereignishandler das Ereignis zuzuordnen, fügen Sie dem Ereignis eine Instanz des Delegaten hinzu.</target>       </trans-unit>
        <trans-unit id="414" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Der Ereignishandler wird bei jedem Eintreten des Ereignisses aufgerufen, sofern der Delegat nicht entfernt wird.</target>       </trans-unit>
        <trans-unit id="415" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Weitere Informationen über Delegaten für Ereignishandler finden Sie unter <bpt id="p1">[</bpt>Ereignissen und Delegaten<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="416" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>The following example creates a shared speech recognizer, and then creates two types of grammars for recognizing specific words and for accepting free dictation.</source>
          <target state="translated">Im folgende Beispiel erstellt eine freigegebene Spracherkennung und erstellt dann auf zwei Arten von Grammatiken für die Erkennung von bestimmten Wörtern und kostenlose diktieren annimmt.</target>       </trans-unit>
        <trans-unit id="417" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>The example asynchronously loads all the created grammars to the recognizer.</source>
          <target state="translated">Im Beispiel werden alle erstellten Grammatiken an die Erkennung asynchron geladen.</target>       </trans-unit>
        <trans-unit id="418" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>A handler for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt;</ph> event uses the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> method to put Windows Recognition in "listening" mode.</source>
          <target state="translated">Einen Handler für das <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt;</ph> Ereignis verwendet die <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> Methode Windows Recognition in "Überwachungsmodus" aufgenommen werden sollen.</target>       </trans-unit>
        <trans-unit id="419" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars">
          <source>Unloads all speech recognition grammars from the shared recognizer.</source>
          <target state="translated">Entlädt alle Spracherkennungsgrammatiken aus dem freigegebenen Erkennungsmodul.</target>       </trans-unit>
        <trans-unit id="420" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars">
          <source>If the recognizer is currently loading a grammar asynchronously, this method waits until the grammar is loaded, before it unloads all of the recognizer's grammars.</source>
          <target state="translated">Wenn die Erkennung eine Grammatik derzeit asynchron geladen wird, wartet diese Methode, bis die Grammatik geladen wird, vor dem Entladen alle Grammatiken für die Erkennung.</target>       </trans-unit>
        <trans-unit id="421" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars">
          <source>To unload a specific grammar, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A&gt;</ph> method.</source>
          <target state="translated">Verwenden Sie zum Entladen einer bestimmten Grammatik der <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A&gt;</ph> Methode.</target>       </trans-unit>
        <trans-unit id="422" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)">
          <source>The grammar to unload.</source>
          <target state="translated">Die zu entladene Grammatik.</target>       </trans-unit>
        <trans-unit id="423" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)">
          <source>Unloads a specified speech recognition grammar from the shared recognizer.</source>
          <target state="translated">Entlädt eine angegebene Spracherkennungsgrammatik aus dem freigegebenen Erkennungsmodul.</target>       </trans-unit>
        <trans-unit id="424" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)">
          <source>If the recognizer is running, applications must use <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> to pause the speech recognition engine before loading, unloading,  enabling, or disabling a grammar.</source>
          <target state="translated">Wenn die Erkennung ausgeführt wird, müssen Anwendungen verwenden <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> der Spracherkennungsmoduls vor dem Laden, entladen, aktivieren oder deaktivieren eine Grammatik anhalten.</target>       </trans-unit>
        <trans-unit id="425" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)">
          <source>To unload all grammars, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A&gt;</ph> method.</source>
          <target state="translated">Verwenden Sie zum Entladen alle Grammatiken der <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A&gt;</ph> Methode.</target>       </trans-unit>
      </group>
    </body>
  </file>
</xliff>