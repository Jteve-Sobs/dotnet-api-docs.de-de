<Type Name="SemanticResultKey" FullName="System.Speech.Recognition.SemanticResultKey">
  <Metadata><Meta Name="ms.openlocfilehash" Value="9d41242796c25031134a175d7e82a84cb6e4c818" /><Meta Name="ms.sourcegitcommit" Value="88014e1c5440e3df4f66ef04393854d15b1fd534" /><Meta Name="ms.translationtype" Value="MT" /><Meta Name="ms.contentlocale" Value="de-DE" /><Meta Name="ms.lasthandoff" Value="09/05/2019" /><Meta Name="ms.locfileid" Value="70606472" /></Metadata><TypeSignature Language="C#" Value="public class SemanticResultKey" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi beforefieldinit SemanticResultKey extends System.Object" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Recognition.SemanticResultKey" />
  <TypeSignature Language="VB.NET" Value="Public Class SemanticResultKey" />
  <TypeSignature Language="C++ CLI" Value="public ref class SemanticResultKey" />
  <TypeSignature Language="F#" Value="type SemanticResultKey = class" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>3.0.0.0</AssemblyVersion>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Object</BaseTypeName>
  </Base>
  <Interfaces />
  <Attributes>
    <Attribute>
      <AttributeName>System.Diagnostics.DebuggerDisplay("{_semanticKey.DebugSummary}")</AttributeName>
    </Attribute>
  </Attributes>
  <Docs>
    <summary>Ordnet <see cref="T:System.Speech.Recognition.SemanticResultValue" />-Werten eine Schlüsselzeichenfolge zu, um <see cref="T:System.Speech.Recognition.SemanticValue" />-Objekte zu definieren.</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Die grundlegende Einheit des semantischen Ausdrucks in System. Speech <xref:System.Speech.Recognition.SemanticValue>ist das, bei dem es sich um ein Schlüssel-Wert-Paar handelt.  
  
 Mithilfe <xref:System.Speech.Recognition.SemanticResultKey> von-Objekten markieren <xref:System.Speech.Recognition.SemanticResultValue> Sie Instanzen, <xref:System.Speech.Recognition.GrammarBuilder> die in Objekten und Zeichen folgen enthalten sind, damit auf die <xref:System.Speech.Recognition.SemanticValue> Werte von Instanzen bei der Erkennung möglicherweise zugegriffen werden kann.  
  
 Sie können- <xref:System.Speech.Recognition.SemanticResultValue> und <xref:System.Speech.Recognition.SemanticResultKey> -Objekte zusammen mit <xref:System.Speech.Recognition.GrammarBuilder> -und <xref:System.Speech.Recognition.Choices> -Objekten verwenden, um die semantische Struktur für eine sprach Erkennungs Grammatik zu definieren. Um auf die semantischen Informationen in einem Erkennungs Ergebnis zuzugreifen, rufen Sie <xref:System.Speech.Recognition.SemanticValue> mithilfe der <xref:System.Speech.Recognition.RecognizedPhrase.Semantics%2A> -Eigenschaft <xref:System.Speech.Recognition.RecognizedPhrase>für eine Instanz von ab.  
  
  
## Examples  
 Im folgenden Beispiel wird ein <xref:System.Speech.Recognition.Grammar> erstellt, um die Kenn Wort Eingabe in der Form "mein Kennwort ist..." zu erkennen, wobei die tatsächliche Eingabe mit einem Platzhalter übereinstimmt.  
  
 Der Platzhalter wird mit einem semantischen Schlüssel gekennzeichnet, <xref:System.Speech.Recognition.Grammar.SpeechRecognized> und der Handler prüft, ob dieses Tag vorhanden ist, um zu überprüfen, ob eine Kenn Wort Eingabe aufgetreten ist.  
  
```csharp  
private void pwdGrammar()   
{  
  GrammarBuilder pwdBuilder = new GrammarBuilder("My Password is");  
  GrammarBuilder wildcardBuilder = new GrammarBuilder();  
  wildcardBuilder.AppendWildcard();  
  SemanticResultKey wildcardKey= new SemanticResultKey("Password", wildcardBuilder);  
  pwdBuilder+=wildcardKey;  
  Grammar grammar = new Grammar(pwdBuilder);  
  grammar.Name = "Password input";  
  
  grammar.SpeechRecognized += delegate(object sender, SpeechRecognizedEventArgs eventArgs)   
  {  
    SemanticValue semantics = eventArgs.Result.Semantics;  
    RecognitionResult result=eventArgs.Result;  
  
    if (!semantics.ContainsKey("Password"))   
    {  
      SpeechUI.SendTextFeedback(eventArgs.Result, "No Password Provided", false);  
    }  
    else   
    {  
      RecognizedAudio pwdAudio = result.GetAudioForWordRange(result.Words[3], result.Words[result.Words.Count - 1]);  
      MemoryStream pwdMemoryStream = new MemoryStream();  
      pwdAudio.WriteToAudioStream(pwdMemoryStream);  
      if (!IsValidPwd(pwdMemoryStream))   
      {  
        string badPwd = System.IO.Path.GetTempPath() + "BadPwd" + (new Random()).Next().ToString() + ".wav";  
        FileStream waveStream = new FileStream(badPwd, FileMode.Create);  
        pwdAudio.WriteToWaveStream(waveStream);  
        waveStream.Flush();  
        waveStream.Close();  
        SpeechUI.SendTextFeedback(eventArgs.Result, "Invalid Password", false);  
  
      }  
    }  
  };  
  grammar.Enabled = true;  
  _recognizer.LoadGrammar(grammar);  
  UpdateGrammarTree(_grammarTreeView, _recognizer);  
  
}  
```  
  
 ]]></format>
    </remarks>
    <altmember cref="T:System.Speech.Recognition.SemanticValue" />
    <altmember cref="T:System.Speech.Recognition.SemanticResultValue" />
    <related type="Article" href="https://docs.microsoft.com/previous-versions/office/developer/speech-technologies/hh361587(v%3doffice.14)">Verwenden von semantikresultkey zum Extrahieren eines semantikresultvalue</related>
  </Docs>
  <Members>
    <MemberGroup MemberName=".ctor">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Erstellt eine Instanz von <see cref="T:System.Speech.Recognition.SemanticResultKey" /> und ordnet den Schlüssel Grammatikkomponenten zu.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Die Konstruktoren für <xref:System.Speech.Recognition.SemanticResultKey> geben ein texttag (den semantischen Schlüssel) und einen Satz von Grammatik Komponenten an, die einer sprach Erkennungs Grammatik hinzugefügt werden sollen.  
  
 Die Grammatik Komponenten können als Array von <xref:System.Speech.Recognition.GrammarBuilder> -Objekten oder als Array von <xref:System.String> -Instanzen angegeben werden.  
  
 Wenn die Grammatik Komponenten bei der Erkennung verwendet werden, können Sie auf die <xref:System.Speech.Recognition.SemanticValue> zurückgegebene zugreifen, indem Sie das texttag verwenden <xref:System.Speech.Recognition.SemanticResultKey> , das dem Konstruktor von als semantischer Schlüssel bereitgestellt wird. Die <xref:System.Speech.Recognition.SemanticValue.Value%2A> -Eigenschaft <xref:System.Speech.Recognition.SemanticValue> der-Instanz wird von den in der Definition von <xref:System.Speech.Recognition.SemanticResultKey>verwendeten Grammatik Komponenten bestimmt.  
  
 ]]></format>
        </remarks>
      </Docs>
    </MemberGroup>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public SemanticResultKey (string semanticResultKey, params System.Speech.Recognition.GrammarBuilder[] builders);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(string semanticResultKey, class System.Speech.Recognition.GrammarBuilder[] builders) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SemanticResultKey.#ctor(System.String,System.Speech.Recognition.GrammarBuilder[])" />
      <MemberSignature Language="VB.NET" Value="Public Sub New (semanticResultKey As String, ParamArray builders As GrammarBuilder())" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; SemanticResultKey(System::String ^ semanticResultKey, ... cli::array &lt;System::Speech::Recognition::GrammarBuilder ^&gt; ^ builders);" />
      <MemberSignature Language="F#" Value="new System.Speech.Recognition.SemanticResultKey : string * System.Speech.Recognition.GrammarBuilder[] -&gt; System.Speech.Recognition.SemanticResultKey" Usage="new System.Speech.Recognition.SemanticResultKey (semanticResultKey, builders)" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="semanticResultKey" Type="System.String" />
        <Parameter Name="builders" Type="System.Speech.Recognition.GrammarBuilder[]">
          <Attributes>
            <Attribute FrameworkAlternate="netframework-3.0">
              <AttributeName>System.ParamArray</AttributeName>
            </Attribute>
          </Attributes>
        </Parameter>
      </Parameters>
      <Docs>
        <param name="semanticResultKey">Das Tag, das als semantischer Schlüssel verwendet werden soll, um auf die <see cref="T:System.Speech.Recognition.SemanticValue" />-Instanz zuzugreifen, die den <see cref="T:System.Speech.Recognition.GrammarBuilder" />-Objekten zugeordnet ist, die vom Argument <paramref name="builders" /> angegeben werden.</param>
        <param name="builders">Ein Array von Grammatikkomponenten, die einem <see cref="T:System.Speech.Recognition.SemanticValue" />-Objekt zugeordnet werden, auf das mit dem in <paramref name="semanticResultKey" /> definierten Tag zugegriffen werden kann.</param>
        <summary>Weist einem oder mehreren <see cref="T:System.Speech.Recognition.GrammarBuilder" />-Objekten, die verwendet werden, um eine Spracherkennungsgrammatik zu erstellen einen semantischen Schlüssel zu.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Aufgrund impliziter Konvertierungen `builders` <xref:System.Speech.Recognition.SemanticResultKey>unterstützt <xref:System.Speech.Recognition.SemanticResultValue> <xref:System.Speech.Recognition.Choices>das-Argument auch <xref:System.String> die-,-,-und-Objekte. Weitere Informationen zu impliziten Konvertierungen finden <xref:System.Speech.Recognition.GrammarBuilder.op_Implicit%2A>Sie unter.  
  
 Wenn Sie einen Erkennungs Vorgang ausführen, <xref:System.Speech.Recognition.GrammarBuilder> werden die `builders` im-Argument bereitgestellten-Objekte als sequenziell behandelt. Wenn z. b. Folgendes <xref:System.Speech.Recognition.SemanticResultValue> verwendet wird, um eine <xref:System.Speech.Recognition.Grammar>zu erstellen, muss die Eingabe in die Erkennungs-Engine die Wörter "The Quick Brown Fox" in der Sequenz enthalten, um erkannt zu werden.  
  
```csharp  
SemanticResultKey stringTest=new SemanticResultKey(  
    "stringTest", new GrammarBuilder[] {  
    new GrammarBuilder("the"),  
    new GrammarBuilder("quick"),  
    new GrammarBuilder("brown"),  
    new GrammarBuilder("fox")});  
```  
  
 Das `semanticResultKey` -Argument enthält das-Tag, das <xref:System.Speech.Recognition.SemanticValue> für den Zugriff auf den verwendet wird.  
  
 Der <xref:System.Speech.Recognition.SemanticValue.Value%2A> <xref:System.Speech.Recognition.GrammarBuilder> von wird von den-Instanzen bestimmt, die vom- Parameter bereitgestellt werden. `builders`  <xref:System.Speech.Recognition.SemanticValue>  
  
 Wenn die <xref:System.Speech.Recognition.GrammarBuilder> -Objekte keine definierenden Instanzen <xref:System.Speech.Recognition.SemanticResultValue>von enthalten <xref:System.Speech.Recognition.SemanticValue> , ist `null`der Wert von.  
  
 Wenn die <xref:System.Speech.Recognition.GrammarBuilder> Objekte, die `builders` im-Parameter bereitgestellt werden, eine nicht markierte Instanz <xref:System.Speech.Recognition.SemanticResultKey> (die <xref:System.Speech.Recognition.SemanticResultValue> nicht mit einem-Objekt verknüpft ist) bereitstellen, die <xref:System.Speech.Recognition.SemanticResultValue> von der Erkennungs Logik verwendet wird, definiert diese Instanz von das <xref:System.Speech.Recognition.SemanticValue.Value%2A> die <xref:System.Speech.Recognition.SemanticValue>  -Eigenschaft des-Objekts, das erstellt wird.  
  
 In den <xref:System.Speech.Recognition.SemanticResultValue> <xref:System.Speech.Recognition.GrammarBuilder> Objekten, die durch den `builders` -Parameter angegeben werden, sollte nur eine nicht markierte Instanz vorhanden sein. Wenn mehrere Instanzen von ohne Tags <xref:System.Speech.Recognition.SemanticResultValue> zugeordnet <xref:System.Speech.Recognition.SemanticResultKey>sind, versucht jede, den Wert von <xref:System.Speech.Recognition.SemanticValue> festzulegen, der im Erkennungs Ergebnis erzeugt wird. Dies ist nicht zulässig, und die Erkennung generiert eine Ausnahme, wenn versucht wird, eine zu verwenden <xref:System.Speech.Recognition.Grammar> , die mit einer <xref:System.Speech.Recognition.SemanticResultKey> solchen Instanz erstellt wurde.  
  
 Instanzen von <xref:System.Speech.Recognition.SemanticResultValue> , die in <xref:System.Speech.Recognition.GrammarBuilder> den Objekten enthalten sind `builders` , die durch den-Parameter <xref:System.Speech.Recognition.SemanticResultKey> angegeben und bereits einem anderen zugeordnet <xref:System.Speech.Recognition.SemanticResultKey> sind, haben keine Auswirkung auf die aktuelle Instanz.  
  
   
  
## Examples  
 Im folgenden Beispiel wird ein <xref:System.Speech.Recognition.Grammar> erstellt, um die Kenn Wort Eingabe in der Form "mein Kennwort ist..." zu erkennen, wobei die tatsächliche Eingabe mit einem Platzhalter übereinstimmt.  
  
 Der Platzhalter wird durch einen <xref:System.Speech.Recognition.SpeechRecognizer> gekennzeichnet, dessen Schlüsselwert "Password" lautet. Der <xref:System.Speech.Recognition.Grammar.SpeechRecognized> Handler prüft, ob dieses Tag vorhanden ist, erhält die Audioeingabe des Kennworts und überprüft das Kennwort.  
  
```csharp  
private void pwdGrammar()   
{  
  GrammarBuilder pwdBuilder = new GrammarBuilder("My Password is");  
  GrammarBuilder wildcardBuilder = new GrammarBuilder();  
  wildcardBuilder.AppendWildcard();  
  SemanticResultKey wildcardKey= new SemanticResultKey("Password", wildcardBuilder);  
  pwdBuilder+=wildcardKey;  
  Grammar grammar = new Grammar(pwdBuilder);  
  grammar.Name = "Password input";  
  
  grammar.SpeechRecognized +=   
    delegate(object sender, SpeechRecognizedEventArgs eventArgs)   
    {  
      SemanticValue semantics = eventArgs.Result.Semantics;  
      RecognitionResult result=eventArgs.Result;  
  
      if (!semantics.ContainsKey("Password"))   
      {  
        SpeechUI.SendTextFeedback(eventArgs.Result, "No Password Provided", false);  
      }  
      else   
      {  
        RecognizedAudio pwdAudio = result.GetAudioForWordRange(  
                  result.Words[3],  
                  result.Words[result.Words.Count - 1]);  
                  MemoryStream pwdMemoryStream = new MemoryStream();  
                  pwdAudio.WriteToAudioStream(pwdMemoryStream);  
        if (!IsValidPwd(pwdMemoryStream))   
        {  
          string badPwd = System.IO.Path.GetTempPath() + "BadPwd" + (new Random()).Next().ToString() + ".wav";  
          FileStream waveStream = new FileStream(badPwd, FileMode.Create);    
          pwdAudio.WriteToWaveStream(waveStream);  
          waveStream.Flush();  
          waveStream.Close();  
          SpeechUI.SendTextFeedback(eventArgs.Result, "Invalid Password", false);      
        }  
      }  
    };  
  
  grammar.Enabled = true;  
  _recognizer.LoadGrammar(grammar);  
  UpdateGrammarTree(_grammarTreeView, _recognizer);  
  
}  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public SemanticResultKey (string semanticResultKey, params string[] phrases);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(string semanticResultKey, string[] phrases) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SemanticResultKey.#ctor(System.String,System.String[])" />
      <MemberSignature Language="VB.NET" Value="Public Sub New (semanticResultKey As String, ParamArray phrases As String())" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; SemanticResultKey(System::String ^ semanticResultKey, ... cli::array &lt;System::String ^&gt; ^ phrases);" />
      <MemberSignature Language="F#" Value="new System.Speech.Recognition.SemanticResultKey : string * string[] -&gt; System.Speech.Recognition.SemanticResultKey" Usage="new System.Speech.Recognition.SemanticResultKey (semanticResultKey, phrases)" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="semanticResultKey" Type="System.String" />
        <Parameter Name="phrases" Type="System.String[]">
          <Attributes>
            <Attribute FrameworkAlternate="netframework-3.0">
              <AttributeName>System.ParamArray</AttributeName>
            </Attribute>
          </Attributes>
        </Parameter>
      </Parameters>
      <Docs>
        <param name="semanticResultKey">Das Tag, das verwendet werden soll, um auf die <see cref="T:System.Speech.Recognition.SemanticValue" />-Instanz zuzugreifen, die den <see cref="T:System.String" />-Objekten zugeordnet ist, die vom Argument <paramref name="phrases" /> angegeben werden.</param>
        <param name="phrases">Eines oder mehrere <see cref="T:System.String" />-Objekte, deren verketteter Text einem <see cref="T:System.Speech.Recognition.SemanticValue" />-Objekt zugeordnet wird, das mit dem Tag zugreifbar ist, das in <paramref name="semanticResultKey" /> definiert wird.</param>
        <summary>Weist einem oder mehreren <see cref="T:System.String" />-Instanzen, die verwendet werden, um eine Spracherkennungsgrammatik zu erstellen einen semantischen Schlüssel zu.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Wenn Sie einen Erkennungs Vorgang ausführen, <xref:System.String> werden die `phrases` im-Parameter verwendeten-Objekte als sequenziell behandelt. Wenn z. b. Folgendes <xref:System.Speech.Recognition.SemanticResultValue> verwendet wird, um eine <xref:System.Speech.Recognition.Grammar>zu erstellen, muss die Eingabe in die Erkennungs-Engine die Wörter "The Quick Brown Fox" in der Sequenz enthalten, um erkannt zu werden.  
  
```csharp  
SemanticResultKey stringTest=new SemanticResultKey("stringTest",   
                                new string[] {  
                                               "the",  
                                               "quick",  
                                               "brown",  
                                               "fox"});  
```  
  
 Das `semanticResultKey` -Argument bestimmt den Schlüssel für den Zugriff <xref:System.Speech.Recognition.SemanticValue> auf das, das zurückgegeben werden kann.  
  
 Wenn Sie ein <xref:System.Speech.Recognition.Grammar> mithilfe eines <xref:System.Speech.Recognition.GrammarBuilder> -Objekts erstellen, das einen semantischen Schlüssel mit einem Array <xref:System.Speech.Recognition.SemanticValue.Value%2A> von Zeichen folgen Objekten enthält <xref:System.Speech.Recognition.SemanticValue> , ist der der von einem Erkennungs Vorgang erzeugte Zeichenfolge die Zeichenfolge, die für die Erkennung verwendet wird. Im vorangehenden Beispiel bedeutet dies, dass <xref:System.Speech.Recognition.SemanticValue.Value%2A> "The Quick Brown Fox" wäre.  
  
   
  
## Examples  
 Im folgenden Beispiel wird ein <xref:System.Speech.Recognition.Grammar> aus einem <xref:System.Speech.Recognition.GrammarBuilder> -Objekt erstellt, <xref:System.Speech.Recognition.SemanticResultKey>das ein-Objekt verwendet, das durch <xref:System.String> ein Array von-Objekten definiert wird.  
  
 Eine Erkennungs-Engine, <xref:System.Speech.Recognition.Grammar> die die erstellte verwendet, erkennt den Ausdruck "Color Red Green Blue Zero". Die Semantik von, <xref:System.Speech.Recognition.RecognizedPhrase> die von der Erkennung zurückgegeben <xref:System.Speech.Recognition.SemanticValue> wird, <xref:System.Speech.Recognition.SemanticValue.Value%2A> enthält ein-Zeichen mit dem-Zeichen "Red Green Blue". Sie können auf das <xref:System.Speech.Recognition.SemanticValue> mit dem Tag "Code" zugreifen.  
  
 Aufgrund der `SemanticResultValue("zero", 5)` an den <xref:System.Speech.Recognition.GrammarBuilder>angefügten hat das <xref:System.Speech.Recognition.SemanticValue> Stamm Objekt im den <xref:System.Speech.Recognition.RecognizedPhrase> Wert 5.  
  
```csharp  
private void keyTest()   
{  
  // Say "color red green blue zero"  
  GrammarBuilder gb = new GrammarBuilder("color") +  
                        new SemanticResultKey("code",   
                          (new string[] {"red", "green", "blue"})) +  
                        new SemanticResultValue("zero", 5);  
  Grammar g = new Grammar(gb);  
  g.Name = "keyTest";  
  _recognizer.LoadGrammar(g);  
}  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="ToGrammarBuilder">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.GrammarBuilder ToGrammarBuilder ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Speech.Recognition.GrammarBuilder ToGrammarBuilder() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SemanticResultKey.ToGrammarBuilder" />
      <MemberSignature Language="VB.NET" Value="Public Function ToGrammarBuilder () As GrammarBuilder" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; System::Speech::Recognition::GrammarBuilder ^ ToGrammarBuilder();" />
      <MemberSignature Language="F#" Value="member this.ToGrammarBuilder : unit -&gt; System.Speech.Recognition.GrammarBuilder" Usage="semanticResultKey.ToGrammarBuilder " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.GrammarBuilder</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Gibt eine Instanz von <see cref="T:System.Speech.Recognition.GrammarBuilder" /> zurück, die aus der aktuellen <see cref="T:System.Speech.Recognition.SemanticResultKey" />-Instanz konstruiert wurde.</summary>
        <returns>Eine Instanz von <see cref="T:System.Speech.Recognition.GrammarBuilder" />, die aus der aktuellen <see langword="SemanticResultKey" />-Instanz konstruiert wurde.</returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Die Verwendung von <xref:System.Speech.Recognition.SemanticResultValue.ToGrammarBuilder%2A> entspricht der <xref:System.Speech.Recognition.GrammarBuilder> Verwendung des-Konstruktors, der <xref:System.Speech.Recognition.SemanticResultKey> als Argument annimmt (<xref:System.Speech.Recognition.GrammarBuilder.%23ctor%28System.Speech.Recognition.SemanticResultKey%29>).  
  
   
  
## Examples  
 Im folgenden Beispiel wird ein <xref:System.Speech.Recognition.Grammar> -Objekt erstellt, das-Befehle zum Ändern der Hintergrundfarbe unterstützt.  
  
 Ein <xref:System.Speech.Recognition.Choices> -Objekt`colorChoice`(), das die Liste der Optionen für Hintergrundfarben enthält, <xref:System.Speech.Recognition.Choices.Add%28System.Speech.Recognition.GrammarBuilder%5B%5D%29> wird mithilfe <xref:System.Speech.Recognition.GrammarBuilder> der-Methode mit-Instanzen aufgefüllt. Die <xref:System.Speech.Recognition.GrammarBuilder> -Instanzen werden über die <xref:System.Speech.Recognition.SemanticResultKey.ToGrammarBuilder> -Methode für <xref:System.Speech.Recognition.SemanticResultValue> die Objekte abgerufen, die aus Farb Zeichenfolgen erstellt wurden.  
  
 Eine <xref:System.Speech.Recognition.GrammarBuilder> wird dann durch Aufrufen <xref:System.Speech.Recognition.SemanticResultKey.ToGrammarBuilder> von für eine <xref:System.Speech.Recognition.SemanticResultKey> -Instanz abgerufen, die zum Schlüssel der semantischen Auswahl in `colorChoice`verwendet wird.  
  
```csharp  
  
private Grammar CreateGrammarBuilderRGBSemantics()   
{  
  
  // Create a set of choices, each a lookup from a color name to RGB.  
  // Choices constructors do not take SemanticResultValue parameters, so cast   
  // the SemanticResultValue to GrammarBuilder.  
  Choices colorChoice = new Choices();  
  foreach (string colorName in System.Enum.GetNames(typeof(KnownColor)))   
  {  
    SemanticResultValue colorValue=new SemanticResultValue(colorName, Color.FromName(colorName).ToArgb());  
  
    // Use implicit conversion of SemanticResultValue to GrammarBuilder.  
    colorChoice.Add(colorValue.ToGrammarBuilder());      
  }  
  SemanticResultKey choiceKey = new SemanticResultKey("rgb", colorChoice);  
  GrammarBuilder choiceBuilder = choiceKey.ToGrammarBuilder();  
  
  // Create two intermediate grammars with introductory phrase and the color choice.  
  GrammarBuilder makeBackgroundBuilder = "Make background";  
  makeBackgroundBuilder.Append(choiceBuilder);  
  
  GrammarBuilder configureBackgroundBuilder = new GrammarBuilder("Configure background as");  
  configureBackgroundBuilder.Append((new SemanticResultKey("rgb", colorChoice)).ToGrammarBuilder());  
  
  // Create the Grammar object, which recognizes either intermediate grammar.  
  Grammar grammar = new Grammar(new Choices(new GrammarBuilder[] {makeBackgroundBuilder, configureBackgroundBuilder}));  
  grammar.Name = "Make Background /Configure background as";  
  
  return grammar;  
}  
  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
  </Members>
</Type>
