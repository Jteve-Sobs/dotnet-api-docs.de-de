<Type Name="PromptBuilder" FullName="System.Speech.Synthesis.PromptBuilder">
  <Metadata><Meta Name="ms.openlocfilehash" Value="14118e75456eed1da06612825ae9e28e57c83a9f" /><Meta Name="ms.sourcegitcommit" Value="1654a92bac785a221098172d9cacd405ceaac9b7" /><Meta Name="ms.translationtype" Value="HT" /><Meta Name="ms.contentlocale" Value="de-DE" /><Meta Name="ms.lasthandoff" Value="12/01/2018" /><Meta Name="ms.locfileid" Value="52739036" /></Metadata><TypeSignature Language="C#" Value="public class PromptBuilder" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi serializable beforefieldinit PromptBuilder extends System.Object" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Synthesis.PromptBuilder" />
  <TypeSignature Language="VB.NET" Value="Public Class PromptBuilder" />
  <TypeSignature Language="C++ CLI" Value="public ref class PromptBuilder" />
  <TypeSignature Language="F#" Value="type PromptBuilder = class" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>3.0.0.0</AssemblyVersion>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Object</BaseTypeName>
  </Base>
  <Interfaces />
  <Attributes>
    <Attribute FrameworkAlternate="netframework-3.0;netframework-3.5;netframework-4.0;netframework-4.5;netframework-4.5.1;netframework-4.5.2;netframework-4.6;netframework-4.6.1;netframework-4.6.2;netframework-4.7;netframework-4.7.1;netframework-4.7.2;netframework-4.8">
      <AttributeName>System.Serializable</AttributeName>
    </Attribute>
  </Attributes>
  <Docs>
    <summary>Erstellt ein leeres <see cref="T:System.Speech.Synthesis.Prompt" />-Objekt und stellt Methoden zum Hinzufügen von Inhalt, Auswählen von Stimmen, das Steuern von Stimmenattributen und das Steuern der Aussprache der gesprochenen Wörter bereit.</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Mit <xref:System.Speech.Synthesis.PromptBuilder>, können Sie hinzufügen, eine Vielzahl von Inhaltstypen zu einer Eingabeaufforderung den nur-Text, die SSML-Code (als eine Zeichenfolge oder eine Datei), einschließlich aufgezeichnet, Audio oder sogar einen anderen <xref:System.Speech.Synthesis.PromptBuilder> Objekt.  
  
 Zum Anfügen von Text auf einer <xref:System.Speech.Synthesis.PromptBuilder> Objekt aus, und optional stimmenattributen steuern, wie z. B. Betonung, Rate und Lautstärke, verwenden eines der <xref:System.Speech.Synthesis.PromptBuilder.AppendText%2A> Methoden.  Sie können auch stimmenattributen steuern, wie eine Gruppe mit der <xref:System.Speech.Synthesis.PromptBuilder.StartStyle%2A> und <xref:System.Speech.Synthesis.PromptBuilder.EndStyle%2A> Methoden.  
  
 Können Sie Text Anfügen und steuern, gesprochenen und wie es ausgesprochen wird mithilfe der <xref:System.Speech.Synthesis.PromptBuilder.AppendTextWithHint%2A>, <xref:System.Speech.Synthesis.PromptBuilder.AppendTextWithAlias%2A>, <xref:System.Speech.Synthesis.PromptBuilder.AppendTextWithPronunciation%2A>, <xref:System.Speech.Synthesis.PromptBuilder.AppendSsml%2A>, oder <xref:System.Speech.Synthesis.PromptBuilder.AppendSsmlMarkup%2A> Methoden.  
  
 Ändern Sie den aktuell ausgewählte Stimme in der Eingabeaufforderung mithilfe einer der überladenen <xref:System.Speech.Synthesis.PromptBuilder.StartVoice%2A> Voice-Merkmale, z. B. Alter und Geschlecht erforderlich, Methoden, benennen eine bestimmte Stimme verwenden oder angeben.  
  
 Zum Generieren einer Sprachausgabe aus einem <xref:System.Speech.Synthesis.PromptBuilder> Objekt ist, können Sie es als Argument übergeben die <xref:System.Speech.Synthesis.SpeechSynthesizer.Speak%2A> Methode.  
  
 Weitere Informationen finden Sie unter [erstellen eine komplexe Eingabeaufforderung](https://docs.microsoft.com/previous-versions/office/developer/speech-technologies/hh361616(v%3doffice.14)).  
  
 ]]></format>
    </remarks>
  </Docs>
  <Members>
    <MemberGroup MemberName=".ctor">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Erstellt eine neue Instanz der <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Klasse.</summary>
      </Docs>
    </MemberGroup>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public PromptBuilder ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.#ctor" />
      <MemberSignature Language="VB.NET" Value="Public Sub New ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; PromptBuilder();" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters />
      <Docs>
        <summary>Erstellt eine neue Instanz der <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Klasse.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Examples  
 Das folgende Beispiel erstellt ein neues <xref:System.Speech.Synthesis.PromptBuilder> -Instanz und fügt eine Textzeichenfolge hinzu.  
  
```csharp  
using System.Speech.Synthesis;  
  
public void MySimpleText ()  
{  
    PromptBuilder builder = new PromptBuilder ();  
    builder.AppendText("Hello world!");  
}  
```  
  
 Das folgende Markup zeigt die Entsprechung in Speech Synthesis Markup Language (SSML) (`xml:lang` ist ein erforderliches Attribut des der `speak` Element):  
  
```xml  
<speak version="1.0"  
 xmlns="http://www.w3.org/2001/10/synthesis" xml:lang="en-US">  
  Hello world!  
</speak>  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public PromptBuilder (System.Globalization.CultureInfo culture);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(class System.Globalization.CultureInfo culture) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.#ctor(System.Globalization.CultureInfo)" />
      <MemberSignature Language="VB.NET" Value="Public Sub New (culture As CultureInfo)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; PromptBuilder(System::Globalization::CultureInfo ^ culture);" />
      <MemberSignature Language="F#" Value="new System.Speech.Synthesis.PromptBuilder : System.Globalization.CultureInfo -&gt; System.Speech.Synthesis.PromptBuilder" Usage="new System.Speech.Synthesis.PromptBuilder culture" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="culture" Type="System.Globalization.CultureInfo" />
      </Parameters>
      <Docs>
        <param name="culture">Enthält Informationen über eine bestimmte Kultur, wie ihre Sprache, den Namen der Kultur, das Schreibsystem, den verwendeten Kalender und darüber, wie Datumsangaben formatiert und Zeichenfolgen sortiert werden.</param>
        <summary>Erstellt eine neue Instanz der <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Klasse und gibt eine Kultur an.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Dieser Konstruktor legt den Wert für die <xref:System.Speech.Synthesis.PromptBuilder.Culture%2A> Eigenschaft. Die <xref:System.Speech.Synthesis.SpeechSynthesizer> Objekt versucht, eine installierte Stimme auswählen, die die angegebenen Sprache unterstützt die `culture` Parameter an die Eingabeaufforderung zu verarbeiten. Wenn eine Stimme mit der angegebenen Kultur gefunden wird, wird er verwendet werden. Wenn eine Stimme mit der angegebenen Kultur nicht gefunden werden kann, wird die standardmäßige Sprache verwendet werden.  
  
 Um die Wörter in der angegebenen Sprache richtig ausgesprochen der `culture` einer Sprachsynthese (Text-Sprach- oder TTS)-Engine die Sprache unterstützt-Parameter muss installiert sein. Eine installierte Vorlese-Engine wird eine Stimme aufgerufen. Rufen Sie Informationen darüber, welche stimmen zurück, die installiert werden für eine bestimmte Kultur mit der <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> Methode.  
  
 Microsoft Windows und die API "System.Speech" akzeptieren Sie alle gültigen Sprache / Land-Codes als Werte für `culture`. Die Vorlese-Engines, die mit den im Lieferumfang von Windows 7 unterstützen die folgenden Codes für Sprache / Land:  
  
-   En-US. Englisch (USA)  
  
-   zh-CN. Chinesisch (China)  
  
-   Zh-TW. Chinesisch (Taiwan)  
  
 Zwei Buchstaben bestehenden Sprachcodes, z. B. "En" sind ebenfalls zulässig.  
  
   
  
## Examples  
 Das folgende Beispiel erstellt eine <xref:System.Speech.Synthesis.PromptBuilder> -Instanz und gibt an, dessen <xref:System.Speech.Synthesis.PromptBuilder.Culture%2A>.  
  
```csharp  
using System.Speech.Synthesis;  
  
public void MySimpleText ()  
{  
    PromptBuilder builder = new PromptBuilder(new System.Globalization.CultureInfo("en-US"));  
    builder.AppendText("Hello world!");  
}  
```  
  
 Das folgende Markup zeigt die entsprechende SSML:  
  
```xml  
<speak version="1.0"  
 xmlns="http://www.w3.org/2001/10/synthesis" xml:lang="en-US">  
  Hello world!  
</speak>  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <MemberGroup MemberName="AppendAudio">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Fügt einem <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt eine angegebene Audiodatei an.</summary>
      </Docs>
    </MemberGroup>
    <Member MemberName="AppendAudio">
      <MemberSignature Language="C#" Value="public void AppendAudio (string path);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendAudio(string path) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendAudio(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendAudio (path As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendAudio(System::String ^ path);" />
      <MemberSignature Language="F#" Value="member this.AppendAudio : string -&gt; unit" Usage="promptBuilder.AppendAudio path" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="path" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="path">Der vollqualifizierte Pfad zu der Audiodatei.</param>
        <summary>Fügt die angegebene Audiodatei dem <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt an.</summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendAudio">
      <MemberSignature Language="C#" Value="public void AppendAudio (Uri audioFile);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendAudio(class System.Uri audioFile) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendAudio(System.Uri)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendAudio (audioFile As Uri)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendAudio(Uri ^ audioFile);" />
      <MemberSignature Language="F#" Value="member this.AppendAudio : Uri -&gt; unit" Usage="promptBuilder.AppendAudio audioFile" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="audioFile" Type="System.Uri" />
      </Parameters>
      <Docs>
        <param name="audioFile">URI für die Audiodatei.</param>
        <summary>Fügt die Audio-Datei am angegebenen URI an das <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt an.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Examples  
 Im folgenden Beispiel initialisiert eine neue Instanz der dem <xref:System.Speech.Synthesis.PromptBuilder> -Klasse und fügt dann Text, gefolgt von einer Audiodatei.  
  
```csharp  
using System.Speech.PromptBuilder;  
  
public void SimpleConcatenation()  
{  
    // Add a prompt fragment from a .wav file.  
    PromptBuilder builder = new PromptBuilder ();  
    builder.AppendText("How are you today?");  
    builder.AppendAudio(new Uri ("http://www.speech.microsoft.com/ding.wav"));  
}  
```  
  
 Das folgende Markup zeigt die entsprechende SSML-Code.  
  
```xml  
<speak xmlns="http://www.w3.org/2001/10/synthesis"  
       xmlns:ms="http://www.microsoft.com/speech/synthesis" xml:lang="en">  
  
  How are you today?  
  <audio src="http://www.speech.microsoft.com/ding.wav" />  
  
</speak>  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendAudio">
      <MemberSignature Language="C#" Value="public void AppendAudio (Uri audioFile, string alternateText);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendAudio(class System.Uri audioFile, string alternateText) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendAudio(System.Uri,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendAudio (audioFile As Uri, alternateText As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendAudio(Uri ^ audioFile, System::String ^ alternateText);" />
      <MemberSignature Language="F#" Value="member this.AppendAudio : Uri * string -&gt; unit" Usage="promptBuilder.AppendAudio (audioFile, alternateText)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="audioFile" Type="System.Uri" />
        <Parameter Name="alternateText" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="audioFile">URI für die Audiodatei.</param>
        <param name="alternateText">Eine Zeichenfolge, die den alternativen Text enthält, der das Audio darstellt.</param>
        <summary>Fügt die angegebene Audiodatei und den alternativen Text an das <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt an.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Die Sprachsynthese-Engine wird der alternative Text gesprochen, wenn die Audiodatei nicht wiedergegeben werden kann.  
  
   
  
## Examples  
 In den folgenden Beispielen Fügt eine Audiodatei, eine <xref:System.Speech.Synthesis.PromptBuilder> -Instanz und gibt Text an, zu sprechen, wenn die Audiodatei nicht wiedergegeben werden kann.  
  
```csharp  
using System.Speech.PromptBuilder;  
  
public void SimpleConcatenation()  
{  
  
    // Concatenate a prompt fragment from a .wav file.  
    PromptBuilder builder = new PromptBuilder ();  
    builder.AppendAudio(new Uri ("C:\\OnHold.wav"), "Your call will be answered in the order it was received");  
}  
```  
  
 Das folgende Markup zeigt die entsprechende SSML-Code.  
  
```xml  
<speak xmlns="http://www.w3.org/2001/10/synthesis"  
       xmlns:ms="http://www.microsoft.com/speech/synthesis" xml:lang="en">  
  
  <audio src="C:\OnHold.wav"> Your call will be answered in the order it was received. </audio>  
  
</speak>  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendBookmark">
      <MemberSignature Language="C#" Value="public void AppendBookmark (string bookmarkName);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendBookmark(string bookmarkName) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendBookmark(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendBookmark (bookmarkName As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendBookmark(System::String ^ bookmarkName);" />
      <MemberSignature Language="F#" Value="member this.AppendBookmark : string -&gt; unit" Usage="promptBuilder.AppendBookmark bookmarkName" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="bookmarkName" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="bookmarkName">Eine Zeichenfolge mit dem Namen des angefügten Lesezeichens.</param>
        <summary>Fügt ein Lesezeichen an das <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt an.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Wird zu eine sprachesynthese-Engine generieren eine <xref:System.Speech.Synthesis.SpeechSynthesizer.BookmarkReached> Ereignis, wenn es beim Sprechen einer Eingabeaufforderung mit einer der auf ein Lesezeichen trifft die <xref:System.Speech.Synthesis.SpeechSynthesizer.Speak%2A>, <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync%2A>, <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsml%2A>, oder <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsmlAsync%2A> Methoden.  
  
   
  
## Examples  
 Das folgende Beispiel erstellt eine Eingabeaufforderung, die enthält zwei Lesezeichen und sendet die Ausgabe an eine WAV-Datei für die Wiedergabe. Der Handler für die <xref:System.Speech.Synthesis.SpeechSynthesizer.BookmarkReached> Ereignis schreibt den Namen des Lesezeichens und seine Position im Audiostream aus, wenn das Ereignis, an die Konsole ausgelöst wurde.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToWaveFile(@"C:\test\weather.wav");  
  
        // Create a SoundPlayer instance to play the output audio file.  
        System.Media.SoundPlayer m_SoundPlayer =  
          new System.Media.SoundPlayer(@"C:\test\weather.wav");  
  
        // Build a prompt and append bookmarks.  
        PromptBuilder builder = new PromptBuilder(  
          new System.Globalization.CultureInfo("en-US"));  
        builder.AppendText(  
          "The weather forecast for today is partly cloudy with some sun breaks.");  
        builder.AppendBookmark("Daytime forecast");  
        builder.AppendText(  
          "Tonight's weather will be cloudy with a 30% chance of showers.");  
        builder.AppendBookmark("Nightime forecast");  
  
        // Add a handler for the BookmarkReached event.  
        synth.BookmarkReached +=  
          new EventHandler<BookmarkReachedEventArgs>(synth_BookmarkReached);  
  
        // Speak the prompt and play back the output file.  
        synth.Speak(builder);  
        m_SoundPlayer.Play();  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Write the name and position of the bookmark to the console.  
    static void synth_BookmarkReached(object sender, BookmarkReachedEventArgs e)  
    {  
      Console.WriteLine("Bookmark ({0}) reached at: {1} ",  
        e.Bookmark, e.AudioPosition);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <MemberGroup MemberName="AppendBreak">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Fügt eine Unterbrechung (Anhalten) im Inhalt eines <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekts ein.</summary>
      </Docs>
    </MemberGroup>
    <Member MemberName="AppendBreak">
      <MemberSignature Language="C#" Value="public void AppendBreak ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendBreak() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendBreak" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendBreak ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendBreak();" />
      <MemberSignature Language="F#" Value="member this.AppendBreak : unit -&gt; unit" Usage="promptBuilder.AppendBreak " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Fügt dem <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt eine Unterbrechung an.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Diese Methode gibt keine Dauer für die Unterbrechung an. Die <xref:System.Speech.Synthesis.SpeechSynthesizer> einen Duration-Wert, der basierend auf den Sprachkontext bestimmt.  
  
   
  
## Examples  
 Im folgenden Beispiel erstellt eine Eingabeaufforderung mit zwei Sätzen, die durch eine Unterbrechung getrennt und der aus, um das Standardaudiogerät auf dem Computer spricht.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Build a prompt with two sentences separated by a break.  
        PromptBuilder builder = new PromptBuilder(  
          new System.Globalization.CultureInfo("en-US"));  
        builder.AppendText(  
          "Tonight's movie showings in theater A are at 5:45, 7:15, and 8:45.");  
        builder.AppendBreak();  
        builder.AppendText(  
          "Tonight's movie showings in theater B are at 5:15, 7:30, and 9:15.");  
  
        // Speak the prompt.  
        synth.Speak(builder);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendBreak">
      <MemberSignature Language="C#" Value="public void AppendBreak (System.Speech.Synthesis.PromptBreak strength);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendBreak(valuetype System.Speech.Synthesis.PromptBreak strength) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendBreak(System.Speech.Synthesis.PromptBreak)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendBreak (strength As PromptBreak)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendBreak(System::Speech::Synthesis::PromptBreak strength);" />
      <MemberSignature Language="F#" Value="member this.AppendBreak : System.Speech.Synthesis.PromptBreak -&gt; unit" Usage="promptBuilder.AppendBreak strength" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="strength" Type="System.Speech.Synthesis.PromptBreak" />
      </Parameters>
      <Docs>
        <param name="strength">Gibt die Dauer der Unterbrechung an, mit den folgenden Erhöhungswerten:</param>
        <summary>Fügt dem <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt eine Unterbrechung an und gibt die Stärke (Dauer) an.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Die Werte in der <xref:System.Speech.Synthesis.PromptBreak> Enumeration stellen einen Bereich der Trennung Intervalle (pausiert) zwischen Wortgrenzen dar. Die Sprachsynthese-Engine bestimmt die genaue Dauer des Intervalls. Wenn eine Unterbrechung angefordert wird, wird einen der folgenden Werte für die Sprachwiedergabe von Text-Engine (TTS) übergeben, die eine Zuordnung zwischen diesen Werten und die entsprechenden Millisekunde Break-Werte enthält.  
  
   
  
## Examples  
 Im folgenden Beispiel wird eine Eingabeaufforderung mit zwei Sätzen, die durch eine Unterbrechung getrennt erstellt und sendet die Ausgabe an eine WAV-Datei für die Wiedergabe.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToWaveFile(@"C:\test\weather.wav");  
  
        // Create a SoundPlayer instance to play the output audio file.  
        System.Media.SoundPlayer m_SoundPlayer =  
          new System.Media.SoundPlayer(@"C:\test\weather.wav");  
  
        // Build a prompt with two sentences separated by a break.  
        PromptBuilder builder = new PromptBuilder(  
          new System.Globalization.CultureInfo("en-US"));  
        builder.AppendText(  
          "Tonight's movie showings in theater A are at 5:45, 7:15, and 8:45");  
        builder.AppendBreak(PromptBreak.Medium);  
        builder.AppendText(  
          "Tonight's movie showings in theater B are at 5:15, 7:15, and 9:15");  
  
        // Speak the prompt and play back the output file.  
        synth.Speak(builder);  
        m_SoundPlayer.Play();  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendBreak">
      <MemberSignature Language="C#" Value="public void AppendBreak (TimeSpan duration);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendBreak(valuetype System.TimeSpan duration) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendBreak(System.TimeSpan)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendBreak (duration As TimeSpan)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendBreak(TimeSpan duration);" />
      <MemberSignature Language="F#" Value="member this.AppendBreak : TimeSpan -&gt; unit" Usage="promptBuilder.AppendBreak duration" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="duration" Type="System.TimeSpan" />
      </Parameters>
      <Docs>
        <param name="duration">Die Zeit in Ticks, wobei ein Tick 100 Nanosekunden entspricht.</param>
        <summary>Fügt an das <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt eine Unterbrechung der angegebenen Dauer an.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Ein Umbruch kann verwendet werden, um Pausen oder andere prosodische Grenzen zwischen Wörtern zu steuern. Ein Umbruch ist optional. Wenn eine Unterbrechung nicht vorhanden ist, bestimmt der Synthesizer die Pause zwischen den Wörtern, je nach den Sprachkontext an.  
  
   
  
## Examples  
 Im folgenden Beispiel wird eine Eingabeaufforderung, enthält zwei Sätze, getrennt durch eine Unterbrechung der 15,000,000 Ticks (1,5 Sekunden) erstellt und der aus, um das Standardaudiogerät auf dem Computer spricht.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Build a prompt with two sentences separated by a break.  
        PromptBuilder builder = new PromptBuilder(  
          new System.Globalization.CultureInfo("en-US"));  
        builder.AppendText(  
          "Tonight's movie showings in theater A are at 5:45, 7:15, and 8:45");  
        builder.AppendBreak(new TimeSpan(15000000));  
        builder.AppendText(  
          "Tonight's movie showings in theater B are at 5:15, 7:15, and 9:15");  
  
        // Speak the prompt.  
        synth.Speak(builder);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendPromptBuilder">
      <MemberSignature Language="C#" Value="public void AppendPromptBuilder (System.Speech.Synthesis.PromptBuilder promptBuilder);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendPromptBuilder(class System.Speech.Synthesis.PromptBuilder promptBuilder) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendPromptBuilder(System.Speech.Synthesis.PromptBuilder)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendPromptBuilder(System::Speech::Synthesis::PromptBuilder ^ promptBuilder);" />
      <MemberSignature Language="F#" Value="member this.AppendPromptBuilder : System.Speech.Synthesis.PromptBuilder -&gt; unit" Usage="promptBuilder.AppendPromptBuilder promptBuilder" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="promptBuilder" Type="System.Speech.Synthesis.PromptBuilder" />
      </Parameters>
      <Docs>
        <param name="promptBuilder">Der Inhalt, der angefügt werden soll.</param>
        <summary>Fügt ein <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt an ein anderes <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt an.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Examples  
 Das folgende Beispiel erstellt zwei <xref:System.Speech.Synthesis.PromptBuilder> Instanzen und fügt diese an eine dritte <xref:System.Speech.Synthesis.PromptBuilder>.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToWaveFile(@"C:\test\showtimes.wav");  
  
        // Create a SoundPlayer instance to play the output audio file.  
        System.Media.SoundPlayer m_SoundPlayer =  
          new System.Media.SoundPlayer(@"C:\test\showtimes.wav");  
  
        // Build child prompts.  
        PromptBuilder theatreA = new PromptBuilder();  
        theatreA.AppendText(  
          "Tonight's movie showings in theater A are at 5:45, 7:15, and 9:30");  
        theatreA.AppendBreak(PromptBreak.Large);  
        PromptBuilder theatreB = new PromptBuilder();  
        theatreB.AppendText(  
          "Tonight's movie showings in theater B are at 5:15, 7:15, and 9:15");  
  
        // Build the parent prompt and append the two child prompts.  
        PromptBuilder showTimes = new PromptBuilder(  
          new System.Globalization.CultureInfo("en-US"));  
        showTimes.AppendText(  
          "The following are the show times for tonight's movies:");  
        showTimes.AppendPromptBuilder(theatreA);  
        showTimes.AppendPromptBuilder(theatreB);  
  
        // Speak the prompt and play back the output file.  
        synth.Speak(showTimes);  
        m_SoundPlayer.Play();  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <MemberGroup MemberName="AppendSsml">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Fügt eine SSML-Datei an ein <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt an.</summary>
      </Docs>
    </MemberGroup>
    <Member MemberName="AppendSsml">
      <MemberSignature Language="C#" Value="public void AppendSsml (string path);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendSsml(string path) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendSsml(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendSsml (path As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendSsml(System::String ^ path);" />
      <MemberSignature Language="F#" Value="member this.AppendSsml : string -&gt; unit" Usage="promptBuilder.AppendSsml path" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="path" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="path">Ein vollqualifizierter Pfad zu der SSML-Datei, die angefügt werden soll.</param>
        <summary>Fügt die SSML-Datei am angegebenen Pfad an das <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt an.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Die SSML-Datei muss eine XML-Formatdatei entspricht der [Speech Synthesis Markup Language (SSML) Version 1.0](https://go.microsoft.com/fwlink/?LinkId=201763) Spezifikation.  
  
 Sie können auch die SSML-Markup als Zeichenfolge anfügen <xref:System.Speech.Synthesis.PromptBuilder.AppendSsmlMarkup%2A>.  
  
   
  
## Examples  
 Das folgende Beispiel erstellt eine <xref:System.Speech.Synthesis.PromptBuilder> -Objekt und fügt den Inhalt des eine SSML-Datei mit den <xref:System.Speech.Synthesis.PromptBuilder.AppendSsml%2A> Methode.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Create a PromptBuilder object and append a file that defines an SSML prompt.  
        PromptBuilder ssmlFile = new PromptBuilder();  
        ssmlFile.AppendSsml("c:\\test\\Weather.ssml");  
  
        // Speak the contents of the SSML prompt.  
        synth.Speak(ssmlFile);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 Im folgenden wird die SSML-Datei, die im vorherige Beispiel verweist.  
  
```xml  
<?xml version="1.0" encoding="ISO-8859-1"?>  
<speak version="1.0"  
 xmlns="http://www.w3.org/2001/10/synthesis"  
 xml:lang="en-US">  
  
  <s> The weather forecast for today is partly cloudy with some sun breaks. </s>  
  
</speak>  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendSsml">
      <MemberSignature Language="C#" Value="public void AppendSsml (Uri ssmlFile);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendSsml(class System.Uri ssmlFile) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendSsml(System.Uri)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendSsml (ssmlFile As Uri)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendSsml(Uri ^ ssmlFile);" />
      <MemberSignature Language="F#" Value="member this.AppendSsml : Uri -&gt; unit" Usage="promptBuilder.AppendSsml ssmlFile" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="ssmlFile" Type="System.Uri" />
      </Parameters>
      <Docs>
        <param name="ssmlFile">Ein vollqualifizierter URI zu der SSML-Datei, die angefügt werden soll.</param>
        <summary>Fügt die SSML-Datei am angegebenen URI an das <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt an.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Die SSML-Datei muss eine XML-Formatdatei entspricht der [Speech Synthesis Markup Language (SSML) Version 1.0](https://www.w3.org/TR/speech-synthesis/) Spezifikation.  
  
 Sie können auch die SSML-Markup als Zeichenfolge anfügen <xref:System.Speech.Synthesis.PromptBuilder.AppendSsmlMarkup%2A>.  
  
   
  
## Examples  
 Das folgende Beispiel erstellt eine <xref:System.Speech.Synthesis.PromptBuilder> -Objekt und fügt den Inhalt des eine SSML-Datei mit den <xref:System.Speech.Synthesis.PromptBuilder.AppendSsml%2A> Methode.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Create a PromptBuilder object and append a file that defines an SSML prompt.  
        PromptBuilder ssmlFile = new PromptBuilder();  
        ssmlFile.AppendSsml(new Uri("c:\\test\\Weather.ssml"));  
  
        // Speak the contents of the SSML prompt.  
        synth.Speak(ssmlFile);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
```  
  
 Im folgenden wird die SSML-Datei, die im vorherige Beispiel verweist.  
  
```xml  
<?xml version="1.0" encoding="ISO-8859-1"?>  
<speak version="1.0"  
 xmlns="http://www.w3.org/2001/10/synthesis"  
 xml:lang="en-US">  
  
  <s> The weather forecast for today is partly cloudy with some sun breaks. </s>  
  
</speak>  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendSsml">
      <MemberSignature Language="C#" Value="public void AppendSsml (System.Xml.XmlReader ssmlFile);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendSsml(class System.Xml.XmlReader ssmlFile) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendSsml(System.Xml.XmlReader)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendSsml (ssmlFile As XmlReader)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendSsml(System::Xml::XmlReader ^ ssmlFile);" />
      <MemberSignature Language="F#" Value="member this.AppendSsml : System.Xml.XmlReader -&gt; unit" Usage="promptBuilder.AppendSsml ssmlFile" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="ssmlFile" Type="System.Xml.XmlReader" />
      </Parameters>
      <Docs>
        <param name="ssmlFile">Der vollqualifizierte Name der XML-Datei, die angefügt werden soll.</param>
        <summary>Fügt ein <c>XMLReader</c>-Objekt an, das auf eine SSML-Eingabeaufforderung auf das <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt verweist.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Die SSML-Datei muss eine XML-Formatdatei entspricht der [Speech Synthesis Markup Language (SSML) Version 1.0](https://www.w3.org/TR/speech-synthesis/) Spezifikation.  
  
 Sie können auch die SSML-Markup als Zeichenfolge anfügen <xref:System.Speech.Synthesis.PromptBuilder.AppendSsmlMarkup%2A>.  
  
   
  
## Examples  
 Das folgende Beispiel erstellt eine <xref:System.Speech.Synthesis.PromptBuilder> -Objekt aus einer <xref:System.Xml.XmlReader> Objekt, das eine Datei mit Speech Synthesis Markup Language (SSML) Markup verweist.  
  
```csharp  
using System;  
using System.Xml;  
using System.IO;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToWaveFile(@"C:\test\weather.wav");  
  
        // Create a SoundPlayer instance to play the output audio file.  
        System.Media.SoundPlayer m_SoundPlayer =  
          new System.Media.SoundPlayer(@"C:\test\weather.wav");  
  
        // Create the path to the SSML file.  
        string weatherFile = Path.GetFullPath("c:\\test\\Weather.xml");  
        PromptBuilder builder = null;  
  
        // Create an XML Reader from the file, create a PromptBuilder and   
        // append the XmlReader.  
        if (File.Exists(weatherFile))  
        {  
          XmlReader reader = XmlReader.Create(weatherFile);  
          builder = new PromptBuilder();  
          builder.AppendSsml(reader);  
          reader.Close();  
        }  
  
        // Speak the prompt and play back the output file.  
        synth.Speak(builder);  
        m_SoundPlayer.Play();  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendSsmlMarkup">
      <MemberSignature Language="C#" Value="public void AppendSsmlMarkup (string ssmlMarkup);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendSsmlMarkup(string ssmlMarkup) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendSsmlMarkup(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendSsmlMarkup (ssmlMarkup As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendSsmlMarkup(System::String ^ ssmlMarkup);" />
      <MemberSignature Language="F#" Value="member this.AppendSsmlMarkup : string -&gt; unit" Usage="promptBuilder.AppendSsmlMarkup ssmlMarkup" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0;netframework-4.5;netframework-4.5.1;netframework-4.5.2;netframework-4.6;netframework-4.6.1;netframework-4.6.2;netframework-4.7;netframework-4.7.1;netframework-4.7.2;netframework-4.8">
          <AttributeName>System.ComponentModel.EditorBrowsable</AttributeName>
        </Attribute>
        <Attribute FrameworkAlternate="netframework-3.0;netframework-3.5">
          <AttributeName>System.ComponentModel.EditorBrowsable(System.ComponentModel.EditorBrowsableState.Advanced)</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="ssmlMarkup" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="ssmlMarkup">Eine Zeichenfolge, die SSML-Code enthält.</param>
        <summary>Fügt die angegebene Zeichenfolge, die SSML-Code enthält, an das <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt an.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Sie müssen die entsprechenden Escapezeichen verwenden, beim Anhängen der SSML-Code. Beachten Sie, dass die umgekehrten Schrägstriche vor den Wert des einschließenden Anführungszeichen der `interpret-as` Attribut im folgenden Beispiel:  
  
```csharp  
builder.AppendSsmlMarkup("<say-as interpret-as = \"characters\"> chair </say-as>");  
```  
  
> [!NOTE]
>  Die Zeichenfolge als Argument an <xref:System.Speech.Synthesis.PromptBuilder.AppendSsmlMarkup%2A> darf keine enthalten eine `speak` Element.  
  
 Bei Verwendung <xref:System.Speech.Synthesis.PromptBuilder.AppendSsmlMarkup%2A> , Inline-Aussprachen im eine `phoneme` Element können Sie Smartphones mithilfe eines der folgenden phonetischen Alphabete, vorausgesetzt, dass die aktuelle spracherkennungs-Engine unterstützt:  
  
-   Internationalen Lautalphabet (IPA)  
  
-   Universelle Phone Set (USV)  
  
-   SAPI-Phone-Satz  
  
 Engines, die SSML-kompatiblen Sprache wird Smartphones sprechen Sie über die IPA-Datei aus.  
  
 Sie können auch eine Datei mit einer der SSML-Code mit Anfügen der <xref:System.Speech.Synthesis.PromptBuilder.AppendSsml%2A> Methoden. Um den zu sprechenden Text anzufügen, die nicht mit Markupsprache formatiert ist, gehen die <xref:System.Speech.Synthesis.PromptBuilder.AppendText%2A>, <xref:System.Speech.Synthesis.PromptBuilder.AppendTextWithAlias%2A>, <xref:System.Speech.Synthesis.PromptBuilder.AppendTextWithHint%2A>, oder <xref:System.Speech.Synthesis.PromptBuilder.AppendTextWithPronunciation%2A> Methoden.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <MemberGroup MemberName="AppendText">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Fügt Text an das <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt an.</summary>
      </Docs>
    </MemberGroup>
    <Member MemberName="AppendText">
      <MemberSignature Language="C#" Value="public void AppendText (string textToSpeak);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendText(string textToSpeak) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendText(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendText (textToSpeak As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendText(System::String ^ textToSpeak);" />
      <MemberSignature Language="F#" Value="member this.AppendText : string -&gt; unit" Usage="promptBuilder.AppendText textToSpeak" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="textToSpeak" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="textToSpeak">Eine Zeichenfolge, die den zu sprechenden Text enthält.</param>
        <summary>Bezeichnet Text, der an das Objekt <see cref="T:System.Speech.Synthesis.PromptBuilder" /> anzufügen ist.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Verwenden Sie zum Anfügen von Text, die SSML-Markupsprache formatiert ist, <xref:System.Speech.Synthesis.PromptBuilder.AppendSsmlMarkup%2A>.  
  
   
  
## Examples  
 Das folgende Beispiel erstellt eine <xref:System.Speech.Synthesis.PromptBuilder> -Objekt und fügt eine Zeichenfolge mit Text die <xref:System.Speech.Synthesis.PromptBuilder.AppendText%2A> Methode.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Create a PromptBuilder object and append a text string.  
        PromptBuilder speakText = new PromptBuilder();  
        speakText.AppendText("Say the name of the song you want to hear");  
  
        // Speak the contents of the prompt.  
        synth.Speak(speakText);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendText">
      <MemberSignature Language="C#" Value="public void AppendText (string textToSpeak, System.Speech.Synthesis.PromptEmphasis emphasis);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendText(string textToSpeak, valuetype System.Speech.Synthesis.PromptEmphasis emphasis) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendText(System.String,System.Speech.Synthesis.PromptEmphasis)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendText (textToSpeak As String, emphasis As PromptEmphasis)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendText(System::String ^ textToSpeak, System::Speech::Synthesis::PromptEmphasis emphasis);" />
      <MemberSignature Language="F#" Value="member this.AppendText : string * System.Speech.Synthesis.PromptEmphasis -&gt; unit" Usage="promptBuilder.AppendText (textToSpeak, emphasis)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="textToSpeak" Type="System.String" />
        <Parameter Name="emphasis" Type="System.Speech.Synthesis.PromptEmphasis" />
      </Parameters>
      <Docs>
        <param name="textToSpeak">Eine Zeichenfolge, die den zu sprechenden Text enthält.</param>
        <param name="emphasis">Der auf den Text anzuwendende Wert für Nachdruck oder Betonung.</param>
        <summary>Fügt Text an das <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt an und gibt den Grad der Betonung für den Text an.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Den Schwerpunkt-Parameter zu diesem Zeitpunkt wird von der sprachesynthese-Engines in Windows nicht unterstützt. Festlegen von Werten für den Parameter für die Hervorhebung erzeugt keine akustische Änderung in der Ausgabe gebildeter Sprache.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendText">
      <MemberSignature Language="C#" Value="public void AppendText (string textToSpeak, System.Speech.Synthesis.PromptRate rate);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendText(string textToSpeak, valuetype System.Speech.Synthesis.PromptRate rate) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendText(System.String,System.Speech.Synthesis.PromptRate)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendText (textToSpeak As String, rate As PromptRate)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendText(System::String ^ textToSpeak, System::Speech::Synthesis::PromptRate rate);" />
      <MemberSignature Language="F#" Value="member this.AppendText : string * System.Speech.Synthesis.PromptRate -&gt; unit" Usage="promptBuilder.AppendText (textToSpeak, rate)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="textToSpeak" Type="System.String" />
        <Parameter Name="rate" Type="System.Speech.Synthesis.PromptRate" />
      </Parameters>
      <Docs>
        <param name="textToSpeak">Eine Zeichenfolge, die den zu sprechenden Text enthält.</param>
        <param name="rate">Der auf den Text anzuwendende Wert für die Sprechgeschwindigkeit.</param>
        <summary>Fügt Text an das <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt an und gibt die Sprechgeschwindigkeit für den Text an.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Examples  
 Das folgende Beispiel erstellt eine <xref:System.Speech.Synthesis.PromptBuilder> -Objekt und fügt Sie Textzeichenfolgen. Im Beispiel wird die <xref:System.Speech.Synthesis.PromptBuilder.AppendText%2A> Methode, um eine langsame Vorträge anzugeben rate für die Zeichenfolge, die hinzugefügt wird, der den Inhalt einer Bestellung aufgeführt.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Create a PromptBuilder object and add content.  
        PromptBuilder speakRate = new PromptBuilder();  
        speakRate.AppendText("Your order for");  
        speakRate.AppendText("one kitchen sink and one faucet", PromptRate.Slow);  
        speakRate.AppendText("has been confirmed.");  
  
        // Speak the contents of the SSML prompt.  
        synth.Speak(speakRate);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendText">
      <MemberSignature Language="C#" Value="public void AppendText (string textToSpeak, System.Speech.Synthesis.PromptVolume volume);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendText(string textToSpeak, valuetype System.Speech.Synthesis.PromptVolume volume) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendText(System.String,System.Speech.Synthesis.PromptVolume)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendText (textToSpeak As String, volume As PromptVolume)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendText(System::String ^ textToSpeak, System::Speech::Synthesis::PromptVolume volume);" />
      <MemberSignature Language="F#" Value="member this.AppendText : string * System.Speech.Synthesis.PromptVolume -&gt; unit" Usage="promptBuilder.AppendText (textToSpeak, volume)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="textToSpeak" Type="System.String" />
        <Parameter Name="volume" Type="System.Speech.Synthesis.PromptVolume" />
      </Parameters>
      <Docs>
        <param name="textToSpeak">Eine Zeichenfolge, die den zu sprechenden Text enthält.</param>
        <param name="volume">Der auf den Text anzuwendende Wert für die Sprecherlautstärke.</param>
        <summary>Fügt Text an das <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt an und gibt die Lautstärke an, mit der der Text gesprochen werden soll.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Die <xref:System.Speech.Synthesis.PromptVolume.Default> zum <xref:System.Speech.Synthesis.PromptVolume> volle Lautstärke, die die gleiche ist als <xref:System.Speech.Synthesis.PromptVolume.ExtraLoud>. Die anderen Einstellungen Verringern der Lautstärke der Sprachausgabe relativ zur vollen Volume.  
  
   
  
## Examples  
 Im folgenden Beispiel wird die <xref:System.Speech.Synthesis.PromptBuilder.AppendText%2A> Methode, um die Volumeeinstellungen angeben, die die <xref:System.Speech.Synthesis.SpeechSynthesizer> gelten für die Sprachausgabe.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Build a prompt that applies different volume settings.  
        PromptBuilder builder = new PromptBuilder();  
        builder.AppendText("This is the default speaking volume.", PromptVolume.Default);  
        builder.AppendBreak();  
        builder.AppendText("This is the extra loud speaking volume.", PromptVolume.ExtraLoud);  
        builder.AppendBreak();  
        builder.AppendText("This is the medium speaking volume.", PromptVolume.Medium);  
  
        // Speak the prompt.  
        synth.Speak(builder);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendTextWithAlias">
      <MemberSignature Language="C#" Value="public void AppendTextWithAlias (string textToSpeak, string substitute);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendTextWithAlias(string textToSpeak, string substitute) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendTextWithAlias(System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendTextWithAlias (textToSpeak As String, substitute As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendTextWithAlias(System::String ^ textToSpeak, System::String ^ substitute);" />
      <MemberSignature Language="F#" Value="member this.AppendTextWithAlias : string * string -&gt; unit" Usage="promptBuilder.AppendTextWithAlias (textToSpeak, substitute)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="textToSpeak" Type="System.String" />
        <Parameter Name="substitute" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="textToSpeak">Eine Zeichenfolge, die die Textdarstellung enthält.</param>
        <param name="substitute">Eine Zeichenfolge, die den zu sprechenden Text enthält.</param>
        <summary>Fügt Text an das <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt an und gibt den Aliastext an, der anstelle des angefügten Texts gesprochen werden soll.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Dadurch wird ein Dokument in einem gesprochenen und eine Schriftform für eine Aufforderung enthalten. Beispielsweise die geschriebene Form handelt es sich möglicherweise um ein Akronym, z. B. SAPI, und die gesprochene Form handelt es sich möglicherweise um den erweiterten Text für das Akronym, in diesem Fall Speech Application Programming Interface.  
  
   
  
## Examples  
 Das folgende Beispiel fügt eine Zeichenfolge ("Speech Synthesis Markup Language") und den Alias "" (SSML) an einen <xref:System.Speech.Synthesis.PromptBuilder> Objekt. Der Synthesizer wird "S, S, M, L" nachsehen.  
  
```  
PromptBuilder alias = new PromptBuilder();  
alias.AppendTextWithAlias("Speech Synthesis Markup Language","SSML");   
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <MemberGroup MemberName="AppendTextWithHint">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Fügt Text an das <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt an und gibt den Inhaltstyp des Texts an.</summary>
      </Docs>
    </MemberGroup>
    <Member MemberName="AppendTextWithHint">
      <MemberSignature Language="C#" Value="public void AppendTextWithHint (string textToSpeak, System.Speech.Synthesis.SayAs sayAs);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendTextWithHint(string textToSpeak, valuetype System.Speech.Synthesis.SayAs sayAs) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendTextWithHint(System.String,System.Speech.Synthesis.SayAs)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendTextWithHint(System::String ^ textToSpeak, System::Speech::Synthesis::SayAs sayAs);" />
      <MemberSignature Language="F#" Value="member this.AppendTextWithHint : string * System.Speech.Synthesis.SayAs -&gt; unit" Usage="promptBuilder.AppendTextWithHint (textToSpeak, sayAs)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="textToSpeak" Type="System.String" />
        <Parameter Name="sayAs" Type="System.Speech.Synthesis.SayAs" />
      </Parameters>
      <Docs>
        <param name="textToSpeak">Eine Zeichenfolge, die den zu sprechenden Text enthält.</param>
        <param name="sayAs">Der Inhaltstyps des Texts.</param>
        <summary>Fügt Text an das <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt an und gibt den Inhaltstyp mithilfe eines Members der <see cref="T:System.Speech.Synthesis.SayAs" />-Enumeration an.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Der Inhaltstyp, der anhand des `sayAs` bieten Anleitungen, die die Sprachsynthese-Engine dazu, wie Sie den Inhalt der auszusprechen `textToSpeak`.  
  
   
  
## Examples  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Create a PromptBuilder object and define the data types for some of the added strings.  
        PromptBuilder sayAs = new PromptBuilder();  
        sayAs.AppendText("Your");  
        sayAs.AppendTextWithHint("1st", SayAs.NumberOrdinal);  
        sayAs.AppendText("request was for");  
        sayAs.AppendTextWithHint("1", SayAs.NumberCardinal);  
        sayAs.AppendText("room, on");  
        sayAs.AppendTextWithHint("10/19/2012,", SayAs.MonthDayYear);  
        sayAs.AppendText("with early arrival at");  
        sayAs.AppendTextWithHint("12:35pm", SayAs.Time12);  
  
        // Speak the contents of the SSML prompt.  
        synth.Speak(sayAs);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendTextWithHint">
      <MemberSignature Language="C#" Value="public void AppendTextWithHint (string textToSpeak, string sayAs);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendTextWithHint(string textToSpeak, string sayAs) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendTextWithHint(System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendTextWithHint (textToSpeak As String, sayAs As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendTextWithHint(System::String ^ textToSpeak, System::String ^ sayAs);" />
      <MemberSignature Language="F#" Value="member this.AppendTextWithHint : string * string -&gt; unit" Usage="promptBuilder.AppendTextWithHint (textToSpeak, sayAs)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="textToSpeak" Type="System.String" />
        <Parameter Name="sayAs" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="textToSpeak">Eine Zeichenfolge, die den zu sprechenden Text enthält.</param>
        <param name="sayAs">Der Inhaltstyps des Texts.</param>
        <summary>Fügt Text an das <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt an und eine <see cref="T:System.String" />, die den Inhaltstyp des Texts angibt.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Sie können diese Methode verwenden, an einen Inhaltstyp, der nicht Bestandteil der <xref:System.Speech.Synthesis.SayAs> Enumeration. Allerdings muss die Vorlese-Engine den-Parameter unterstützt, den Sie angeben.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendTextWithPronunciation">
      <MemberSignature Language="C#" Value="public void AppendTextWithPronunciation (string textToSpeak, string pronunciation);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendTextWithPronunciation(string textToSpeak, string pronunciation) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendTextWithPronunciation(System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendTextWithPronunciation (textToSpeak As String, pronunciation As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendTextWithPronunciation(System::String ^ textToSpeak, System::String ^ pronunciation);" />
      <MemberSignature Language="F#" Value="member this.AppendTextWithPronunciation : string * string -&gt; unit" Usage="promptBuilder.AppendTextWithPronunciation (textToSpeak, pronunciation)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="textToSpeak" Type="System.String" />
        <Parameter Name="pronunciation" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="textToSpeak">Eine Zeichenfolge, die die im konventionellen Alphabet einer Sprache geschriebene Form des Worts enthält.</param>
        <param name="pronunciation">Eine Zeichenfolge, die die zu sprechenden Sprachlaute aus dem internationalen Lautalphabet (IPA) enthält.</param>
        <summary>Fügt Text an das <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt an und gibt die Aussprache für den Text an.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Synthesizers spricht, den Inhalt der `pronunciation` -Parameter, die nicht den Inhalt der `textToSpeak` Parameter.  
  
 Aussprache, die in den eingabeaufforderungen Inline angegeben gelten nur für die einzelnen Vorkommen eines Worts und außer Kraft setzen der Aussprache der die spracherkennungs-Engine oder eines der derzeit aktiven subjektivitätslexika. In der Regel verwenden Sie Inline Aussprache für benutzerdefinierte Aussprache der vorhandene Wörter oder für die Aussprache ungewöhnlich Wortarten, z. B. Eigennamen, die die Sprachsynthese-Engine kann keine ausgesprochen als auch erwartet.  
  
 Inline-Aussprache müssen mithilfe von Smartphones aus dem internationalen Lautalphabet (IPA) angegeben werden. Ein Telefon ist einem Buchstaben oder einer Zeichen, das einen diskret Sound der Sprache darstellt. Spracherkennungsmodule, die die Einhaltung der [Speech Synthesis Markup Language (SSML) Version 1.0](https://go.microsoft.com/fwlink/?LinkId=201763) Spezifikation wird ein Smartphone mit der die IPA-Datei nachsehen. Inline-Aussprache, die mit anderen phonetischen Alphabete angeben zu können, finden Sie unter <xref:System.Speech.Synthesis.PromptBuilder.AppendSsmlMarkup%2A>.  
  
 Veröffentlicht die IPA-Datei eine [Diagramm](https://go.microsoft.com/fwlink/?LinkId=58362) , listet die Telefone und ordnet diese den Unicode-Ziffern.  
  
 Einige Telefone im Alphabet IPA-Datei haben die gleichen Darstellungen als Buchstaben im lateinischen Alphabet an. In diesen Fällen ist es möglich, geben Sie die lateinischen Zeichensatz und die ordnungsgemäße Darstellung für ein Smartphone aufweisen. Da die lateinischen Zeichen, wie häufig im Text-Format verwendet verschiedene Smartphones des Satzes Phone IPA-Datei darstellen können, kann nicht einfach die lateinische Zeichen eingeben im gewünschten präzise IPA Phone führen. Andere Telefone Alphabet IPA-Datei müssen im Code als dargestellt werden Zeichen Verweise, die mit einem kaufmännischen und-Zeichen (&), Nummernzeichen (#), und eine Unicode-Zahl für das gewünschte Smartphone in Hexadezimal oder Dezimal, alle durch ein Semikolon (;) folgt. Z. B. eine Schwa (&\#X0259;) durch dargestellt werden würde `&#x0259;`.  
  
 Um neue oder benutzerdefinierte Aussprachen nach mehreren Wörtern hinzuzufügen, z. B. auf express regionalen Dialekte oder zum Hinzufügen von Eigennamen oder Vokabular, das für eine Bildungseinrichtung oder medizinischen Disziplin spezifisch ist, erstellen Sie ein Lexikon und Hinzufügen der <xref:System.Speech.Synthesis.SpeechSynthesizer> mit <xref:System.Speech.Synthesis.SpeechSynthesizer.AddLexicon%2A>.  
  
   
  
## Examples  
 Im folgenden Beispiel initialisiert eine neue Instanz der dem <xref:System.Speech.Synthesis.PromptBuilder> Klasse. Es fügt die Zeichenfolge "Mein Name ist" an die Instanz. Schließlich Fügt eine Zeichenfolge, die mit dem richtigen Namen "DuBois", und gibt die Aussprache des Namens.  
  
```csharp  
public void ProperName()  
{  
    PromptBuilder builder = new PromptBuilder();  
    builder.AppendText("My name is");  
  
    // Add a proper name and its pronunciation.  
    builder.AppendTextWithPronunciation("DuBois", "duˈbwɑ");     
}  
```  
  
 Das folgende Markup zeigt das SSML, das von diesem <xref:System.Speech.Synthesis.PromptBuilder> Objekt generiert.  
  
```xml  
<speak xmlns="http://www.w3.org/2001/10/synthesis" xml:lang="en-us">  
  My name is <phoneme ph="duˈbwɑ"> DuBois </phoneme>  
</speak>  
```  
  
 ]]></format>
        </remarks>
        <related type="ExternalDocumentation" href="https://go.microsoft.com/fwlink/?LinkId=58363">Internationale phonetische Zuordnung</related>
      </Docs>
    </Member>
    <Member MemberName="ClearContent">
      <MemberSignature Language="C#" Value="public void ClearContent ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void ClearContent() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.ClearContent" />
      <MemberSignature Language="VB.NET" Value="Public Sub ClearContent ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void ClearContent();" />
      <MemberSignature Language="F#" Value="member this.ClearContent : unit -&gt; unit" Usage="promptBuilder.ClearContent " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Löscht den Inhalt des <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekts.</summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="Culture">
      <MemberSignature Language="C#" Value="public System.Globalization.CultureInfo Culture { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Globalization.CultureInfo Culture" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Synthesis.PromptBuilder.Culture" />
      <MemberSignature Language="VB.NET" Value="Public Property Culture As CultureInfo" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Globalization::CultureInfo ^ Culture { System::Globalization::CultureInfo ^ get(); void set(System::Globalization::CultureInfo ^ value); };" />
      <MemberSignature Language="F#" Value="member this.Culture : System.Globalization.CultureInfo with get, set" Usage="System.Speech.Synthesis.PromptBuilder.Culture" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>get: System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Globalization.CultureInfo</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Ruft die Kulturinformationen für das <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt ab oder legt diese fest.</summary>
        <value>To be added.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Die <xref:System.Speech.Synthesis.SpeechSynthesizer> Objekt versucht, eine installierte Stimme auswählen, die die angegebenen Sprache unterstützt die <xref:System.Speech.Synthesis.PromptBuilder.Culture%2A> Eigenschaft, um die Eingabeaufforderung zu verarbeiten. Wenn eine Stimme mit der angegebenen Kultur gefunden wird, wird er verwendet werden. Wenn eine Stimme mit der angegebenen Kultur nicht gefunden werden kann, wird die standardmäßige Sprache verwendet werden.  
  
 Eine Kultur kann auch angegeben werden, in der Eingabeaufforderung für einzelne Abschnitte von Inhalten mithilfe der <xref:System.Speech.Synthesis.PromptBuilder.StartVoice%2A>, <xref:System.Speech.Synthesis.PromptBuilder.StartParagraph%2A>, und <xref:System.Speech.Synthesis.PromptBuilder.StartSentence%2A> Methoden. Eine Kultur angegeben, für ein Teil des Inhalts mithilfe einer der oben genannten Methoden außer Kraft setzen, wird die <xref:System.Speech.Synthesis.PromptBuilder.Culture%2A> Eigenschaft zwar aktiviert ist, und die <xref:System.Speech.Synthesis.SpeechSynthesizer> wird versucht, eine installierte Stimme auswählen, die die angegebenen Sprache unterstützt die `culture` die Parameter der Methode.  
  
 Um die Wörter in der angegebenen Sprache richtig ausgesprochen der <xref:System.Speech.Synthesis.PromptBuilder.Culture%2A> einer Sprachsynthese (Text-Sprach- oder TTS)-Engine die Sprache unterstützt-Eigenschaft muss installiert sein. Eine installierte Vorlese-Engine wird eine Stimme aufgerufen. Rufen Sie Informationen darüber, welche stimmen zurück, die installiert werden für eine bestimmte Kultur mit der <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> Methode.  
  
 Microsoft Windows und die API "System.Speech" akzeptieren Sie alle gültigen Sprache / Land-Codes als Werte für `culture`. Die Vorlese-Engines, die mit den im Lieferumfang von Windows 7 unterstützen die folgenden Codes für Sprache / Land:  
  
-   En-US. Englisch (USA)  
  
-   zh-CN. Chinesisch (China)  
  
-   Zh-TW. Chinesisch (Taiwan)  
  
 Zwei Buchstaben bestehenden Sprachcodes, z. B. "En" sind ebenfalls zulässig.  Finden Sie unter [-Bezeichner Konstanten und Zeichenfolgen](https://msdn.microsoft.com/library/dd318693\(VS.85\).aspx) eine umfassende Liste von Sprachcodes.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="EndParagraph">
      <MemberSignature Language="C#" Value="public void EndParagraph ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void EndParagraph() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.EndParagraph" />
      <MemberSignature Language="VB.NET" Value="Public Sub EndParagraph ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void EndParagraph();" />
      <MemberSignature Language="F#" Value="member this.EndParagraph : unit -&gt; unit" Usage="promptBuilder.EndParagraph " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Bezeichnet das Ende eines Absatzes im <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Lange Anweisungen können menschliche Stimme eher gerendert werden, wenn sie in Sätze und Absätzen unterteilt werden. Ein Beispiel finden Sie unter <xref:System.Speech.Synthesis.PromptBuilder.StartParagraph%2A>.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="EndSentence">
      <MemberSignature Language="C#" Value="public void EndSentence ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void EndSentence() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.EndSentence" />
      <MemberSignature Language="VB.NET" Value="Public Sub EndSentence ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void EndSentence();" />
      <MemberSignature Language="F#" Value="member this.EndSentence : unit -&gt; unit" Usage="promptBuilder.EndSentence " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Bezeichnet das Ende eines Satzes im <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Lange Anweisungen können menschliche Stimme eher gerendert werden, wenn sie in Sätze und Absätzen unterteilt werden. Ein Beispiel finden Sie unter <xref:System.Speech.Synthesis.PromptBuilder.StartSentence%2A>.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="EndStyle">
      <MemberSignature Language="C#" Value="public void EndStyle ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void EndStyle() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.EndStyle" />
      <MemberSignature Language="VB.NET" Value="Public Sub EndStyle ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void EndStyle();" />
      <MemberSignature Language="F#" Value="member this.EndStyle : unit -&gt; unit" Usage="promptBuilder.EndStyle " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Bezeichnet das Ende eines Stils im <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Die <xref:System.Speech.Synthesis.PromptBuilder.EndStyle%2A> Methode beendet den aktuellen Sprachstil. Der Sprachstil setzt die Einstellung, die zuvor aktiviert war die <xref:System.Speech.Synthesis.PromptBuilder.StartStyle%2A> Methode initiiert eine neue Sprachstil. Ein Beispiel finden Sie unter <xref:System.Speech.Synthesis.PromptBuilder.StartStyle%2A>.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="EndVoice">
      <MemberSignature Language="C#" Value="public void EndVoice ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void EndVoice() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.EndVoice" />
      <MemberSignature Language="VB.NET" Value="Public Sub EndVoice ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void EndVoice();" />
      <MemberSignature Language="F#" Value="member this.EndVoice : unit -&gt; unit" Usage="promptBuilder.EndVoice " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Bezeichnet das Ende der Verwendung einer Stimme im <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Die <xref:System.Speech.Synthesis.PromptBuilder.EndVoice%2A> Methode wird die Verwendung des die aktuelle Stimme für die Sprachausgabe beendet. Die Stimme setzt die Einstellung, die zuvor aktiviert war die <xref:System.Speech.Synthesis.PromptBuilder.StartVoice%2A> Methode initiiert eine neue Stimme.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="IsEmpty">
      <MemberSignature Language="C#" Value="public bool IsEmpty { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance bool IsEmpty" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Synthesis.PromptBuilder.IsEmpty" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property IsEmpty As Boolean" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property bool IsEmpty { bool get(); };" />
      <MemberSignature Language="F#" Value="member this.IsEmpty : bool" Usage="System.Speech.Synthesis.PromptBuilder.IsEmpty" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Boolean</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Ruft ab, ob das <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt leer ist.</summary>
        <value>To be added.</value>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <MemberGroup MemberName="StartParagraph">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Bezeichnet den Anfang eines Absatzes im <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt; optional wird auch eine Sprache angegeben.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Lange Anweisungen können menschliche Stimme eher gerendert werden, wenn sie in Sätze und Absätzen unterteilt werden.  
  
 ]]></format>
        </remarks>
      </Docs>
    </MemberGroup>
    <Member MemberName="StartParagraph">
      <MemberSignature Language="C#" Value="public void StartParagraph ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void StartParagraph() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.StartParagraph" />
      <MemberSignature Language="VB.NET" Value="Public Sub StartParagraph ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void StartParagraph();" />
      <MemberSignature Language="F#" Value="member this.StartParagraph : unit -&gt; unit" Usage="promptBuilder.StartParagraph " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Bezeichnet das Anfang eines Absatzes im <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Lange Anweisungen können menschliche Stimme eher gerendert werden, wenn sie in Sätze und Absätzen unterteilt werden.  
  
   
  
## Examples  
 Das folgende Beispiel erstellt eine <xref:System.Speech.Synthesis.PromptBuilder> Objekt, fügt Inhalt an und ordnet den Inhalt in Abschnitte und Sätze.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Create a PromptBuilder object and add content as paragraphs and sentences.  
        PromptBuilder parSent = new PromptBuilder();  
        parSent.StartParagraph();  
        parSent.StartSentence();  
        parSent.AppendText("Introducing the sentence element.");  
        parSent.EndSentence();  
        parSent.StartSentence();  
        parSent.AppendText("You can use it to mark individual sentences.");  
        parSent.EndSentence();  
        parSent.EndParagraph();  
        parSent.StartParagraph();  
        parSent.AppendText("Another simple paragraph. Sentence structure in this paragraph" +  
          "is not explicitly marked.");  
        parSent.EndParagraph();  
  
        // Speak the contents of the SSML prompt.  
        synth.Speak(parSent);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="StartParagraph">
      <MemberSignature Language="C#" Value="public void StartParagraph (System.Globalization.CultureInfo culture);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void StartParagraph(class System.Globalization.CultureInfo culture) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.StartParagraph(System.Globalization.CultureInfo)" />
      <MemberSignature Language="VB.NET" Value="Public Sub StartParagraph (culture As CultureInfo)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void StartParagraph(System::Globalization::CultureInfo ^ culture);" />
      <MemberSignature Language="F#" Value="member this.StartParagraph : System.Globalization.CultureInfo -&gt; unit" Usage="promptBuilder.StartParagraph culture" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="culture" Type="System.Globalization.CultureInfo" />
      </Parameters>
      <Docs>
        <param name="culture">Enthält Informationen über eine bestimmte Kultur, wie die Sprache, den Namen der Kultur, das Schreibsystem, den verwendeten Kalender und darüber, wie Datumsangaben formatiert und Zeichenfolgen sortiert werden.</param>
        <summary>Bezeichnet den Anfang eines Absatzes in der angegebenen Kultur im <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Lange Anweisungen können menschliche Stimme eher gerendert werden, wenn sie in Sätze und Absätzen unterteilt werden.  
  
 Die `culture` -Parameter für einen Absatz unterschiedlich sein der <xref:System.Speech.Synthesis.PromptBuilder.Culture%2A> Eigenschaft der <xref:System.Speech.Synthesis.PromptBuilder> -Objekts an. Zwar aktiviert ist, den Wert des der `culture` Parameter überschreibt die <xref:System.Speech.Synthesis.PromptBuilder.Culture%2A> Eigenschaft. Die <xref:System.Speech.Synthesis.SpeechSynthesizer> wird versucht, eine installierte Stimme auswählen, die die angegebenen Sprache unterstützt die `culture` Parameter, den Absatz zu sprechen. Wenn eine Stimme mit der angegebenen Kultur gefunden wird, wird er verwendet werden. Wenn eine Stimme mit der angegebenen Kultur nicht gefunden werden kann, wird die standardmäßige Sprache verwendet werden. Beenden der Verwendung von Stimme gemäß <xref:System.Speech.Synthesis.PromptBuilder.StartParagraph%2A>, rufen Sie <xref:System.Speech.Synthesis.PromptBuilder.EndParagraph%2A>.  
  
 Um die Wörter in der angegebenen Sprache richtig ausgesprochen der `culture` einer Sprachsynthese (Text-Sprach- oder TTS)-Engine die Sprache unterstützt-Parameter muss installiert sein. Eine installierte Vorlese-Engine wird eine Stimme aufgerufen. Rufen Sie Informationen darüber, welche stimmen zurück, die installiert werden für eine bestimmte Kultur mit der <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> Methode.  
  
 Microsoft Windows und die API "System.Speech" akzeptieren Sie alle gültigen Sprache / Land-Codes als Werte für `culture`. Die Vorlese-Engines, die mit den im Lieferumfang von Windows 7 unterstützen die folgenden Codes für Sprache / Land:  
  
-   En-US. Englisch (USA)  
  
-   zh-CN. Chinesisch (China)  
  
-   Zh-TW. Chinesisch (Taiwan)  
  
 Zwei Buchstaben bestehenden Sprachcodes, z. B. "En" sind ebenfalls zulässig.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <MemberGroup MemberName="StartSentence">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Bezeichnet den Anfang eines Satzes im <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt; optional wird auch eine Sprache angegeben.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Lange Anweisungen können menschliche Stimme eher gerendert werden, wenn sie in Sätze und Absätzen unterteilt werden.  
  
 ]]></format>
        </remarks>
      </Docs>
    </MemberGroup>
    <Member MemberName="StartSentence">
      <MemberSignature Language="C#" Value="public void StartSentence ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void StartSentence() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.StartSentence" />
      <MemberSignature Language="VB.NET" Value="Public Sub StartSentence ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void StartSentence();" />
      <MemberSignature Language="F#" Value="member this.StartSentence : unit -&gt; unit" Usage="promptBuilder.StartSentence " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Bezeichnet den Anfang eines Satzes im <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Lange Anweisungen können menschliche Stimme eher gerendert werden, wenn sie in Sätze und Absätzen unterteilt werden.  
  
   
  
## Examples  
 Das folgende Beispiel erstellt eine <xref:System.Speech.Synthesis.PromptBuilder> Objekt, fügt Inhalt an und ordnet den Inhalt in Abschnitte und Sätze.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Create a PromptBuilder object and add content as paragraphs and sentences.  
        PromptBuilder parSent = new PromptBuilder();  
        parSent.StartParagraph();  
        parSent.StartSentence();  
        parSent.AppendText("Introducing the sentence element.");  
        parSent.EndSentence();  
        parSent.StartSentence();  
        parSent.AppendText("You can use it to mark individual sentences.");  
        parSent.EndSentence();  
        parSent.EndParagraph();  
        parSent.StartParagraph();  
        parSent.AppendText("Another simple paragraph. Sentence structure in this paragraph" +  
          "is not explicitly marked.");  
        parSent.EndParagraph();  
  
        // Speak the contents of the SSML prompt.  
        synth.Speak(parSent);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="StartSentence">
      <MemberSignature Language="C#" Value="public void StartSentence (System.Globalization.CultureInfo culture);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void StartSentence(class System.Globalization.CultureInfo culture) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.StartSentence(System.Globalization.CultureInfo)" />
      <MemberSignature Language="VB.NET" Value="Public Sub StartSentence (culture As CultureInfo)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void StartSentence(System::Globalization::CultureInfo ^ culture);" />
      <MemberSignature Language="F#" Value="member this.StartSentence : System.Globalization.CultureInfo -&gt; unit" Usage="promptBuilder.StartSentence culture" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="culture" Type="System.Globalization.CultureInfo" />
      </Parameters>
      <Docs>
        <param name="culture">Enthält Informationen über eine bestimmte Kultur, wie die Sprache, den Namen der Kultur, das Schreibsystem, den verwendeten Kalender und darüber, wie Datumsangaben formatiert und Zeichenfolgen sortiert werden.</param>
        <summary>Bezeichnet den Anfang eines Satzes in der angegebenen Kultur im <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Lange Anweisungen können menschliche Stimme eher gerendert werden, wenn sie in Sätze und Absätzen unterteilt werden.  
  
 Die `culture` -Parameter für einen Satz unterschiedlich sein der `culture` -Parameter für den Absatz, der den Satz enthält oder der <xref:System.Speech.Synthesis.PromptBuilder.Culture%2A> Eigenschaft der <xref:System.Speech.Synthesis.PromptBuilder> -Objekt, das diese enthält.  
  
 Zwar aktiviert ist, den Wert des der `culture` Parameter überschreibt die <xref:System.Speech.Synthesis.PromptBuilder.Culture%2A> Eigenschaft und die `culture` -Parameter für den Absatz, der den Satz enthält. Die <xref:System.Speech.Synthesis.SpeechSynthesizer> wird versucht, eine installierte Stimme auswählen, die die angegebenen Sprache unterstützt die `culture` Parameter, um den Satz zu sprechen. Wenn eine Stimme mit der angegebenen Kultur gefunden wird, wird er verwendet werden. Wenn eine Stimme mit der angegebenen Kultur nicht gefunden werden kann, wird die standardmäßige Sprache verwendet werden. Beenden der Verwendung von Stimme gemäß <xref:System.Speech.Synthesis.PromptBuilder.StartSentence%2A>, rufen Sie <xref:System.Speech.Synthesis.PromptBuilder.EndSentence%2A>.  
  
 Um die Wörter in der angegebenen Sprache richtig ausgesprochen der `culture` einer Sprachsynthese (Text-Sprach- oder TTS)-Engine die Sprache unterstützt-Parameter muss installiert sein. Eine installierte Vorlese-Engine wird eine Stimme aufgerufen. Rufen Sie Informationen darüber, welche stimmen zurück, die installiert werden für eine bestimmte Kultur mit der <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> Methode.  
  
 Microsoft Windows und die API "System.Speech" akzeptieren Sie alle gültigen Sprache / Land-Codes als Werte für `culture`. Die Vorlese-Engines, die mit den im Lieferumfang von Windows 7 unterstützen die folgenden Codes für Sprache / Land:  
  
-   En-US. Englisch (USA)  
  
-   zh-CN. Chinesisch (China)  
  
-   Zh-TW. Chinesisch (Taiwan)  
  
 Zwei Buchstaben bestehenden Sprachcodes, z. B. "En" sind ebenfalls zulässig.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="StartStyle">
      <MemberSignature Language="C#" Value="public void StartStyle (System.Speech.Synthesis.PromptStyle style);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void StartStyle(class System.Speech.Synthesis.PromptStyle style) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.StartStyle(System.Speech.Synthesis.PromptStyle)" />
      <MemberSignature Language="VB.NET" Value="Public Sub StartStyle (style As PromptStyle)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void StartStyle(System::Speech::Synthesis::PromptStyle ^ style);" />
      <MemberSignature Language="F#" Value="member this.StartStyle : System.Speech.Synthesis.PromptStyle -&gt; unit" Usage="promptBuilder.StartStyle style" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="style" Type="System.Speech.Synthesis.PromptStyle" />
      </Parameters>
      <Docs>
        <param name="style">Der zu startende Stil.</param>
        <summary>Bezeichnet den Anfang eines Stils im <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Die <xref:System.Speech.Synthesis.PromptBuilder.StartStyle%2A> -Methode übernimmt eine <xref:System.Speech.Synthesis.PromptStyle> Objekt als Argument. Können Sie die Eigenschaften der <xref:System.Speech.Synthesis.PromptStyle> Objekt zum Festlegen des Schwerpunkt, sprechgeschwindigkeit und Volumen (Lautstärke) anwenden, die in die Sprache, die ausgegeben werden, während das Format aktiviert ist. Um mit dem aktuellen Stil zu beenden, rufen die <xref:System.Speech.Synthesis.PromptBuilder.EndStyle%2A> Methode.  
  
> [!NOTE]
> -   Den Schwerpunkt-Parameter zu diesem Zeitpunkt wird von der sprachesynthese-Engines in Windows nicht unterstützt. Festlegen von Werten für den Parameter für die Hervorhebung erzeugt keine akustische Änderung in der Ausgabe gebildeter Sprache.  
> -   Die <xref:System.Speech.Synthesis.PromptVolume.Default> zum <xref:System.Speech.Synthesis.PromptVolume> volle Lautstärke, die die gleiche ist als <xref:System.Speech.Synthesis.PromptVolume.ExtraLoud>. Die anderen Einstellungen Verringern der Lautstärke der Sprachausgabe relativ zur vollen Volume.  
  
   
  
## Examples  
 Das folgende Beispiel erstellt eine <xref:System.Speech.Synthesis.PromptBuilder> -Objekt und fügt Sie Textzeichenfolgen. Im Beispiel wird die <xref:System.Speech.Synthesis.PromptBuilder.StartStyle%2A> Methode, um eine langsame Vorträge anzugeben rate für die Zeichenfolge, die hinzugefügt wird, der den Inhalt einer Bestellung aufgeführt.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Create a PromptBuilder object and add content.  
        PromptBuilder style = new PromptBuilder();  
        style.AppendText("Your order for");  
        style.StartStyle(new PromptStyle(PromptRate.Slow));  
        style.AppendText("one kitchen sink and one faucet");  
        style.EndStyle();  
        style.AppendText("has been confirmed.");  
  
        // Speak the contents of the SSML prompt.  
        synth.Speak(style);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <MemberGroup MemberName="StartVoice">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Weist den Synthesizer an, die Stimme in einem <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt zu ändern.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Eine Stimme stellt eine installierte Vorlese-Engine dar. Verwenden der <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> Methoden und <xref:System.Speech.Synthesis.VoiceInfo> Klasse den Namen und die Attribute der abzurufenden installiert Speech (TTS) stimmen zurück, die Sie auswählen können.  
  
 Wenn eine Anwendung ruft <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A>, die Methode überprüft, ob jeder der stimmen zurück, es in der Registrierung findet, bestimmte Mindestkriterien erfüllt. Für alle Stimme an, die Überprüfung schlägt fehl, <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> legt die <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> Eigenschaft, um `False`. Eine Anwendung kann nicht aufgerufen, eines der <xref:System.Speech.Synthesis.PromptBuilder.StartVoice%2A> Methoden für eine Stimme, deren <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> Eigenschaft `False`. Anwendungen werden in der Regel nicht Festlegen der Sprachnotizen <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> Eigenschaft.  
  
 ]]></format>
        </remarks>
      </Docs>
    </MemberGroup>
    <Member MemberName="StartVoice">
      <MemberSignature Language="C#" Value="public void StartVoice (System.Globalization.CultureInfo culture);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void StartVoice(class System.Globalization.CultureInfo culture) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.StartVoice(System.Globalization.CultureInfo)" />
      <MemberSignature Language="VB.NET" Value="Public Sub StartVoice (culture As CultureInfo)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void StartVoice(System::Globalization::CultureInfo ^ culture);" />
      <MemberSignature Language="F#" Value="member this.StartVoice : System.Globalization.CultureInfo -&gt; unit" Usage="promptBuilder.StartVoice culture" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="culture" Type="System.Globalization.CultureInfo" />
      </Parameters>
      <Docs>
        <param name="culture">Enthält Informationen über eine bestimmte Kultur, wie die Sprache, den Namen der Kultur, das Schreibsystem, den verwendeten Kalender und darüber, wie Datumsangaben formatiert und Zeichenfolgen sortiert werden.</param>
        <summary>Weist den Synthesizer an, die Stimme im <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt zu ändern und gibt die Kultur der zu verwendenden Stimme an.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Die `culture` -Parameter für <xref:System.Speech.Synthesis.PromptBuilder.StartVoice%2A> unterschiedlich sein der <xref:System.Speech.Synthesis.PromptBuilder.Culture%2A> Eigenschaft der <xref:System.Speech.Synthesis.PromptBuilder> -Objekts an.  Zwar aktiviert ist, den Wert des der `culture` Parameter überschreibt die <xref:System.Speech.Synthesis.PromptBuilder.Culture%2A> Eigenschaft. Die <xref:System.Speech.Synthesis.SpeechSynthesizer> wird versucht, eine installierte Stimme auswählen, die die angegebenen Sprache unterstützt die `culture` Parameter, um den Inhalt eingeschlossen sprechen <xref:System.Speech.Synthesis.PromptBuilder.StartVoice%2A> und <xref:System.Speech.Synthesis.PromptBuilder.EndVoice%2A>. Wenn eine Stimme mit der angegebenen Kultur gefunden wird, wird er verwendet werden. Wenn eine Stimme mit der angegebenen Kultur nicht gefunden werden kann, wird die standardmäßige Sprache verwendet werden. Beenden der Verwendung von Stimme gemäß <xref:System.Speech.Synthesis.PromptBuilder.StartVoice%2A>, rufen Sie <xref:System.Speech.Synthesis.PromptBuilder.EndVoice%2A>.  
  
 Um die Wörter in der angegebenen Sprache richtig ausgesprochen der `culture` einer Sprachsynthese (Text-Sprach- oder TTS)-Engine die Sprache unterstützt-Parameter muss installiert sein. Eine installierte Vorlese-Engine wird eine Stimme aufgerufen. Rufen Sie Informationen darüber, welche stimmen zurück, die installiert werden für eine bestimmte Kultur mit der <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> Methode.  
  
 Microsoft Windows und die API "System.Speech" akzeptieren Sie alle gültigen Sprache / Land-Codes als Werte für `culture`. Die Vorlese-Engines, die mit den im Lieferumfang von Windows 7 unterstützen die folgenden Codes für Sprache / Land:  
  
-   En-US. Englisch (USA)  
  
-   zh-CN. Chinesisch (China)  
  
-   Zh-TW. Chinesisch (Taiwan)  
  
 Zwei Buchstaben bestehenden Sprachcodes, z. B. "En" sind ebenfalls zulässig.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="StartVoice">
      <MemberSignature Language="C#" Value="public void StartVoice (System.Speech.Synthesis.VoiceGender gender);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void StartVoice(valuetype System.Speech.Synthesis.VoiceGender gender) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.StartVoice(System.Speech.Synthesis.VoiceGender)" />
      <MemberSignature Language="VB.NET" Value="Public Sub StartVoice (gender As VoiceGender)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void StartVoice(System::Speech::Synthesis::VoiceGender gender);" />
      <MemberSignature Language="F#" Value="member this.StartVoice : System.Speech.Synthesis.VoiceGender -&gt; unit" Usage="promptBuilder.StartVoice gender" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="gender" Type="System.Speech.Synthesis.VoiceGender" />
      </Parameters>
      <Docs>
        <param name="gender">Das Geschlecht der zu verwendenden Stimme.</param>
        <summary>Weist den Synthesizer an, die Stimme im <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt zu ändern und gibt das Geschlecht der zu verwendenden Stimme an.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Verwenden der <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> Methoden und <xref:System.Speech.Synthesis.VoiceInfo> Klasse den Namen und die Attribute der abzurufenden installiert Speech (TTS) stimmen zurück, die Sie auswählen können.  
  
 Beenden der Verwendung von Stimme gemäß <xref:System.Speech.Synthesis.PromptBuilder.StartVoice%2A> Aufrufen <xref:System.Speech.Synthesis.PromptBuilder.EndVoice%2A>.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="StartVoice">
      <MemberSignature Language="C#" Value="public void StartVoice (System.Speech.Synthesis.VoiceInfo voice);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void StartVoice(class System.Speech.Synthesis.VoiceInfo voice) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.StartVoice(System.Speech.Synthesis.VoiceInfo)" />
      <MemberSignature Language="VB.NET" Value="Public Sub StartVoice (voice As VoiceInfo)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void StartVoice(System::Speech::Synthesis::VoiceInfo ^ voice);" />
      <MemberSignature Language="F#" Value="member this.StartVoice : System.Speech.Synthesis.VoiceInfo -&gt; unit" Usage="promptBuilder.StartVoice voice" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="voice" Type="System.Speech.Synthesis.VoiceInfo" />
      </Parameters>
      <Docs>
        <param name="voice">Die Kriterien für die zu verwendende Stimme.</param>
        <summary>Weist den Synthesizer an, die Stimme im <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt zu ändern und gibt Kriterien für die neue Stimme an.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Verwenden der <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> Methoden und <xref:System.Speech.Synthesis.VoiceInfo> Klasse den Namen und die Attribute der abzurufenden installiert Speech (TTS) stimmen zurück, die Sie auswählen können.  
  
 Beenden der Verwendung von Stimme gemäß <xref:System.Speech.Synthesis.PromptBuilder.StartVoice%2A> Aufrufen <xref:System.Speech.Synthesis.PromptBuilder.EndVoice%2A>.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="StartVoice">
      <MemberSignature Language="C#" Value="public void StartVoice (string name);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void StartVoice(string name) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.StartVoice(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub StartVoice (name As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void StartVoice(System::String ^ name);" />
      <MemberSignature Language="F#" Value="member this.StartVoice : string -&gt; unit" Usage="promptBuilder.StartVoice name" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="name" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="name">Der Name der Stimme, die verwendet werden soll.</param>
        <summary>Weist den Synthesizer an, die Stimme im <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt zu ändern und gibt den Namen der zu verwendenden Stimme an.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Abrufen von Informationen über die stimmen werden installiert gehen die <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> Methoden.  
  
 Beenden der Verwendung von Stimme gemäß <xref:System.Speech.Synthesis.PromptBuilder.StartVoice%2A> Aufrufen <xref:System.Speech.Synthesis.PromptBuilder.EndVoice%2A>.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="StartVoice">
      <MemberSignature Language="C#" Value="public void StartVoice (System.Speech.Synthesis.VoiceGender gender, System.Speech.Synthesis.VoiceAge age);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void StartVoice(valuetype System.Speech.Synthesis.VoiceGender gender, valuetype System.Speech.Synthesis.VoiceAge age) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.StartVoice(System.Speech.Synthesis.VoiceGender,System.Speech.Synthesis.VoiceAge)" />
      <MemberSignature Language="VB.NET" Value="Public Sub StartVoice (gender As VoiceGender, age As VoiceAge)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void StartVoice(System::Speech::Synthesis::VoiceGender gender, System::Speech::Synthesis::VoiceAge age);" />
      <MemberSignature Language="F#" Value="member this.StartVoice : System.Speech.Synthesis.VoiceGender * System.Speech.Synthesis.VoiceAge -&gt; unit" Usage="promptBuilder.StartVoice (gender, age)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="gender" Type="System.Speech.Synthesis.VoiceGender" />
        <Parameter Name="age" Type="System.Speech.Synthesis.VoiceAge" />
      </Parameters>
      <Docs>
        <param name="gender">Das Geschlecht der neuen zu verwendenden Stimme.</param>
        <param name="age">Das Alter der zu verwendenden Stimme.</param>
        <summary>Weist den Synthesizer an, die Stimme im <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt zu ändern und gibt das Geschlecht und das Alter der neuen Stimme an.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Verwenden der <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> Methoden und <xref:System.Speech.Synthesis.VoiceInfo> Klasse den Namen und die Attribute der abzurufenden installiert Speech (TTS) stimmen zurück, die Sie auswählen können.  
  
 Beenden der Verwendung von Stimme gemäß <xref:System.Speech.Synthesis.PromptBuilder.StartVoice%2A> Aufrufen <xref:System.Speech.Synthesis.PromptBuilder.EndVoice%2A>.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="StartVoice">
      <MemberSignature Language="C#" Value="public void StartVoice (System.Speech.Synthesis.VoiceGender gender, System.Speech.Synthesis.VoiceAge age, int voiceAlternate);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void StartVoice(valuetype System.Speech.Synthesis.VoiceGender gender, valuetype System.Speech.Synthesis.VoiceAge age, int32 voiceAlternate) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.StartVoice(System.Speech.Synthesis.VoiceGender,System.Speech.Synthesis.VoiceAge,System.Int32)" />
      <MemberSignature Language="VB.NET" Value="Public Sub StartVoice (gender As VoiceGender, age As VoiceAge, voiceAlternate As Integer)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void StartVoice(System::Speech::Synthesis::VoiceGender gender, System::Speech::Synthesis::VoiceAge age, int voiceAlternate);" />
      <MemberSignature Language="F#" Value="member this.StartVoice : System.Speech.Synthesis.VoiceGender * System.Speech.Synthesis.VoiceAge * int -&gt; unit" Usage="promptBuilder.StartVoice (gender, age, voiceAlternate)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="gender" Type="System.Speech.Synthesis.VoiceGender" />
        <Parameter Name="age" Type="System.Speech.Synthesis.VoiceAge" />
        <Parameter Name="voiceAlternate" Type="System.Int32" />
      </Parameters>
      <Docs>
        <param name="gender">Das Geschlecht der zu verwendenden Stimme.</param>
        <param name="age">Das Alter der zu verwendenden Stimme.</param>
        <param name="voiceAlternate">Eine ganze Zahl, die eine bevorzugte Stimme angibt, wenn mehr als eine Stimme den <paramref name="gender" />- und <paramref name="age" />-Parametern entspricht.</param>
        <summary>Weist den Synthesizer an, die Stimme im <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt zu ändern und gibt ihr Geschlecht, Alter und eine bevorzugte Stimme an, die dem angegebenen Geschlecht und Alter entspricht.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Eine Sprachsynthese-Engine zählt die Übereinstimmungen, für den angegebenen Parametern wird erkannt und die Stimme zurückgegeben wird, wenn die Anzahl, der `voiceAlternate` Parameter.  
  
 Verwenden der <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> Methoden und <xref:System.Speech.Synthesis.VoiceInfo> Klasse den Namen und die Attribute der abzurufenden installiert Speech (TTS) stimmen zurück, die Sie auswählen können.  
  
 Beenden der Verwendung von Stimme gemäß <xref:System.Speech.Synthesis.PromptBuilder.StartVoice%2A> Aufrufen <xref:System.Speech.Synthesis.PromptBuilder.EndVoice%2A>.  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Synthesis.PromptBuilder.StartVoice(System.Speech.Synthesis.VoiceGender,System.Speech.Synthesis.VoiceAge)" />
      </Docs>
    </Member>
    <Member MemberName="ToXml">
      <MemberSignature Language="C#" Value="public string ToXml ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance string ToXml() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.ToXml" />
      <MemberSignature Language="VB.NET" Value="Public Function ToXml () As String" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; System::String ^ ToXml();" />
      <MemberSignature Language="F#" Value="member this.ToXml : unit -&gt; string" Usage="promptBuilder.ToXml " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.String</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Gibt das SSML zurück, das aus dem <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt generiert wird.</summary>
        <returns>Gibt das SSML zurück, das aus dem <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt als einzelne Zeile generiert wird.</returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Die <xref:System.Speech.Synthesis.PromptBuilder.ToXml%2A> Methode unternimmt keinen Versuch, den zurückgegebene SSML in irgendeiner Weise zu formatieren.  
  
   
  
## Examples  
 Das folgende Beispiel erstellt eine <xref:System.Speech.Synthesis.PromptBuilder> Objekt, fügt Text an und klicken Sie dann die SSML-Entsprechung der Eingabeaufforderung in die Konsole schreibt, vor dem der Inhalt der Eingabeaufforderung zu sprechen.  
  
```csharp  
  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Create a PromptBuilder object and add content.  
        PromptBuilder style = new PromptBuilder();  
        style.AppendText("Your order for");  
        style.StartStyle(new PromptStyle(PromptRate.Slow));  
        style.AppendText("one kitchen sink and one faucet");  
        style.EndStyle();  
        style.AppendText("has been confirmed.");  
  
        // Write the contents of the PromptBuilder object to the console as  
        // an SSML-compatible XML file.  
        string myXml = style.ToXml();  
        Console.WriteLine("This is the SSML equivalent of the PromptBuilder: \n\n" + myXml);  
  
        // Speak the contents of the SSML prompt.  
        synth.Speak(style);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
  </Members>
</Type>