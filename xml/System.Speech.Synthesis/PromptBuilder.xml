<Type Name="PromptBuilder" FullName="System.Speech.Synthesis.PromptBuilder">
  <Metadata><Meta Name="ms.openlocfilehash" Value="70c05fd64cf6cb3f9671ecfd65dd231ed3473dbf" /><Meta Name="ms.sourcegitcommit" Value="b53d35b4a410c949742abd4c6a989d1af5357bca" /><Meta Name="ms.translationtype" Value="MT" /><Meta Name="ms.contentlocale" Value="de-DE" /><Meta Name="ms.lasthandoff" Value="07/21/2020" /><Meta Name="ms.locfileid" Value="86826352" /></Metadata><TypeSignature Language="C#" Value="public class PromptBuilder" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi serializable beforefieldinit PromptBuilder extends System.Object" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Synthesis.PromptBuilder" />
  <TypeSignature Language="VB.NET" Value="Public Class PromptBuilder" />
  <TypeSignature Language="C++ CLI" Value="public ref class PromptBuilder" />
  <TypeSignature Language="F#" Value="type PromptBuilder = class" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>3.0.0.0</AssemblyVersion>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Object</BaseTypeName>
  </Base>
  <Interfaces />
  <Attributes>
    <Attribute>
      <AttributeName Language="C#">[System.Serializable]</AttributeName>
      <AttributeName Language="F#">[&lt;System.Serializable&gt;]</AttributeName>
    </Attribute>
  </Attributes>
  <Docs>
    <summary>Erstellt ein leeres <see cref="T:System.Speech.Synthesis.Prompt" />-Objekt und stellt Methoden zum Hinzufügen von Inhalt, Auswählen von Stimmen, das Steuern von Stimmenattributen und das Steuern der Aussprache der gesprochenen Wörter bereit.</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Mit <xref:System.Speech.Synthesis.PromptBuilder> können Sie einer Eingabeaufforderung eine Vielzahl von Inhaltstypen hinzufügen, einschließlich Klartext, SSML-Markup (als Zeichenfolge oder Datei), aufgezeichnete Audiodaten oder sogar ein anderes <xref:System.Speech.Synthesis.PromptBuilder> Objekt.  
  
 Verwenden Sie eine der-Methoden, um Text an ein <xref:System.Speech.Synthesis.PromptBuilder> -Objekt anzufügen und optional sprach Attribute wie Betonung, Rate und Volume zu steuern <xref:System.Speech.Synthesis.PromptBuilder.AppendText%2A> .  Sie können sprach Attribute auch als Gruppe mit der <xref:System.Speech.Synthesis.PromptBuilder.StartStyle%2A> -Methode und der- <xref:System.Speech.Synthesis.PromptBuilder.EndStyle%2A> Methode steuern.  
  
 Mithilfe der <xref:System.Speech.Synthesis.PromptBuilder.AppendTextWithHint%2A> <xref:System.Speech.Synthesis.PromptBuilder.AppendTextWithAlias%2A> Methoden,, <xref:System.Speech.Synthesis.PromptBuilder.AppendTextWithPronunciation%2A> ,  <xref:System.Speech.Synthesis.PromptBuilder.AppendSsml%2A> oder können Sie Text anfügen und Steuern, was gesprochen wird, oder wie er ausgesprochen wird <xref:System.Speech.Synthesis.PromptBuilder.AppendSsmlMarkup%2A> .  
  
 Ändern Sie die derzeit ausgewählte Sprechstimme in der Eingabeaufforderung, indem Sie eine der überladenen <xref:System.Speech.Synthesis.PromptBuilder.StartVoice%2A> Methoden verwenden, eine bestimmte Stimme benennen, die verwendet werden soll, oder die erforderlichen Sprachmerkmale wie Alter und Geschlecht angeben.  
  
 Um Sprache aus einem- <xref:System.Speech.Synthesis.PromptBuilder> Objekt zu generieren, können Sie Sie als Argument an die- <xref:System.Speech.Synthesis.SpeechSynthesizer.Speak%2A> Methode übergeben.  
  
 Weitere Informationen finden Sie unter [Erstellen einer komplexen Eingabeaufforderung](https://docs.microsoft.com/previous-versions/office/developer/speech-technologies/hh361616(v%3doffice.14)).  
  
 ]]></format>
    </remarks>
  </Docs>
  <Members>
    <MemberGroup MemberName=".ctor">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Erstellt eine neue Instanz der <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Klasse.</summary>
      </Docs>
    </MemberGroup>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public PromptBuilder ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.#ctor" />
      <MemberSignature Language="VB.NET" Value="Public Sub New ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; PromptBuilder();" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters />
      <Docs>
        <summary>Erstellt eine neue Instanz der <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Klasse.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Examples  
 Im folgenden Beispiel wird eine neue <xref:System.Speech.Synthesis.PromptBuilder> -Instanz erstellt und ihr eine Text Zeichenfolge hinzugefügt.  
  
```csharp  
using System.Speech.Synthesis;  
  
public void MySimpleText ()  
{  
    PromptBuilder builder = new PromptBuilder ();  
    builder.AppendText("Hello world!");  
}  
```  
  
 Das folgende Markup zeigt das Äquivalent in der Sprache Synthese Markup Language (SSML), ( `xml:lang` ist ein erforderliches Attribut des- `speak` Elements):  
  
```xml  
<speak version="1.0"  
 xmlns="http://www.w3.org/2001/10/synthesis" xml:lang="en-US">  
  Hello world!  
</speak>  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public PromptBuilder (System.Globalization.CultureInfo culture);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(class System.Globalization.CultureInfo culture) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.#ctor(System.Globalization.CultureInfo)" />
      <MemberSignature Language="VB.NET" Value="Public Sub New (culture As CultureInfo)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; PromptBuilder(System::Globalization::CultureInfo ^ culture);" />
      <MemberSignature Language="F#" Value="new System.Speech.Synthesis.PromptBuilder : System.Globalization.CultureInfo -&gt; System.Speech.Synthesis.PromptBuilder" Usage="new System.Speech.Synthesis.PromptBuilder culture" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="culture" Type="System.Globalization.CultureInfo" />
      </Parameters>
      <Docs>
        <param name="culture">Enthält Informationen über eine bestimmte Kultur, wie ihre Sprache, den Namen der Kultur, das Schreibsystem, den verwendeten Kalender und darüber, wie Datumsangaben formatiert und Zeichenfolgen sortiert werden.</param>
        <summary>Erstellt eine neue Instanz der <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Klasse und gibt eine Kultur an.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Dieser Konstruktor legt den Wert für die- <xref:System.Speech.Synthesis.PromptBuilder.Culture%2A> Eigenschaft fest. Das <xref:System.Speech.Synthesis.SpeechSynthesizer> Objekt versucht, eine installierte Stimme auszuwählen, die die durch den-Parameter angegebene Sprache `culture` zur Verarbeitung der Eingabeaufforderung unterstützt. Wenn eine Stimme mit der angegebenen Kultur gefunden wird, wird diese verwendet. Wenn eine Stimme mit der angegebenen Kultur nicht gefunden werden kann, wird die Standardsprache verwendet.  
  
 Zum ordnungsgemäßen aussprechen von Wörtern in der durch den-Parameter angegebenen Sprache `culture` muss eine Sprachsynthese-Engine (Text-zu-Sprache oder TTS) installiert sein, die die Sprache unterstützt. Eine installierte TTS-Engine wird als Stimme bezeichnet. Verwenden Sie die-Methode, um Informationen darüber zu erhalten, welche Stimmen für eine bestimmte Kultur installiert sind <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> .  
  
 Microsoft Windows und die System. Speech-API akzeptieren alle gültigen sprach Ländercodes als Werte für `culture` . Die TTS-Engines, die mit Windows 7 ausgeliefert wurden, unterstützen die folgenden sprach Ländercodes:  
  
-   en-US. Englisch (USA)  
  
-   zh-cn. Chinesisch (China)  
  
-   zh-tw. Chinesisch (Taiwan)  
  
 Sprachcodes mit zwei Buchstaben, z. b. "en", sind ebenfalls zulässig.  
  
   
  
## Examples  
 Im folgenden Beispiel wird eine <xref:System.Speech.Synthesis.PromptBuilder> -Instanz erstellt und deren angegeben <xref:System.Speech.Synthesis.PromptBuilder.Culture%2A> .  
  
```csharp  
using System.Speech.Synthesis;  
  
public void MySimpleText ()  
{  
    PromptBuilder builder = new PromptBuilder(new System.Globalization.CultureInfo("en-US"));  
    builder.AppendText("Hello world!");  
}  
```  
  
 Das folgende Markup zeigt die entsprechende SSML-Datei:  
  
```xml  
<speak version="1.0"  
 xmlns="http://www.w3.org/2001/10/synthesis" xml:lang="en-US">  
  Hello world!  
</speak>  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <MemberGroup MemberName="AppendAudio">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Fügt einem <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt eine angegebene Audiodatei an.</summary>
      </Docs>
    </MemberGroup>
    <Member MemberName="AppendAudio">
      <MemberSignature Language="C#" Value="public void AppendAudio (string path);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendAudio(string path) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendAudio(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendAudio (path As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendAudio(System::String ^ path);" />
      <MemberSignature Language="F#" Value="member this.AppendAudio : string -&gt; unit" Usage="promptBuilder.AppendAudio path" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="path" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="path">Der vollqualifizierte Pfad zu der Audiodatei.</param>
        <summary>Fügt die angegebene Audiodatei dem <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt an.</summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendAudio">
      <MemberSignature Language="C#" Value="public void AppendAudio (Uri audioFile);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendAudio(class System.Uri audioFile) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendAudio(System.Uri)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendAudio (audioFile As Uri)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendAudio(Uri ^ audioFile);" />
      <MemberSignature Language="F#" Value="member this.AppendAudio : Uri -&gt; unit" Usage="promptBuilder.AppendAudio audioFile" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="audioFile" Type="System.Uri" />
      </Parameters>
      <Docs>
        <param name="audioFile">URI für die Audiodatei.</param>
        <summary>Fügt die Audio-Datei am angegebenen URI an das <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt an.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Examples  
 Im folgenden Beispiel wird eine neue Instanz der <xref:System.Speech.Synthesis.PromptBuilder> -Klasse initialisiert und anschließend Text hinzugefügt, gefolgt von einer Audiodatei.  
  
```csharp  
using System.Speech.PromptBuilder;  
  
public void SimpleConcatenation()  
{  
    // Add a prompt fragment from a .wav file.  
    PromptBuilder builder = new PromptBuilder ();  
    builder.AppendText("How are you today?");  
    builder.AppendAudio(new Uri ("http://www.speech.microsoft.com/ding.wav"));  
}  
```  
  
 Das folgende Markup zeigt das entsprechende SSML-Markup.  
  
```xml  
<speak xmlns="http://www.w3.org/2001/10/synthesis"  
       xmlns:ms="http://www.microsoft.com/speech/synthesis" xml:lang="en">  
  
  How are you today?  
  <audio src="http://www.speech.microsoft.com/ding.wav" />  
  
</speak>  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendAudio">
      <MemberSignature Language="C#" Value="public void AppendAudio (Uri audioFile, string alternateText);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendAudio(class System.Uri audioFile, string alternateText) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendAudio(System.Uri,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendAudio (audioFile As Uri, alternateText As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendAudio(Uri ^ audioFile, System::String ^ alternateText);" />
      <MemberSignature Language="F#" Value="member this.AppendAudio : Uri * string -&gt; unit" Usage="promptBuilder.AppendAudio (audioFile, alternateText)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="audioFile" Type="System.Uri" />
        <Parameter Name="alternateText" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="audioFile">URI für die Audiodatei.</param>
        <param name="alternateText">Eine Zeichenfolge, die den alternativen Text enthält, der das Audio darstellt.</param>
        <summary>Fügt die angegebene Audiodatei und den alternativen Text an das <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt an.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Die Sprachsynthese-Engine spricht den alternativen Text, wenn die Audiodatei nicht wiedergegeben werden kann.  
  
   
  
## Examples  
 In den folgenden Beispielen wird eine Audiodatei zu einer-Instanz hinzugefügt <xref:System.Speech.Synthesis.PromptBuilder> und Text angegeben, um zu sprechen, wenn die Audiodatei nicht wiedergegeben werden kann.  
  
```csharp  
using System.Speech.PromptBuilder;  
  
public void SimpleConcatenation()  
{  
  
    // Concatenate a prompt fragment from a .wav file.  
    PromptBuilder builder = new PromptBuilder ();  
    builder.AppendAudio(new Uri ("C:\\OnHold.wav"), "Your call will be answered in the order it was received");  
}  
```  
  
 Das folgende Markup zeigt das entsprechende SSML-Markup.  
  
```xml  
<speak xmlns="http://www.w3.org/2001/10/synthesis"  
       xmlns:ms="http://www.microsoft.com/speech/synthesis" xml:lang="en">  
  
  <audio src="C:\OnHold.wav"> Your call will be answered in the order it was received. </audio>  
  
</speak>  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendBookmark">
      <MemberSignature Language="C#" Value="public void AppendBookmark (string bookmarkName);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendBookmark(string bookmarkName) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendBookmark(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendBookmark (bookmarkName As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendBookmark(System::String ^ bookmarkName);" />
      <MemberSignature Language="F#" Value="member this.AppendBookmark : string -&gt; unit" Usage="promptBuilder.AppendBookmark bookmarkName" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="bookmarkName" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="bookmarkName">Eine Zeichenfolge mit dem Namen des angefügten Lesezeichens.</param>
        <summary>Fügt ein Lesezeichen an das <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt an.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Eine Sprachsynthese-Engine generiert ein- <xref:System.Speech.Synthesis.SpeechSynthesizer.BookmarkReached> Ereignis, wenn Sie ein Lesezeichen findet, wenn eine Eingabeaufforderung mit einer der <xref:System.Speech.Synthesis.SpeechSynthesizer.Speak%2A> <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync%2A> Methoden,, oder verwendet wird <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsml%2A> <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsmlAsync%2A> .  
  
   
  
## Examples  
 Im folgenden Beispiel wird eine Eingabeaufforderung erstellt, die zwei Lesezeichen enthält und die Ausgabe für die Wiedergabe an eine WAV-Datei sendet. Der Handler für das <xref:System.Speech.Synthesis.SpeechSynthesizer.BookmarkReached> Ereignis schreibt den Namen des Lesezeichens und seine Position in den Audiostream, wenn das Ereignis auf der Konsole ausgelöst wurde.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToWaveFile(@"C:\test\weather.wav");  
  
        // Create a SoundPlayer instance to play the output audio file.  
        System.Media.SoundPlayer m_SoundPlayer =  
          new System.Media.SoundPlayer(@"C:\test\weather.wav");  
  
        // Build a prompt and append bookmarks.  
        PromptBuilder builder = new PromptBuilder(  
          new System.Globalization.CultureInfo("en-US"));  
        builder.AppendText(  
          "The weather forecast for today is partly cloudy with some sun breaks.");  
        builder.AppendBookmark("Daytime forecast");  
        builder.AppendText(  
          "Tonight's weather will be cloudy with a 30% chance of showers.");  
        builder.AppendBookmark("Nighttime forecast");  
  
        // Add a handler for the BookmarkReached event.  
        synth.BookmarkReached +=  
          new EventHandler<BookmarkReachedEventArgs>(synth_BookmarkReached);  
  
        // Speak the prompt and play back the output file.  
        synth.Speak(builder);  
        m_SoundPlayer.Play();  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Write the name and position of the bookmark to the console.  
    static void synth_BookmarkReached(object sender, BookmarkReachedEventArgs e)  
    {  
      Console.WriteLine("Bookmark ({0}) reached at: {1} ",  
        e.Bookmark, e.AudioPosition);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <MemberGroup MemberName="AppendBreak">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Fügt eine Unterbrechung (Anhalten) im Inhalt eines <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekts ein.</summary>
      </Docs>
    </MemberGroup>
    <Member MemberName="AppendBreak">
      <MemberSignature Language="C#" Value="public void AppendBreak ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendBreak() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendBreak" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendBreak ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendBreak();" />
      <MemberSignature Language="F#" Value="member this.AppendBreak : unit -&gt; unit" Usage="promptBuilder.AppendBreak " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Fügt dem <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt eine Unterbrechung an.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Diese Methode gibt keine Dauer für die Unterbrechung an. <xref:System.Speech.Synthesis.SpeechSynthesizer>Bestimmt basierend auf dem linguistischen Kontext einen Duration-Wert.  
  
   
  
## Examples  
 Im folgenden Beispiel wird eine Eingabeaufforderung mit zwei Sätzen erstellt, die durch eine Unterbrechung getrennt sind, und die Eingabeaufforderung wird auf dem Standard Audiogerät des Computers angezeigt.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Build a prompt with two sentences separated by a break.  
        PromptBuilder builder = new PromptBuilder(  
          new System.Globalization.CultureInfo("en-US"));  
        builder.AppendText(  
          "Tonight's movie showings in theater A are at 5:45, 7:15, and 8:45.");  
        builder.AppendBreak();  
        builder.AppendText(  
          "Tonight's movie showings in theater B are at 5:15, 7:30, and 9:15.");  
  
        // Speak the prompt.  
        synth.Speak(builder);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendBreak">
      <MemberSignature Language="C#" Value="public void AppendBreak (System.Speech.Synthesis.PromptBreak strength);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendBreak(valuetype System.Speech.Synthesis.PromptBreak strength) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendBreak(System.Speech.Synthesis.PromptBreak)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendBreak (strength As PromptBreak)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendBreak(System::Speech::Synthesis::PromptBreak strength);" />
      <MemberSignature Language="F#" Value="member this.AppendBreak : System.Speech.Synthesis.PromptBreak -&gt; unit" Usage="promptBuilder.AppendBreak strength" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="strength" Type="System.Speech.Synthesis.PromptBreak" />
      </Parameters>
      <Docs>
        <param name="strength">Gibt die Dauer der Unterbrechung an, mit den folgenden Erhöhungswerten:</param>
        <summary>Fügt dem <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt eine Unterbrechung an und gibt die Stärke (Dauer) an.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Die Werte in der- <xref:System.Speech.Synthesis.PromptBreak> Enumeration stellen einen Bereich von Trennungs Intervallen (Pausen) zwischen Wortgrenzen dar. Die Sprachsynthese-Engine bestimmt die genaue Dauer des Intervalls. Wenn eine Unterbrechung angefordert wird, wird einer dieser Werte an das TTS-Modul (Text-to-Speech), das eine Zuordnung zwischen diesen Werten und den entsprechenden Millisekunden-Break-Werten enthält, übermittelt.  
  
   
  
## Examples  
 Im folgenden Beispiel wird eine Eingabeaufforderung mit zwei durch eine Unterbrechung getrennten Sätzen erstellt, und die Ausgabe wird zur Wiedergabe an eine WAV-Datei gesendet.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToWaveFile(@"C:\test\weather.wav");  
  
        // Create a SoundPlayer instance to play the output audio file.  
        System.Media.SoundPlayer m_SoundPlayer =  
          new System.Media.SoundPlayer(@"C:\test\weather.wav");  
  
        // Build a prompt with two sentences separated by a break.  
        PromptBuilder builder = new PromptBuilder(  
          new System.Globalization.CultureInfo("en-US"));  
        builder.AppendText(  
          "Tonight's movie showings in theater A are at 5:45, 7:15, and 8:45");  
        builder.AppendBreak(PromptBreak.Medium);  
        builder.AppendText(  
          "Tonight's movie showings in theater B are at 5:15, 7:15, and 9:15");  
  
        // Speak the prompt and play back the output file.  
        synth.Speak(builder);  
        m_SoundPlayer.Play();  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendBreak">
      <MemberSignature Language="C#" Value="public void AppendBreak (TimeSpan duration);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendBreak(valuetype System.TimeSpan duration) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendBreak(System.TimeSpan)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendBreak (duration As TimeSpan)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendBreak(TimeSpan duration);" />
      <MemberSignature Language="F#" Value="member this.AppendBreak : TimeSpan -&gt; unit" Usage="promptBuilder.AppendBreak duration" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="duration" Type="System.TimeSpan" />
      </Parameters>
      <Docs>
        <param name="duration">Die Zeit in Ticks, wobei ein Tick 100 Nanosekunden entspricht.</param>
        <summary>Fügt an das <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt eine Unterbrechung der angegebenen Dauer an.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Eine Unterbrechung kann verwendet werden, um Pausen oder andere prosodischen-Begrenzungen zwischen Wörtern zu steuern. Eine Unterbrechung ist optional. Wenn keine Unterbrechung vorhanden ist, bestimmt der Synthesizer die Unterbrechung zwischen Wörtern abhängig vom linguistischen Kontext.  
  
   
  
## Examples  
 Im folgenden Beispiel wird eine Eingabeaufforderung mit zwei Sätzen erstellt, die durch eine Unterbrechung von 15 Millionen Ticks (1,5 Sekunden) getrennt sind, und die Aufforderung wird an das Standardaudiogerät auf dem Computer ausgegeben.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Build a prompt with two sentences separated by a break.  
        PromptBuilder builder = new PromptBuilder(  
          new System.Globalization.CultureInfo("en-US"));  
        builder.AppendText(  
          "Tonight's movie showings in theater A are at 5:45, 7:15, and 8:45");  
        builder.AppendBreak(new TimeSpan(15000000));  
        builder.AppendText(  
          "Tonight's movie showings in theater B are at 5:15, 7:15, and 9:15");  
  
        // Speak the prompt.  
        synth.Speak(builder);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendPromptBuilder">
      <MemberSignature Language="C#" Value="public void AppendPromptBuilder (System.Speech.Synthesis.PromptBuilder promptBuilder);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendPromptBuilder(class System.Speech.Synthesis.PromptBuilder promptBuilder) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendPromptBuilder(System.Speech.Synthesis.PromptBuilder)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendPromptBuilder (promptBuilder As PromptBuilder)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendPromptBuilder(System::Speech::Synthesis::PromptBuilder ^ promptBuilder);" />
      <MemberSignature Language="F#" Value="member this.AppendPromptBuilder : System.Speech.Synthesis.PromptBuilder -&gt; unit" Usage="promptBuilder.AppendPromptBuilder promptBuilder" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="promptBuilder" Type="System.Speech.Synthesis.PromptBuilder" />
      </Parameters>
      <Docs>
        <param name="promptBuilder">Der Inhalt, der angefügt werden soll.</param>
        <summary>Fügt ein <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt an ein anderes <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt an.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Examples  
 Im folgenden Beispiel werden zwei <xref:System.Speech.Synthesis.PromptBuilder> -Instanzen erstellt und dann an ein drittes angefügt <xref:System.Speech.Synthesis.PromptBuilder> .  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToWaveFile(@"C:\test\showtimes.wav");  
  
        // Create a SoundPlayer instance to play the output audio file.  
        System.Media.SoundPlayer m_SoundPlayer =  
          new System.Media.SoundPlayer(@"C:\test\showtimes.wav");  
  
        // Build child prompts.  
        PromptBuilder theatreA = new PromptBuilder();  
        theatreA.AppendText(  
          "Tonight's movie showings in theater A are at 5:45, 7:15, and 9:30");  
        theatreA.AppendBreak(PromptBreak.Large);  
        PromptBuilder theatreB = new PromptBuilder();  
        theatreB.AppendText(  
          "Tonight's movie showings in theater B are at 5:15, 7:15, and 9:15");  
  
        // Build the parent prompt and append the two child prompts.  
        PromptBuilder showTimes = new PromptBuilder(  
          new System.Globalization.CultureInfo("en-US"));  
        showTimes.AppendText(  
          "The following are the show times for tonight's movies:");  
        showTimes.AppendPromptBuilder(theatreA);  
        showTimes.AppendPromptBuilder(theatreB);  
  
        // Speak the prompt and play back the output file.  
        synth.Speak(showTimes);  
        m_SoundPlayer.Play();  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <MemberGroup MemberName="AppendSsml">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Fügt eine SSML-Datei an ein <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt an.</summary>
      </Docs>
    </MemberGroup>
    <Member MemberName="AppendSsml">
      <MemberSignature Language="C#" Value="public void AppendSsml (string path);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendSsml(string path) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendSsml(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendSsml (path As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendSsml(System::String ^ path);" />
      <MemberSignature Language="F#" Value="member this.AppendSsml : string -&gt; unit" Usage="promptBuilder.AppendSsml path" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="path" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="path">Ein vollqualifizierter Pfad zu der SSML-Datei, die angefügt werden soll.</param>
        <summary>Fügt die SSML-Datei am angegebenen Pfad an das <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt an.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Bei der SSML-Datei muss es sich um eine XML-Format Datei handeln, die der Spezifikation der [Sprache Synthese Markup Language (SSML) Version 1,0](https://go.microsoft.com/fwlink/?LinkId=201763) entspricht.  
  
 Sie können auch SSML-Markup mithilfe von als Zeichenfolge anfügen <xref:System.Speech.Synthesis.PromptBuilder.AppendSsmlMarkup%2A> .  
  
   
  
## Examples  
 Im folgenden Beispiel wird ein <xref:System.Speech.Synthesis.PromptBuilder> -Objekt erstellt, und der Inhalt einer SSML-Datei wird mithilfe der-Methode angefügt <xref:System.Speech.Synthesis.PromptBuilder.AppendSsml%2A> .  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Create a PromptBuilder object and append a file that defines an SSML prompt.  
        PromptBuilder ssmlFile = new PromptBuilder();  
        ssmlFile.AppendSsml("c:\\test\\Weather.ssml");  
  
        // Speak the contents of the SSML prompt.  
        synth.Speak(ssmlFile);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 Im folgenden finden Sie die SSML-Datei, auf die im vorherigen Beispiel verwiesen wird.  
  
```xml  
<?xml version="1.0" encoding="ISO-8859-1"?>  
<speak version="1.0"  
 xmlns="http://www.w3.org/2001/10/synthesis"  
 xml:lang="en-US">  
  
  <s> The weather forecast for today is partly cloudy with some sun breaks. </s>  
  
</speak>  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendSsml">
      <MemberSignature Language="C#" Value="public void AppendSsml (Uri ssmlFile);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendSsml(class System.Uri ssmlFile) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendSsml(System.Uri)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendSsml (ssmlFile As Uri)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendSsml(Uri ^ ssmlFile);" />
      <MemberSignature Language="F#" Value="member this.AppendSsml : Uri -&gt; unit" Usage="promptBuilder.AppendSsml ssmlFile" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="ssmlFile" Type="System.Uri" />
      </Parameters>
      <Docs>
        <param name="ssmlFile">Ein vollqualifizierter URI zu der SSML-Datei, die angefügt werden soll.</param>
        <summary>Fügt die SSML-Datei am angegebenen URI an das <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt an.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Bei der SSML-Datei muss es sich um eine XML-Format Datei handeln, die der Spezifikation der [Sprache Synthese Markup Language (SSML) Version 1,0](https://www.w3.org/TR/speech-synthesis/) entspricht.  
  
 Sie können auch SSML-Markup mithilfe von als Zeichenfolge anfügen <xref:System.Speech.Synthesis.PromptBuilder.AppendSsmlMarkup%2A> .  
  
   
  
## Examples  
 Im folgenden Beispiel wird ein <xref:System.Speech.Synthesis.PromptBuilder> -Objekt erstellt, und der Inhalt einer SSML-Datei wird mithilfe der-Methode angefügt <xref:System.Speech.Synthesis.PromptBuilder.AppendSsml%2A> .  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Create a PromptBuilder object and append a file that defines an SSML prompt.  
        PromptBuilder ssmlFile = new PromptBuilder();  
        ssmlFile.AppendSsml(new Uri("c:\\test\\Weather.ssml"));  
  
        // Speak the contents of the SSML prompt.  
        synth.Speak(ssmlFile);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
```  
  
 Im folgenden finden Sie die SSML-Datei, auf die im vorherigen Beispiel verwiesen wird.  
  
```xml  
<?xml version="1.0" encoding="ISO-8859-1"?>  
<speak version="1.0"  
 xmlns="http://www.w3.org/2001/10/synthesis"  
 xml:lang="en-US">  
  
  <s> The weather forecast for today is partly cloudy with some sun breaks. </s>  
  
</speak>  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendSsml">
      <MemberSignature Language="C#" Value="public void AppendSsml (System.Xml.XmlReader ssmlFile);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendSsml(class System.Xml.XmlReader ssmlFile) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendSsml(System.Xml.XmlReader)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendSsml (ssmlFile As XmlReader)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendSsml(System::Xml::XmlReader ^ ssmlFile);" />
      <MemberSignature Language="F#" Value="member this.AppendSsml : System.Xml.XmlReader -&gt; unit" Usage="promptBuilder.AppendSsml ssmlFile" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="ssmlFile" Type="System.Xml.XmlReader" />
      </Parameters>
      <Docs>
        <param name="ssmlFile">Der vollqualifizierte Name der XML-Datei, die angefügt werden soll.</param>
        <summary>Fügt ein <c>XMLReader</c>-Objekt an, das auf eine SSML-Eingabeaufforderung auf das <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt verweist.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Bei der SSML-Datei muss es sich um eine XML-Format Datei handeln, die der Spezifikation der [Sprache Synthese Markup Language (SSML) Version 1,0](https://www.w3.org/TR/speech-synthesis/) entspricht.  
  
 Sie können auch SSML-Markup mithilfe von als Zeichenfolge anfügen <xref:System.Speech.Synthesis.PromptBuilder.AppendSsmlMarkup%2A> .  
  
   
  
## Examples  
 Im folgenden Beispiel wird ein- <xref:System.Speech.Synthesis.PromptBuilder> Objekt aus einem- <xref:System.Xml.XmlReader> Objekt erstellt, das auf eine Datei verweist, die Sprachsynthese Markup Language (SSML)-Markup enthält.  
  
```csharp  
using System;  
using System.Xml;  
using System.IO;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToWaveFile(@"C:\test\weather.wav");  
  
        // Create a SoundPlayer instance to play the output audio file.  
        System.Media.SoundPlayer m_SoundPlayer =  
          new System.Media.SoundPlayer(@"C:\test\weather.wav");  
  
        // Create the path to the SSML file.  
        string weatherFile = Path.GetFullPath("c:\\test\\Weather.xml");  
        PromptBuilder builder = null;  
  
        // Create an XML Reader from the file, create a PromptBuilder and   
        // append the XmlReader.  
        if (File.Exists(weatherFile))  
        {  
          XmlReader reader = XmlReader.Create(weatherFile);  
          builder = new PromptBuilder();  
          builder.AppendSsml(reader);  
          reader.Close();  
        }  
  
        // Speak the prompt and play back the output file.  
        synth.Speak(builder);  
        m_SoundPlayer.Play();  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendSsmlMarkup">
      <MemberSignature Language="C#" Value="public void AppendSsmlMarkup (string ssmlMarkup);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendSsmlMarkup(string ssmlMarkup) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendSsmlMarkup(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendSsmlMarkup (ssmlMarkup As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendSsmlMarkup(System::String ^ ssmlMarkup);" />
      <MemberSignature Language="F#" Value="member this.AppendSsmlMarkup : string -&gt; unit" Usage="promptBuilder.AppendSsmlMarkup ssmlMarkup" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute>
          <AttributeName Language="C#">[System.ComponentModel.EditorBrowsable(System.ComponentModel.EditorBrowsableState.Advanced)]</AttributeName>
          <AttributeName Language="F#">[&lt;System.ComponentModel.EditorBrowsable(System.ComponentModel.EditorBrowsableState.Advanced)&gt;]</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="ssmlMarkup" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="ssmlMarkup">Eine Zeichenfolge, die SSML-Code enthält.</param>
        <summary>Fügt die angegebene Zeichenfolge, die SSML-Code enthält, an das <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt an.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Beim Anhängen von SSML-Markup müssen die entsprechenden Escapezeichen verwendet werden. Beachten Sie die rückwärts Schrägstriche vor den Anführungszeichen, die den Wert des `interpret-as` Attributs im folgenden Beispiel einschließen:  
  
```csharp  
builder.AppendSsmlMarkup("<say-as interpret-as = \"characters\"> chair </say-as>");  
```  
  
> [!NOTE]
>  Die Zeichenfolge, die als Argument für verwendet wird, <xref:System.Speech.Synthesis.PromptBuilder.AppendSsmlMarkup%2A> darf kein- `speak` Element enthalten.  
  
 Wenn Sie verwenden, <xref:System.Speech.Synthesis.PromptBuilder.AppendSsmlMarkup%2A> um Inline Ausdrücke in einem- `phoneme` Element anzugeben, können Sie Smartphones aus jedem der folgenden Phonetischen Alphabets verwenden, vorausgesetzt, dass die aktuelle Sprach-Engine dies unterstützt:  
  
-   Internationales Phonetisches Alphabet (IPA)  
  
-   Universelles Telefon Satz (UPS)  
  
-   SAPI-Telefon Satz  
  
 Jede SSML-kompatible Sprach-Engine spricht Smartphones aus der IPA-Datei.  
  
 Sie können auch eine Datei, die SSML-Markup enthält, mit einer der-Methoden anfügen <xref:System.Speech.Synthesis.PromptBuilder.AppendSsml%2A> . Um zu sprechenden Text anzufügen, der nicht mit Markup Sprache formatiert ist, verwenden Sie eine der <xref:System.Speech.Synthesis.PromptBuilder.AppendText%2A> <xref:System.Speech.Synthesis.PromptBuilder.AppendTextWithAlias%2A> Methoden,, <xref:System.Speech.Synthesis.PromptBuilder.AppendTextWithHint%2A> oder <xref:System.Speech.Synthesis.PromptBuilder.AppendTextWithPronunciation%2A> .  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <MemberGroup MemberName="AppendText">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Fügt Text an das <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt an.</summary>
      </Docs>
    </MemberGroup>
    <Member MemberName="AppendText">
      <MemberSignature Language="C#" Value="public void AppendText (string textToSpeak);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendText(string textToSpeak) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendText(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendText (textToSpeak As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendText(System::String ^ textToSpeak);" />
      <MemberSignature Language="F#" Value="member this.AppendText : string -&gt; unit" Usage="promptBuilder.AppendText textToSpeak" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="textToSpeak" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="textToSpeak">Eine Zeichenfolge, die den zu sprechenden Text enthält.</param>
        <summary>Bezeichnet Text, der an das Objekt <see cref="T:System.Speech.Synthesis.PromptBuilder" /> anzufügen ist.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Um Text anzufügen, der als SSML-Markup Sprache formatiert ist, verwenden Sie <xref:System.Speech.Synthesis.PromptBuilder.AppendSsmlMarkup%2A> .  
  
   
  
## Examples  
 Im folgenden Beispiel wird ein <xref:System.Speech.Synthesis.PromptBuilder> -Objekt erstellt und mithilfe der-Methode eine Text Zeichenfolge angefügt <xref:System.Speech.Synthesis.PromptBuilder.AppendText%2A> .  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Create a PromptBuilder object and append a text string.  
        PromptBuilder speakText = new PromptBuilder();  
        speakText.AppendText("Say the name of the song you want to hear");  
  
        // Speak the contents of the prompt.  
        synth.Speak(speakText);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendText">
      <MemberSignature Language="C#" Value="public void AppendText (string textToSpeak, System.Speech.Synthesis.PromptEmphasis emphasis);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendText(string textToSpeak, valuetype System.Speech.Synthesis.PromptEmphasis emphasis) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendText(System.String,System.Speech.Synthesis.PromptEmphasis)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendText (textToSpeak As String, emphasis As PromptEmphasis)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendText(System::String ^ textToSpeak, System::Speech::Synthesis::PromptEmphasis emphasis);" />
      <MemberSignature Language="F#" Value="member this.AppendText : string * System.Speech.Synthesis.PromptEmphasis -&gt; unit" Usage="promptBuilder.AppendText (textToSpeak, emphasis)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="textToSpeak" Type="System.String" />
        <Parameter Name="emphasis" Type="System.Speech.Synthesis.PromptEmphasis" />
      </Parameters>
      <Docs>
        <param name="textToSpeak">Eine Zeichenfolge, die den zu sprechenden Text enthält.</param>
        <param name="emphasis">Der auf den Text anzuwendende Wert für Nachdruck oder Betonung.</param>
        <summary>Fügt Text an das <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt an und gibt den Grad der Betonung für den Text an.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Die Sprachsynthese-Engines in Windows unterstützen zu diesem Zeitpunkt nicht den Schwerpunkt Parameter. Durch Festlegen von Werten für den Schwerpunkt Parameter wird keine akustische Änderung in der Ausgabe der synthetisierten Sprache erzeugt.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendText">
      <MemberSignature Language="C#" Value="public void AppendText (string textToSpeak, System.Speech.Synthesis.PromptRate rate);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendText(string textToSpeak, valuetype System.Speech.Synthesis.PromptRate rate) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendText(System.String,System.Speech.Synthesis.PromptRate)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendText (textToSpeak As String, rate As PromptRate)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendText(System::String ^ textToSpeak, System::Speech::Synthesis::PromptRate rate);" />
      <MemberSignature Language="F#" Value="member this.AppendText : string * System.Speech.Synthesis.PromptRate -&gt; unit" Usage="promptBuilder.AppendText (textToSpeak, rate)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="textToSpeak" Type="System.String" />
        <Parameter Name="rate" Type="System.Speech.Synthesis.PromptRate" />
      </Parameters>
      <Docs>
        <param name="textToSpeak">Eine Zeichenfolge, die den zu sprechenden Text enthält.</param>
        <param name="rate">Der auf den Text anzuwendende Wert für die Sprechgeschwindigkeit.</param>
        <summary>Fügt Text an das <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt an und gibt die Sprechgeschwindigkeit für den Text an.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Examples  
 Im folgenden Beispiel wird ein <xref:System.Speech.Synthesis.PromptBuilder> -Objekt erstellt und Text Zeichenfolgen angehängt. Im Beispiel wird die-Methode verwendet, <xref:System.Speech.Synthesis.PromptBuilder.AppendText%2A> um eine langsame Sprechgeschwindigkeit für die hinzugefügte Zeichenfolge anzugeben, die den Inhalt einer Bestellung auflistet.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Create a PromptBuilder object and add content.  
        PromptBuilder speakRate = new PromptBuilder();  
        speakRate.AppendText("Your order for");  
        speakRate.AppendText("one kitchen sink and one faucet", PromptRate.Slow);  
        speakRate.AppendText("has been confirmed.");  
  
        // Speak the contents of the SSML prompt.  
        synth.Speak(speakRate);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendText">
      <MemberSignature Language="C#" Value="public void AppendText (string textToSpeak, System.Speech.Synthesis.PromptVolume volume);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendText(string textToSpeak, valuetype System.Speech.Synthesis.PromptVolume volume) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendText(System.String,System.Speech.Synthesis.PromptVolume)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendText (textToSpeak As String, volume As PromptVolume)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendText(System::String ^ textToSpeak, System::Speech::Synthesis::PromptVolume volume);" />
      <MemberSignature Language="F#" Value="member this.AppendText : string * System.Speech.Synthesis.PromptVolume -&gt; unit" Usage="promptBuilder.AppendText (textToSpeak, volume)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="textToSpeak" Type="System.String" />
        <Parameter Name="volume" Type="System.Speech.Synthesis.PromptVolume" />
      </Parameters>
      <Docs>
        <param name="textToSpeak">Eine Zeichenfolge, die den zu sprechenden Text enthält.</param>
        <param name="volume">Der auf den Text anzuwendende Wert für die Sprecherlautstärke.</param>
        <summary>Fügt Text an das <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt an und gibt die Lautstärke an, mit der der Text gesprochen werden soll.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Die <xref:System.Speech.Synthesis.PromptVolume.Default> Einstellung für <xref:System.Speech.Synthesis.PromptVolume> ist vollständiges Volume, das entspricht <xref:System.Speech.Synthesis.PromptVolume.ExtraLoud> . Die anderen Einstellungen verringern den Umfang der Sprachausgabe in Relation zum vollständigen Volume.  
  
   
  
## Examples  
 Im folgenden Beispiel wird die- <xref:System.Speech.Synthesis.PromptBuilder.AppendText%2A> Methode verwendet, um Volumeeinstellungen anzugeben, die <xref:System.Speech.Synthesis.SpeechSynthesizer> auf die Sprachausgabe angewendet werden sollen.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Build a prompt that applies different volume settings.  
        PromptBuilder builder = new PromptBuilder();  
        builder.AppendText("This is the default speaking volume.", PromptVolume.Default);  
        builder.AppendBreak();  
        builder.AppendText("This is the extra loud speaking volume.", PromptVolume.ExtraLoud);  
        builder.AppendBreak();  
        builder.AppendText("This is the medium speaking volume.", PromptVolume.Medium);  
  
        // Speak the prompt.  
        synth.Speak(builder);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendTextWithAlias">
      <MemberSignature Language="C#" Value="public void AppendTextWithAlias (string textToSpeak, string substitute);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendTextWithAlias(string textToSpeak, string substitute) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendTextWithAlias(System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendTextWithAlias (textToSpeak As String, substitute As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendTextWithAlias(System::String ^ textToSpeak, System::String ^ substitute);" />
      <MemberSignature Language="F#" Value="member this.AppendTextWithAlias : string * string -&gt; unit" Usage="promptBuilder.AppendTextWithAlias (textToSpeak, substitute)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="textToSpeak" Type="System.String" />
        <Parameter Name="substitute" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="textToSpeak">Eine Zeichenfolge, die die Textdarstellung enthält.</param>
        <param name="substitute">Eine Zeichenfolge, die den zu sprechenden Text enthält.</param>
        <summary>Fügt Text an das <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt an und gibt den Aliastext an, der anstelle des angefügten Texts gesprochen werden soll.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Dadurch kann ein Dokument sowohl eine gesprochene als auch ein geschriebenes Formular für eine Eingabeaufforderung enthalten. Beispielsweise könnte das geschriebene Formular ein Akronym sein, z. b. SAPI, und das gesprochene Formular könnte der erweiterte Text für das Akronym sein, in diesem Fall sprach Programmierungs Schnittstelle.  
  
   
  
## Examples  
 Im folgenden Beispiel wird eine Text Zeichenfolge ("Speech Synthese Markup Language") und Ihr Alias ("SSML") an ein- <xref:System.Speech.Synthesis.PromptBuilder> Objekt angehängt. Der Synthesizer gibt "s s M L" aus.  
  
```  
PromptBuilder alias = new PromptBuilder();  
alias.AppendTextWithAlias("Speech Synthesis Markup Language","SSML");   
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <MemberGroup MemberName="AppendTextWithHint">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Fügt Text an das <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt an und gibt den Inhaltstyp des Texts an.</summary>
      </Docs>
    </MemberGroup>
    <Member MemberName="AppendTextWithHint">
      <MemberSignature Language="C#" Value="public void AppendTextWithHint (string textToSpeak, System.Speech.Synthesis.SayAs sayAs);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendTextWithHint(string textToSpeak, valuetype System.Speech.Synthesis.SayAs sayAs) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendTextWithHint(System.String,System.Speech.Synthesis.SayAs)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendTextWithHint (textToSpeak As String, sayAs As SayAs)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendTextWithHint(System::String ^ textToSpeak, System::Speech::Synthesis::SayAs sayAs);" />
      <MemberSignature Language="F#" Value="member this.AppendTextWithHint : string * System.Speech.Synthesis.SayAs -&gt; unit" Usage="promptBuilder.AppendTextWithHint (textToSpeak, sayAs)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="textToSpeak" Type="System.String" />
        <Parameter Name="sayAs" Type="System.Speech.Synthesis.SayAs" />
      </Parameters>
      <Docs>
        <param name="textToSpeak">Eine Zeichenfolge, die den zu sprechenden Text enthält.</param>
        <param name="sayAs">Der Inhaltstyps des Texts.</param>
        <summary>Fügt Text an das <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt an und gibt den Inhaltstyp mithilfe eines Members der <see cref="T:System.Speech.Synthesis.SayAs" />-Enumeration an.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Der durch angegebene Inhaltstyp `sayAs` kann die Sprachsynthese-Engine zum Angeben des Inhalts von bereitstellen `textToSpeak` .  
  
   
  
## Examples  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Create a PromptBuilder object and define the data types for some of the added strings.  
        PromptBuilder sayAs = new PromptBuilder();  
        sayAs.AppendText("Your");  
        sayAs.AppendTextWithHint("1st", SayAs.NumberOrdinal);  
        sayAs.AppendText("request was for");  
        sayAs.AppendTextWithHint("1", SayAs.NumberCardinal);  
        sayAs.AppendText("room, on");  
        sayAs.AppendTextWithHint("10/19/2012,", SayAs.MonthDayYear);  
        sayAs.AppendText("with early arrival at");  
        sayAs.AppendTextWithHint("12:35pm", SayAs.Time12);  
  
        // Speak the contents of the SSML prompt.  
        synth.Speak(sayAs);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendTextWithHint">
      <MemberSignature Language="C#" Value="public void AppendTextWithHint (string textToSpeak, string sayAs);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendTextWithHint(string textToSpeak, string sayAs) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendTextWithHint(System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendTextWithHint (textToSpeak As String, sayAs As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendTextWithHint(System::String ^ textToSpeak, System::String ^ sayAs);" />
      <MemberSignature Language="F#" Value="member this.AppendTextWithHint : string * string -&gt; unit" Usage="promptBuilder.AppendTextWithHint (textToSpeak, sayAs)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="textToSpeak" Type="System.String" />
        <Parameter Name="sayAs" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="textToSpeak">Eine Zeichenfolge, die den zu sprechenden Text enthält.</param>
        <param name="sayAs">Der Inhaltstyps des Texts.</param>
        <summary>Fügt Text an das <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt an und eine <see cref="T:System.String" />, die den Inhaltstyp des Texts angibt.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Mit dieser Methode können Sie einen Inhaltstyp angeben, der nicht in der- <xref:System.Speech.Synthesis.SayAs> Enumeration enthalten ist. Allerdings muss die TTS-Engine den von Ihnen angegebenen Parameter unterstützen.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendTextWithPronunciation">
      <MemberSignature Language="C#" Value="public void AppendTextWithPronunciation (string textToSpeak, string pronunciation);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendTextWithPronunciation(string textToSpeak, string pronunciation) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendTextWithPronunciation(System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendTextWithPronunciation (textToSpeak As String, pronunciation As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendTextWithPronunciation(System::String ^ textToSpeak, System::String ^ pronunciation);" />
      <MemberSignature Language="F#" Value="member this.AppendTextWithPronunciation : string * string -&gt; unit" Usage="promptBuilder.AppendTextWithPronunciation (textToSpeak, pronunciation)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="textToSpeak" Type="System.String" />
        <Parameter Name="pronunciation" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="textToSpeak">Eine Zeichenfolge, die die im konventionellen Alphabet einer Sprache geschriebene Form des Worts enthält.</param>
        <param name="pronunciation">Eine Zeichenfolge, die die zu sprechenden Sprachlaute aus dem internationalen Lautalphabet (IPA) enthält.</param>
        <summary>Fügt Text an das <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt an und gibt die Aussprache für den Text an.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Der Synthesizer spricht den Inhalt des- `pronunciation` Parameters, nicht den Inhalt des- `textToSpeak` Parameters.  
  
 In Eingabe Aufforderungen angegebene pronationen gelten nur für das einzelne Vorkommen eines Worts und überschreiben die Ausdrücke der Sprach-Engine oder eines der derzeit aktiven Lexicons. In der Regel verwenden Sie Inline Ausdrücke für benutzerdefinierte Ausdrücke vorhandener Wörter oder für die Aussprache von ungewöhnlichen Wörtern, wie z. b. ordnungsgemäßen Namen, die von der Sprachsynthese-Engine möglicherweise nicht und erwartet werden.  
  
 Inline-pronationen müssen mithilfe von Telefonen aus dem internationalen phonetischen Alphabet (IPA) angegeben werden. Ein Telefon ist ein Buchstabe oder ein Zeichen, das einen diskreten Ton der Sprache darstellt. Sprachmodule, die die Spezifikation der [Sprache Synthese Markup Language (SSML) Version 1,0](https://go.microsoft.com/fwlink/?LinkId=201763) erfüllen, werden Telefone aus der IPA-Datei angeben. Informationen zum Angeben von Inline-pronationen mit anderen phonetischen Alphabets finden Sie unter <xref:System.Speech.Synthesis.PromptBuilder.AppendSsmlMarkup%2A> .  
  
 Die IPA-Dateien veröffentlichen ein [Diagramm](https://go.microsoft.com/fwlink/?LinkId=58362) , das Ihre Telefone auflistet und Sie Unicode-Zahlen zuordnet.  
  
 Einige Telefone im IPA-Alphabet haben dieselben Darstellungen wie Buchstaben im lateinischen Alphabet. In diesen Fällen ist es möglich, das lateinische Zeichen einzugeben und die richtige Darstellung für ein Telefon zu haben. Da die lateinischen Zeichen, die im Text häufig verwendet werden, mehrere Telefone des IPA-Telefons darstellen können, führt die einfache Eingabe des lateinischen Zeichens möglicherweise nicht zum exakten IPA-Telefon. Andere Telefone des IPA-Alphabets müssen im Code als Zeichen Verweise dargestellt werden, die aus einem kaufmännischen und-Zeichen (&), dem Nummern Zeichen (#) und einer Unicode-Nummer für das gewünschte Telefon im Hexadezimal-oder Dezimal Format bestehen, gefolgt von einem Semikolon (;). Beispielsweise eine Schwa (&\# x0259;) wird durch dargestellt `&#x0259;` .  
  
 Zum Hinzufügen neuer oder benutzerdefinierter Ausdrücke für mehrere Wörter, z. b. zum Ausdrücken regionaler Dialekte oder zum Hinzufügen von richtigen Namen oder vokabularzeichen, die für eine Ausbildung oder medizinische Disziplin spezifisch sind, erstellen Sie ein Lexikon, und fügen Sie es der mithilfe von hinzu <xref:System.Speech.Synthesis.SpeechSynthesizer> <xref:System.Speech.Synthesis.SpeechSynthesizer.AddLexicon%2A> .  
  
   
  
## Examples  
 Im folgenden Beispiel wird eine neue Instanz der-Klasse initialisiert <xref:System.Speech.Synthesis.PromptBuilder> . Anschließend wird die Text Zeichenfolge "My Name is" an die Instanz angefügt. Schließlich fügt Sie eine Zeichenfolge mit dem richtigen Namen "Dubois" an und gibt die Aussprache des Namens an.  
  
```csharp  
public void ProperName()  
{  
    PromptBuilder builder = new PromptBuilder();  
    builder.AppendText("My name is");  
  
    // Add a proper name and its pronunciation.  
    builder.AppendTextWithPronunciation("DuBois", "duˈbwɑ");     
}  
```  
  
 Das folgende Markup zeigt die SSML-Datei, die von diesem <xref:System.Speech.Synthesis.PromptBuilder> Objekt generiert wird.  
  
```xml  
<speak xmlns="http://www.w3.org/2001/10/synthesis" xml:lang="en-us">  
  My name is <phoneme ph="duˈbwɑ"> DuBois </phoneme>  
</speak>  
```  
  
 ]]></format>
        </remarks>
        <related type="ExternalDocumentation" href="https://www.internationalphoneticassociation.org/content/ipa-chart">Internationale Phonetische Zuordnung</related>
      </Docs>
    </Member>
    <Member MemberName="ClearContent">
      <MemberSignature Language="C#" Value="public void ClearContent ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void ClearContent() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.ClearContent" />
      <MemberSignature Language="VB.NET" Value="Public Sub ClearContent ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void ClearContent();" />
      <MemberSignature Language="F#" Value="member this.ClearContent : unit -&gt; unit" Usage="promptBuilder.ClearContent " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Löscht den Inhalt des <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekts.</summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="Culture">
      <MemberSignature Language="C#" Value="public System.Globalization.CultureInfo Culture { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Globalization.CultureInfo Culture" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Synthesis.PromptBuilder.Culture" />
      <MemberSignature Language="VB.NET" Value="Public Property Culture As CultureInfo" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Globalization::CultureInfo ^ Culture { System::Globalization::CultureInfo ^ get(); void set(System::Globalization::CultureInfo ^ value); };" />
      <MemberSignature Language="F#" Value="member this.Culture : System.Globalization.CultureInfo with get, set" Usage="System.Speech.Synthesis.PromptBuilder.Culture" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName Language="C#">[get: System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")]</AttributeName>
          <AttributeName Language="F#">[&lt;get: System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")&gt;]</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Globalization.CultureInfo</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Ruft die Kulturinformationen für das <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt ab oder legt diese fest.</summary>
        <value>To be added.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Das <xref:System.Speech.Synthesis.SpeechSynthesizer> Objekt versucht, eine installierte Stimme auszuwählen, die die von der-Eigenschaft angegebene Sprache <xref:System.Speech.Synthesis.PromptBuilder.Culture%2A> zur Verarbeitung der Eingabeaufforderung unterstützt. Wenn eine Stimme mit der angegebenen Kultur gefunden wird, wird diese verwendet. Wenn eine Stimme mit der angegebenen Kultur nicht gefunden werden kann, wird die Standardsprache verwendet.  
  
 Eine Kultur kann auch in der Eingabeaufforderung für diskrete Inhalts Abschnitte mithilfe der <xref:System.Speech.Synthesis.PromptBuilder.StartVoice%2A> <xref:System.Speech.Synthesis.PromptBuilder.StartParagraph%2A> Methoden, und angegeben werden <xref:System.Speech.Synthesis.PromptBuilder.StartSentence%2A> . Eine Kultur, die für einen Teil des Inhalts mit einer der oben genannten Methoden angegeben wird, überschreibt die <xref:System.Speech.Synthesis.PromptBuilder.Culture%2A> -Eigenschaft, und versucht dann, <xref:System.Speech.Synthesis.SpeechSynthesizer> eine installierte Stimme auszuwählen, die die durch den-Parameter der-Methode angegebene Sprache unterstützt `culture` .  
  
 Zum ordnungsgemäßen aussprechen von Wörtern in der durch die-Eigenschaft angegebenen Sprache <xref:System.Speech.Synthesis.PromptBuilder.Culture%2A> muss eine Sprachsynthese-Engine (Text-zu-Sprache oder TTS) installiert sein, die die Sprache unterstützt. Eine installierte TTS-Engine wird als Stimme bezeichnet. Verwenden Sie die-Methode, um Informationen darüber zu erhalten, welche Stimmen für eine bestimmte Kultur installiert sind <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> .  
  
 Microsoft Windows und die System. Speech-API akzeptieren alle gültigen sprach Ländercodes als Werte für `culture` . Die TTS-Engines, die mit Windows 7 ausgeliefert wurden, unterstützen die folgenden sprach Ländercodes:  
  
-   en-US. Englisch (USA)  
  
-   zh-cn. Chinesisch (China)  
  
-   zh-tw. Chinesisch (Taiwan)  
  
 Sprachcodes mit zwei Buchstaben, z. b. "en", sind ebenfalls zulässig.  Eine umfassende Liste der Sprachcodes finden Sie unter [sprach Bezeichner-Konstanten und-](https://msdn.microsoft.com/library/dd318693\(VS.85\).aspx) Zeichen folgen.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="EndParagraph">
      <MemberSignature Language="C#" Value="public void EndParagraph ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void EndParagraph() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.EndParagraph" />
      <MemberSignature Language="VB.NET" Value="Public Sub EndParagraph ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void EndParagraph();" />
      <MemberSignature Language="F#" Value="member this.EndParagraph : unit -&gt; unit" Usage="promptBuilder.EndParagraph " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Bezeichnet das Ende eines Absatzes im <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Lange Eingabe Aufforderungen können mehr als Menschen Sprache gerendert werden, wenn Sie in Sätze und Absätze aufgeteilt werden. Ein Beispiel finden Sie unter <xref:System.Speech.Synthesis.PromptBuilder.StartParagraph%2A>.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="EndSentence">
      <MemberSignature Language="C#" Value="public void EndSentence ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void EndSentence() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.EndSentence" />
      <MemberSignature Language="VB.NET" Value="Public Sub EndSentence ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void EndSentence();" />
      <MemberSignature Language="F#" Value="member this.EndSentence : unit -&gt; unit" Usage="promptBuilder.EndSentence " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Bezeichnet das Ende eines Satzes im <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Lange Eingabe Aufforderungen können mehr als Menschen Sprache gerendert werden, wenn Sie in Sätze und Absätze aufgeteilt werden. Ein Beispiel finden Sie unter <xref:System.Speech.Synthesis.PromptBuilder.StartSentence%2A>.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="EndStyle">
      <MemberSignature Language="C#" Value="public void EndStyle ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void EndStyle() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.EndStyle" />
      <MemberSignature Language="VB.NET" Value="Public Sub EndStyle ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void EndStyle();" />
      <MemberSignature Language="F#" Value="member this.EndStyle : unit -&gt; unit" Usage="promptBuilder.EndStyle " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Bezeichnet das Ende eines Stils im <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Die- <xref:System.Speech.Synthesis.PromptBuilder.EndStyle%2A> Methode beendet den aktuellen Sprechstil. Der Sprechstil kehrt auf die Einstellung zurück, die wirksam war, bevor die <xref:System.Speech.Synthesis.PromptBuilder.StartStyle%2A> Methode einen neuen Sprechstil initiiert hat. Ein Beispiel finden Sie unter <xref:System.Speech.Synthesis.PromptBuilder.StartStyle%2A>.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="EndVoice">
      <MemberSignature Language="C#" Value="public void EndVoice ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void EndVoice() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.EndVoice" />
      <MemberSignature Language="VB.NET" Value="Public Sub EndVoice ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void EndVoice();" />
      <MemberSignature Language="F#" Value="member this.EndVoice : unit -&gt; unit" Usage="promptBuilder.EndVoice " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Bezeichnet das Ende der Verwendung einer Stimme im <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Die- <xref:System.Speech.Synthesis.PromptBuilder.EndVoice%2A> Methode beendet die Verwendung der aktuellen Stimme für die Sprachausgabe. Die Stimme kehrt zu der Einstellung zurück, die wirksam war, bevor die <xref:System.Speech.Synthesis.PromptBuilder.StartVoice%2A> Methode eine neue Stimme initiiert hat.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="IsEmpty">
      <MemberSignature Language="C#" Value="public bool IsEmpty { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance bool IsEmpty" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Synthesis.PromptBuilder.IsEmpty" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property IsEmpty As Boolean" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property bool IsEmpty { bool get(); };" />
      <MemberSignature Language="F#" Value="member this.IsEmpty : bool" Usage="System.Speech.Synthesis.PromptBuilder.IsEmpty" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Boolean</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Ruft ab, ob das <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt leer ist.</summary>
        <value>To be added.</value>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <MemberGroup MemberName="StartParagraph">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Bezeichnet den Anfang eines Absatzes im <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt; optional wird auch eine Sprache angegeben.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Lange Eingabe Aufforderungen können mehr als Menschen Sprache gerendert werden, wenn Sie in Sätze und Absätze aufgeteilt werden.  
  
 ]]></format>
        </remarks>
      </Docs>
    </MemberGroup>
    <Member MemberName="StartParagraph">
      <MemberSignature Language="C#" Value="public void StartParagraph ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void StartParagraph() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.StartParagraph" />
      <MemberSignature Language="VB.NET" Value="Public Sub StartParagraph ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void StartParagraph();" />
      <MemberSignature Language="F#" Value="member this.StartParagraph : unit -&gt; unit" Usage="promptBuilder.StartParagraph " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName Language="C#">[System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")]</AttributeName>
          <AttributeName Language="F#">[&lt;System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")&gt;]</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Bezeichnet das Anfang eines Absatzes im <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Lange Eingabe Aufforderungen können mehr als Menschen Sprache gerendert werden, wenn Sie in Sätze und Absätze aufgeteilt werden.  
  
   
  
## Examples  
 Im folgenden Beispiel wird ein- <xref:System.Speech.Synthesis.PromptBuilder> Objekt erstellt, Inhalt angefügt und der Inhalt in Absätzen und Sätze organisiert.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Create a PromptBuilder object and add content as paragraphs and sentences.  
        PromptBuilder parSent = new PromptBuilder();  
        parSent.StartParagraph();  
        parSent.StartSentence();  
        parSent.AppendText("Introducing the sentence element.");  
        parSent.EndSentence();  
        parSent.StartSentence();  
        parSent.AppendText("You can use it to mark individual sentences.");  
        parSent.EndSentence();  
        parSent.EndParagraph();  
        parSent.StartParagraph();  
        parSent.AppendText("Another simple paragraph. Sentence structure in this paragraph" +  
          "is not explicitly marked.");  
        parSent.EndParagraph();  
  
        // Speak the contents of the SSML prompt.  
        synth.Speak(parSent);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="StartParagraph">
      <MemberSignature Language="C#" Value="public void StartParagraph (System.Globalization.CultureInfo culture);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void StartParagraph(class System.Globalization.CultureInfo culture) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.StartParagraph(System.Globalization.CultureInfo)" />
      <MemberSignature Language="VB.NET" Value="Public Sub StartParagraph (culture As CultureInfo)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void StartParagraph(System::Globalization::CultureInfo ^ culture);" />
      <MemberSignature Language="F#" Value="member this.StartParagraph : System.Globalization.CultureInfo -&gt; unit" Usage="promptBuilder.StartParagraph culture" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="culture" Type="System.Globalization.CultureInfo" />
      </Parameters>
      <Docs>
        <param name="culture">Enthält Informationen über eine bestimmte Kultur, wie die Sprache, den Namen der Kultur, das Schreibsystem, den verwendeten Kalender und darüber, wie Datumsangaben formatiert und Zeichenfolgen sortiert werden.</param>
        <summary>Bezeichnet den Anfang eines Absatzes in der angegebenen Kultur im <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Lange Eingabe Aufforderungen können mehr als Menschen Sprache gerendert werden, wenn Sie in Sätze und Absätze aufgeteilt werden.  
  
 Der- `culture` Parameter für einen Absatz kann sich von der- <xref:System.Speech.Synthesis.PromptBuilder.Culture%2A> Eigenschaft des Objekts unterscheiden, in dem <xref:System.Speech.Synthesis.PromptBuilder> es enthalten ist. Wenngleich der Wert des- `culture` Parameters die-Eigenschaft überschreibt <xref:System.Speech.Synthesis.PromptBuilder.Culture%2A> . <xref:System.Speech.Synthesis.SpeechSynthesizer>Versucht, eine installierte Stimme auszuwählen, die die durch den-Parameter angegebene Sprache `culture` zum sprechen des Absatzes unterstützt. Wenn eine Stimme mit der angegebenen Kultur gefunden wird, wird diese verwendet. Wenn eine Stimme mit der angegebenen Kultur nicht gefunden werden kann, wird die Standardsprache verwendet. Um die von angegebene Stimme nicht mehr zu verwenden <xref:System.Speech.Synthesis.PromptBuilder.StartParagraph%2A> , wird aufgerufen <xref:System.Speech.Synthesis.PromptBuilder.EndParagraph%2A> .  
  
 Zum ordnungsgemäßen aussprechen von Wörtern in der durch den-Parameter angegebenen Sprache `culture` muss eine Sprachsynthese-Engine (Text-zu-Sprache oder TTS) installiert sein, die die Sprache unterstützt. Eine installierte TTS-Engine wird als Stimme bezeichnet. Verwenden Sie die-Methode, um Informationen darüber zu erhalten, welche Stimmen für eine bestimmte Kultur installiert sind <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> .  
  
 Microsoft Windows und die System. Speech-API akzeptieren alle gültigen sprach Ländercodes als Werte für `culture` . Die TTS-Engines, die mit Windows 7 ausgeliefert wurden, unterstützen die folgenden sprach Ländercodes:  
  
-   en-US. Englisch (USA)  
  
-   zh-cn. Chinesisch (China)  
  
-   zh-tw. Chinesisch (Taiwan)  
  
 Sprachcodes mit zwei Buchstaben, z. b. "en", sind ebenfalls zulässig.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <MemberGroup MemberName="StartSentence">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Bezeichnet den Anfang eines Satzes im <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt; optional wird auch eine Sprache angegeben.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Lange Eingabe Aufforderungen können mehr als Menschen Sprache gerendert werden, wenn Sie in Sätze und Absätze aufgeteilt werden.  
  
 ]]></format>
        </remarks>
      </Docs>
    </MemberGroup>
    <Member MemberName="StartSentence">
      <MemberSignature Language="C#" Value="public void StartSentence ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void StartSentence() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.StartSentence" />
      <MemberSignature Language="VB.NET" Value="Public Sub StartSentence ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void StartSentence();" />
      <MemberSignature Language="F#" Value="member this.StartSentence : unit -&gt; unit" Usage="promptBuilder.StartSentence " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName Language="C#">[System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")]</AttributeName>
          <AttributeName Language="F#">[&lt;System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")&gt;]</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Bezeichnet den Anfang eines Satzes im <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Lange Eingabe Aufforderungen können mehr als Menschen Sprache gerendert werden, wenn Sie in Sätze und Absätze aufgeteilt werden.  
  
   
  
## Examples  
 Im folgenden Beispiel wird ein- <xref:System.Speech.Synthesis.PromptBuilder> Objekt erstellt, Inhalt angefügt und der Inhalt in Absätzen und Sätze organisiert.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Create a PromptBuilder object and add content as paragraphs and sentences.  
        PromptBuilder parSent = new PromptBuilder();  
        parSent.StartParagraph();  
        parSent.StartSentence();  
        parSent.AppendText("Introducing the sentence element.");  
        parSent.EndSentence();  
        parSent.StartSentence();  
        parSent.AppendText("You can use it to mark individual sentences.");  
        parSent.EndSentence();  
        parSent.EndParagraph();  
        parSent.StartParagraph();  
        parSent.AppendText("Another simple paragraph. Sentence structure in this paragraph" +  
          "is not explicitly marked.");  
        parSent.EndParagraph();  
  
        // Speak the contents of the SSML prompt.  
        synth.Speak(parSent);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="StartSentence">
      <MemberSignature Language="C#" Value="public void StartSentence (System.Globalization.CultureInfo culture);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void StartSentence(class System.Globalization.CultureInfo culture) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.StartSentence(System.Globalization.CultureInfo)" />
      <MemberSignature Language="VB.NET" Value="Public Sub StartSentence (culture As CultureInfo)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void StartSentence(System::Globalization::CultureInfo ^ culture);" />
      <MemberSignature Language="F#" Value="member this.StartSentence : System.Globalization.CultureInfo -&gt; unit" Usage="promptBuilder.StartSentence culture" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="culture" Type="System.Globalization.CultureInfo" />
      </Parameters>
      <Docs>
        <param name="culture">Enthält Informationen über eine bestimmte Kultur, wie die Sprache, den Namen der Kultur, das Schreibsystem, den verwendeten Kalender und darüber, wie Datumsangaben formatiert und Zeichenfolgen sortiert werden.</param>
        <summary>Bezeichnet den Anfang eines Satzes in der angegebenen Kultur im <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Lange Eingabe Aufforderungen können mehr als Menschen Sprache gerendert werden, wenn Sie in Sätze und Absätze aufgeteilt werden.  
  
 Der- `culture` Parameter für einen Satz kann sich von dem- `culture` Parameter für den Absatz, der den Satz enthält, oder der- <xref:System.Speech.Synthesis.PromptBuilder.Culture%2A> Eigenschaft des <xref:System.Speech.Synthesis.PromptBuilder> Objekts, in dem Sie enthalten sind, unterscheiden.  
  
 Wenngleich der Wert des `culture` -Parameters die <xref:System.Speech.Synthesis.PromptBuilder.Culture%2A> -Eigenschaft und den- `culture` Parameter für den Absatz, der den Satz enthält, überschreibt. <xref:System.Speech.Synthesis.SpeechSynthesizer>Versucht, eine installierte Stimme auszuwählen, die die durch den-Parameter angegebene Sprache `culture` zum sprechen des Satzes unterstützt. Wenn eine Stimme mit der angegebenen Kultur gefunden wird, wird diese verwendet. Wenn eine Stimme mit der angegebenen Kultur nicht gefunden werden kann, wird die Standardsprache verwendet. Um die von angegebene Stimme nicht mehr zu verwenden <xref:System.Speech.Synthesis.PromptBuilder.StartSentence%2A> , wird aufgerufen <xref:System.Speech.Synthesis.PromptBuilder.EndSentence%2A> .  
  
 Zum ordnungsgemäßen aussprechen von Wörtern in der durch den-Parameter angegebenen Sprache `culture` muss eine Sprachsynthese-Engine (Text-zu-Sprache oder TTS) installiert sein, die die Sprache unterstützt. Eine installierte TTS-Engine wird als Stimme bezeichnet. Verwenden Sie die-Methode, um Informationen darüber zu erhalten, welche Stimmen für eine bestimmte Kultur installiert sind <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> .  
  
 Microsoft Windows und die System. Speech-API akzeptieren alle gültigen sprach Ländercodes als Werte für `culture` . Die TTS-Engines, die mit Windows 7 ausgeliefert wurden, unterstützen die folgenden sprach Ländercodes:  
  
-   en-US. Englisch (USA)  
  
-   zh-cn. Chinesisch (China)  
  
-   zh-tw. Chinesisch (Taiwan)  
  
 Sprachcodes mit zwei Buchstaben, z. b. "en", sind ebenfalls zulässig.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="StartStyle">
      <MemberSignature Language="C#" Value="public void StartStyle (System.Speech.Synthesis.PromptStyle style);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void StartStyle(class System.Speech.Synthesis.PromptStyle style) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.StartStyle(System.Speech.Synthesis.PromptStyle)" />
      <MemberSignature Language="VB.NET" Value="Public Sub StartStyle (style As PromptStyle)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void StartStyle(System::Speech::Synthesis::PromptStyle ^ style);" />
      <MemberSignature Language="F#" Value="member this.StartStyle : System.Speech.Synthesis.PromptStyle -&gt; unit" Usage="promptBuilder.StartStyle style" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="style" Type="System.Speech.Synthesis.PromptStyle" />
      </Parameters>
      <Docs>
        <param name="style">Der zu startende Stil.</param>
        <summary>Bezeichnet den Anfang eines Stils im <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Die- <xref:System.Speech.Synthesis.PromptBuilder.StartStyle%2A> Methode nimmt ein- <xref:System.Speech.Synthesis.PromptStyle> Objekt als Argument an. Mit den Eigenschaften des-Objekts können Sie <xref:System.Speech.Synthesis.PromptStyle> den Fokus, die Sprechgeschwindigkeit und das Volume (Lautstärke) festlegen, die auf die Sprachausgabe angewendet werden, während der Stil wirksam ist. Um den aktuellen Stil nicht mehr zu verwenden, wird die- <xref:System.Speech.Synthesis.PromptBuilder.EndStyle%2A> Methode aufgerufen.  
  
> [!NOTE]
> -   Die Sprachsynthese-Engines in Windows unterstützen zu diesem Zeitpunkt nicht den Schwerpunkt Parameter. Durch Festlegen von Werten für den Schwerpunkt Parameter wird keine akustische Änderung in der Ausgabe der synthetisierten Sprache erzeugt.  
> -   Die <xref:System.Speech.Synthesis.PromptVolume.Default> Einstellung für <xref:System.Speech.Synthesis.PromptVolume> ist vollständiges Volume, das entspricht <xref:System.Speech.Synthesis.PromptVolume.ExtraLoud> . Die anderen Einstellungen verringern den Umfang der Sprachausgabe in Relation zum vollständigen Volume.  
  
   
  
## Examples  
 Im folgenden Beispiel wird ein <xref:System.Speech.Synthesis.PromptBuilder> -Objekt erstellt und Text Zeichenfolgen angehängt. Im Beispiel wird die-Methode verwendet, <xref:System.Speech.Synthesis.PromptBuilder.StartStyle%2A> um eine langsame Sprechgeschwindigkeit für die hinzugefügte Zeichenfolge anzugeben, die den Inhalt einer Bestellung auflistet.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Create a PromptBuilder object and add content.  
        PromptBuilder style = new PromptBuilder();  
        style.AppendText("Your order for");  
        style.StartStyle(new PromptStyle(PromptRate.Slow));  
        style.AppendText("one kitchen sink and one faucet");  
        style.EndStyle();  
        style.AppendText("has been confirmed.");  
  
        // Speak the contents of the SSML prompt.  
        synth.Speak(style);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <MemberGroup MemberName="StartVoice">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Weist den Synthesizer an, die Stimme in einem <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt zu ändern.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Eine Stimme stellt eine installierte TTS-Engine dar. Verwenden <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> Sie die-Methoden und die- <xref:System.Speech.Synthesis.VoiceInfo> Klasse, um die Namen und Attribute der installierten TTS-Stimmen (Text-to-Speech) abzurufen, die Sie auswählen können.  
  
 Wenn von einer Anwendung aufgerufen <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> wird, überprüft die Methode, ob jede der in der Registrierung gefundenen Stimmen bestimmte Mindestkriterien erfüllt. Für jede Stimme, die die Überprüfung nicht besteht, wird <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> die- <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> Eigenschaft auf festgelegt `False` Eine Anwendung kann keine der <xref:System.Speech.Synthesis.PromptBuilder.StartVoice%2A> Methoden für eine Stimme aufzurufen, deren- <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> Eigenschaft ist `False` . In der Regel wird die-Eigenschaft einer Stimme von Anwendungen nicht festgelegt <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> .  
  
 ]]></format>
        </remarks>
      </Docs>
    </MemberGroup>
    <Member MemberName="StartVoice">
      <MemberSignature Language="C#" Value="public void StartVoice (System.Globalization.CultureInfo culture);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void StartVoice(class System.Globalization.CultureInfo culture) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.StartVoice(System.Globalization.CultureInfo)" />
      <MemberSignature Language="VB.NET" Value="Public Sub StartVoice (culture As CultureInfo)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void StartVoice(System::Globalization::CultureInfo ^ culture);" />
      <MemberSignature Language="F#" Value="member this.StartVoice : System.Globalization.CultureInfo -&gt; unit" Usage="promptBuilder.StartVoice culture" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="culture" Type="System.Globalization.CultureInfo" />
      </Parameters>
      <Docs>
        <param name="culture">Enthält Informationen über eine bestimmte Kultur, wie die Sprache, den Namen der Kultur, das Schreibsystem, den verwendeten Kalender und darüber, wie Datumsangaben formatiert und Zeichenfolgen sortiert werden.</param>
        <summary>Weist den Synthesizer an, die Stimme im <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt zu ändern und gibt die Kultur der zu verwendenden Stimme an.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Der- `culture` Parameter für <xref:System.Speech.Synthesis.PromptBuilder.StartVoice%2A> kann sich von der-Eigenschaft des-Objekts unterscheiden <xref:System.Speech.Synthesis.PromptBuilder.Culture%2A> , in dem <xref:System.Speech.Synthesis.PromptBuilder> es enthalten ist.  Wenngleich der Wert des- `culture` Parameters die-Eigenschaft überschreibt <xref:System.Speech.Synthesis.PromptBuilder.Culture%2A> . <xref:System.Speech.Synthesis.SpeechSynthesizer>Versucht, eine installierte Stimme auszuwählen, die die durch den-Parameter angegebene Sprache unterstützt `culture` , um den von und eingeschlossenen Inhalt zu sprechen <xref:System.Speech.Synthesis.PromptBuilder.StartVoice%2A> <xref:System.Speech.Synthesis.PromptBuilder.EndVoice%2A> . Wenn eine Stimme mit der angegebenen Kultur gefunden wird, wird diese verwendet. Wenn eine Stimme mit der angegebenen Kultur nicht gefunden werden kann, wird die Standardsprache verwendet. Um die von angegebene Stimme nicht mehr zu verwenden <xref:System.Speech.Synthesis.PromptBuilder.StartVoice%2A> , wird aufgerufen <xref:System.Speech.Synthesis.PromptBuilder.EndVoice%2A> .  
  
 Zum ordnungsgemäßen aussprechen von Wörtern in der durch den-Parameter angegebenen Sprache `culture` muss eine Sprachsynthese-Engine (Text-zu-Sprache oder TTS) installiert sein, die die Sprache unterstützt. Eine installierte TTS-Engine wird als Stimme bezeichnet. Verwenden Sie die-Methode, um Informationen darüber zu erhalten, welche Stimmen für eine bestimmte Kultur installiert sind <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> .  
  
 Microsoft Windows und die System. Speech-API akzeptieren alle gültigen sprach Ländercodes als Werte für `culture` . Die TTS-Engines, die mit Windows 7 ausgeliefert wurden, unterstützen die folgenden sprach Ländercodes:  
  
-   en-US. Englisch (USA)  
  
-   zh-cn. Chinesisch (China)  
  
-   zh-tw. Chinesisch (Taiwan)  
  
 Sprachcodes mit zwei Buchstaben, z. b. "en", sind ebenfalls zulässig.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="StartVoice">
      <MemberSignature Language="C#" Value="public void StartVoice (System.Speech.Synthesis.VoiceGender gender);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void StartVoice(valuetype System.Speech.Synthesis.VoiceGender gender) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.StartVoice(System.Speech.Synthesis.VoiceGender)" />
      <MemberSignature Language="VB.NET" Value="Public Sub StartVoice (gender As VoiceGender)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void StartVoice(System::Speech::Synthesis::VoiceGender gender);" />
      <MemberSignature Language="F#" Value="member this.StartVoice : System.Speech.Synthesis.VoiceGender -&gt; unit" Usage="promptBuilder.StartVoice gender" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="gender" Type="System.Speech.Synthesis.VoiceGender" />
      </Parameters>
      <Docs>
        <param name="gender">Das Geschlecht der zu verwendenden Stimme.</param>
        <summary>Weist den Synthesizer an, die Stimme im <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt zu ändern und gibt das Geschlecht der zu verwendenden Stimme an.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Verwenden <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> Sie die-Methoden und die- <xref:System.Speech.Synthesis.VoiceInfo> Klasse, um die Namen und Attribute der installierten TTS-Stimmen (Text-to-Speech) abzurufen, die Sie auswählen können.  
  
 , Wenn die durch den Anruf angegebene Stimme nicht mehr verwendet werden soll <xref:System.Speech.Synthesis.PromptBuilder.StartVoice%2A> <xref:System.Speech.Synthesis.PromptBuilder.EndVoice%2A> .  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="StartVoice">
      <MemberSignature Language="C#" Value="public void StartVoice (System.Speech.Synthesis.VoiceInfo voice);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void StartVoice(class System.Speech.Synthesis.VoiceInfo voice) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.StartVoice(System.Speech.Synthesis.VoiceInfo)" />
      <MemberSignature Language="VB.NET" Value="Public Sub StartVoice (voice As VoiceInfo)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void StartVoice(System::Speech::Synthesis::VoiceInfo ^ voice);" />
      <MemberSignature Language="F#" Value="member this.StartVoice : System.Speech.Synthesis.VoiceInfo -&gt; unit" Usage="promptBuilder.StartVoice voice" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="voice" Type="System.Speech.Synthesis.VoiceInfo" />
      </Parameters>
      <Docs>
        <param name="voice">Die Kriterien für die zu verwendende Stimme.</param>
        <summary>Weist den Synthesizer an, die Stimme im <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt zu ändern und gibt Kriterien für die neue Stimme an.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Verwenden <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> Sie die-Methoden und die- <xref:System.Speech.Synthesis.VoiceInfo> Klasse, um die Namen und Attribute der installierten TTS-Stimmen (Text-to-Speech) abzurufen, die Sie auswählen können.  
  
 , Wenn die durch den Anruf angegebene Stimme nicht mehr verwendet werden soll <xref:System.Speech.Synthesis.PromptBuilder.StartVoice%2A> <xref:System.Speech.Synthesis.PromptBuilder.EndVoice%2A> .  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="StartVoice">
      <MemberSignature Language="C#" Value="public void StartVoice (string name);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void StartVoice(string name) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.StartVoice(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub StartVoice (name As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void StartVoice(System::String ^ name);" />
      <MemberSignature Language="F#" Value="member this.StartVoice : string -&gt; unit" Usage="promptBuilder.StartVoice name" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="name" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="name">Der Name der Stimme, die verwendet werden soll.</param>
        <summary>Weist den Synthesizer an, die Stimme im <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt zu ändern und gibt den Namen der zu verwendenden Stimme an.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Verwenden Sie eine der-Methoden, um Informationen darüber zu erhalten, welche Stimmen installiert sind <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> .  
  
 , Wenn die durch den Anruf angegebene Stimme nicht mehr verwendet werden soll <xref:System.Speech.Synthesis.PromptBuilder.StartVoice%2A> <xref:System.Speech.Synthesis.PromptBuilder.EndVoice%2A> .  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="StartVoice">
      <MemberSignature Language="C#" Value="public void StartVoice (System.Speech.Synthesis.VoiceGender gender, System.Speech.Synthesis.VoiceAge age);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void StartVoice(valuetype System.Speech.Synthesis.VoiceGender gender, valuetype System.Speech.Synthesis.VoiceAge age) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.StartVoice(System.Speech.Synthesis.VoiceGender,System.Speech.Synthesis.VoiceAge)" />
      <MemberSignature Language="VB.NET" Value="Public Sub StartVoice (gender As VoiceGender, age As VoiceAge)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void StartVoice(System::Speech::Synthesis::VoiceGender gender, System::Speech::Synthesis::VoiceAge age);" />
      <MemberSignature Language="F#" Value="member this.StartVoice : System.Speech.Synthesis.VoiceGender * System.Speech.Synthesis.VoiceAge -&gt; unit" Usage="promptBuilder.StartVoice (gender, age)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="gender" Type="System.Speech.Synthesis.VoiceGender" />
        <Parameter Name="age" Type="System.Speech.Synthesis.VoiceAge" />
      </Parameters>
      <Docs>
        <param name="gender">Das Geschlecht der neuen zu verwendenden Stimme.</param>
        <param name="age">Das Alter der zu verwendenden Stimme.</param>
        <summary>Weist den Synthesizer an, die Stimme im <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt zu ändern und gibt das Geschlecht und das Alter der neuen Stimme an.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Verwenden <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> Sie die-Methoden und die- <xref:System.Speech.Synthesis.VoiceInfo> Klasse, um die Namen und Attribute der installierten TTS-Stimmen (Text-to-Speech) abzurufen, die Sie auswählen können.  
  
 , Wenn die durch den Anruf angegebene Stimme nicht mehr verwendet werden soll <xref:System.Speech.Synthesis.PromptBuilder.StartVoice%2A> <xref:System.Speech.Synthesis.PromptBuilder.EndVoice%2A> .  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="StartVoice">
      <MemberSignature Language="C#" Value="public void StartVoice (System.Speech.Synthesis.VoiceGender gender, System.Speech.Synthesis.VoiceAge age, int voiceAlternate);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void StartVoice(valuetype System.Speech.Synthesis.VoiceGender gender, valuetype System.Speech.Synthesis.VoiceAge age, int32 voiceAlternate) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.StartVoice(System.Speech.Synthesis.VoiceGender,System.Speech.Synthesis.VoiceAge,System.Int32)" />
      <MemberSignature Language="VB.NET" Value="Public Sub StartVoice (gender As VoiceGender, age As VoiceAge, voiceAlternate As Integer)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void StartVoice(System::Speech::Synthesis::VoiceGender gender, System::Speech::Synthesis::VoiceAge age, int voiceAlternate);" />
      <MemberSignature Language="F#" Value="member this.StartVoice : System.Speech.Synthesis.VoiceGender * System.Speech.Synthesis.VoiceAge * int -&gt; unit" Usage="promptBuilder.StartVoice (gender, age, voiceAlternate)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="gender" Type="System.Speech.Synthesis.VoiceGender" />
        <Parameter Name="age" Type="System.Speech.Synthesis.VoiceAge" />
        <Parameter Name="voiceAlternate" Type="System.Int32" />
      </Parameters>
      <Docs>
        <param name="gender">Das Geschlecht der zu verwendenden Stimme.</param>
        <param name="age">Das Alter der zu verwendenden Stimme.</param>
        <param name="voiceAlternate">Eine ganze Zahl, die eine bevorzugte Stimme angibt, wenn mehr als eine Stimme den <paramref name="gender" />- und <paramref name="age" />-Parametern entspricht.</param>
        <summary>Weist den Synthesizer an, die Stimme im <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt zu ändern und gibt ihr Geschlecht, Alter und eine bevorzugte Stimme an, die dem angegebenen Geschlecht und Alter entspricht.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Eine Sprachsynthese-Engine zählt die gefundenen Übereinstimmungen für die angegebenen Parameter und gibt die Stimme zurück, wenn die Anzahl gleich dem- `voiceAlternate` Parameter ist.  
  
 Verwenden <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> Sie die-Methoden und die- <xref:System.Speech.Synthesis.VoiceInfo> Klasse, um die Namen und Attribute der installierten TTS-Stimmen (Text-to-Speech) abzurufen, die Sie auswählen können.  
  
 , Wenn die durch den Anruf angegebene Stimme nicht mehr verwendet werden soll <xref:System.Speech.Synthesis.PromptBuilder.StartVoice%2A> <xref:System.Speech.Synthesis.PromptBuilder.EndVoice%2A> .  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Synthesis.PromptBuilder.StartVoice(System.Speech.Synthesis.VoiceGender,System.Speech.Synthesis.VoiceAge)" />
      </Docs>
    </Member>
    <Member MemberName="ToXml">
      <MemberSignature Language="C#" Value="public string ToXml ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance string ToXml() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.ToXml" />
      <MemberSignature Language="VB.NET" Value="Public Function ToXml () As String" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; System::String ^ ToXml();" />
      <MemberSignature Language="F#" Value="member this.ToXml : unit -&gt; string" Usage="promptBuilder.ToXml " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.String</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Gibt das SSML zurück, das aus dem <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt generiert wird.</summary>
        <returns>Gibt das SSML zurück, das aus dem <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt als einzelne Zeile generiert wird.</returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Die <xref:System.Speech.Synthesis.PromptBuilder.ToXml%2A> Methode versucht nicht, die zurückgegebene SSML in irgendeiner Weise zu formatieren.  
  
   
  
## Examples  
 Im folgenden Beispiel wird ein- <xref:System.Speech.Synthesis.PromptBuilder> Objekt erstellt, Text angefügt und dann die SSML-Entsprechung der Eingabeaufforderung in die Konsole geschrieben, bevor der Inhalt der Eingabeaufforderung gesprochen wird.  
  
```csharp  
  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Create a PromptBuilder object and add content.  
        PromptBuilder style = new PromptBuilder();  
        style.AppendText("Your order for");  
        style.StartStyle(new PromptStyle(PromptRate.Slow));  
        style.AppendText("one kitchen sink and one faucet");  
        style.EndStyle();  
        style.AppendText("has been confirmed.");  
  
        // Write the contents of the PromptBuilder object to the console as  
        // an SSML-compatible XML file.  
        string myXml = style.ToXml();  
        Console.WriteLine("This is the SSML equivalent of the PromptBuilder: \n\n" + myXml);  
  
        // Speak the contents of the SSML prompt.  
        synth.Speak(style);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
  </Members>
</Type>
