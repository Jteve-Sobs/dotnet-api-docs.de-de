<Type Name="SpeechSynthesizer" FullName="System.Speech.Synthesis.SpeechSynthesizer">
  <Metadata><Meta Name="ms.openlocfilehash" Value="3606d0bf6fe417ff061d778f3c9ad5b1188f9193" /><Meta Name="ms.sourcegitcommit" Value="562a9964cdf715280f961a412a1abdc5570c052c" /><Meta Name="ms.translationtype" Value="MT" /><Meta Name="ms.contentlocale" Value="de-DE" /><Meta Name="ms.lasthandoff" Value="03/22/2019" /><Meta Name="ms.locfileid" Value="58349290" /></Metadata><TypeSignature Language="C#" Value="public sealed class SpeechSynthesizer : IDisposable" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi sealed beforefieldinit SpeechSynthesizer extends System.Object implements class System.IDisposable" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Synthesis.SpeechSynthesizer" />
  <TypeSignature Language="VB.NET" Value="Public NotInheritable Class SpeechSynthesizer&#xA;Implements IDisposable" />
  <TypeSignature Language="C++ CLI" Value="public ref class SpeechSynthesizer sealed : IDisposable" />
  <TypeSignature Language="F#" Value="type SpeechSynthesizer = class&#xA;    interface IDisposable" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>3.0.0.0</AssemblyVersion>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Object</BaseTypeName>
  </Base>
  <Interfaces>
    <Interface>
      <InterfaceName>System.IDisposable</InterfaceName>
    </Interface>
  </Interfaces>
  <Docs>
    <summary>Bietet Zugriff auf die Funktionalität einer installierten Sprachsynthese-Engine.</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Beim Erstellen einer neuen <xref:System.Speech.Synthesis.SpeechSynthesizer> Objekt ist, wird er verwendet die Standard-System-Stimme. So konfigurieren Sie die <xref:System.Speech.Synthesis.SpeechSynthesizer> verwenden, um eines der stimmen zurück, installierten Sprachsynthese (Text-Sprach-) verwenden, die <xref:System.Speech.Synthesis.SpeechSynthesizer.SelectVoice%2A> oder <xref:System.Speech.Synthesis.SpeechSynthesizer.SelectVoiceByHints%2A> Methode. Rufen Sie Informationen darüber, welche stimmen zurück, die installiert werden mit der <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> Methode und die <xref:System.Speech.Synthesis.VoiceInfo> Klasse.  
  
 Diese Klasse bietet auch die Kontrolle über die folgenden Aspekte der Sprachsynthese:  
  
-   So konfigurieren Sie die Ausgabe für die <xref:System.Speech.Synthesis.SpeechSynthesizer> -Objekts die <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToAudioStream%2A>, <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToDefaultAudioDevice%2A>, <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToNull%2A>, und <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToWaveFile%2A> Methoden.  
  
-   Verwenden Sie zum Generieren der Sprache der <xref:System.Speech.Synthesis.SpeechSynthesizer.Speak%2A>, <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync%2A>, <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsml%2A>, oder <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsmlAsync%2A> Methode. Die <xref:System.Speech.Synthesis.SpeechSynthesizer> können die Sprache aus Text, erzeugen eine <xref:System.Speech.Synthesis.Prompt> oder <xref:System.Speech.Synthesis.PromptBuilder> Objekt oder [Speech Synthesis Markup Language (SSML) Version 1.0](https://go.microsoft.com/fwlink/?LinkId=201763).  
  
-   Verwenden Sie zum Anhalten und Fortsetzen von Sprachsynthese, die <xref:System.Speech.Synthesis.SpeechSynthesizer.Pause%2A> und <xref:System.Speech.Synthesis.SpeechSynthesizer.Resume%2A> Methoden.  
  
-   Verwenden Sie zum Hinzufügen oder Entfernen von Lexika, die <xref:System.Speech.Synthesis.SpeechSynthesizer.AddLexicon%2A> und <xref:System.Speech.Synthesis.SpeechSynthesizer.RemoveLexicon%2A> Methoden. Die <xref:System.Speech.Synthesis.SpeechSynthesizer> können eine oder mehrere Lexika, führen die Aussprache eines Worts.  
  
-   Verwenden Sie zum Ändern der Übermittlung der Sprachausgabe die <xref:System.Speech.Synthesis.SpeechSynthesizer.Rate%2A> und <xref:System.Speech.Synthesis.SpeechSynthesizer.Volume%2A> Eigenschaften.  
  
 Die <xref:System.Speech.Synthesis.SpeechSynthesizer> Ereignisse auslöst, wenn es feststellt, dass bestimmte Funktionen in den eingabeaufforderungen: (<xref:System.Speech.Synthesis.SpeechSynthesizer.BookmarkReached>, <xref:System.Speech.Synthesis.SpeechSynthesizer.PhonemeReached>, <xref:System.Speech.Synthesis.SpeechSynthesizer.VisemeReached>, und <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakProgress>). Sie löst ebenfalls Ereignisse, die beim Start zu melden (<xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakStarted>) und (<xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakCompleted>) der Vorgänge sprechen und auf der Änderung der Sprecherstimme Stimme (<xref:System.Speech.Synthesis.SpeechSynthesizer.VoiceChange>).  
  
> [!NOTE]
>  Rufen Sie immer <xref:System.Speech.Synthesis.SpeechSynthesizer.Dispose%2A> auf, bevor Sie den letzten Verweis auf das <xref:System.Speech.Synthesis.SpeechSynthesizer> freigeben. Andernfalls bleiben die verwendeten Ressourcen reserviert, bis die Garbage Collection die <xref:System.Speech.Synthesis.SpeechSynthesizer>-Methode des <xref:System.Object.Finalize%2A>-Objekts aufruft.  
  
   
  
## Examples  
 Im folgende Beispiel ist Teil einer Konsolenanwendung, die initialisiert einen <xref:System.Speech.Synthesis.SpeechSynthesizer> Objekt und hält Vorträge eine Zeichenfolge.  
  
```csharp  
  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      SpeechSynthesizer synth = new SpeechSynthesizer();  
  
      // Configure the audio output.   
      synth.SetOutputToDefaultAudioDevice();  
  
      // Speak a string.  
      synth.Speak("This example demonstrates a basic use of Speech Synthesizer");  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
    </remarks>
    <altmember cref="T:System.Speech.Synthesis.InstalledVoice" />
    <altmember cref="T:System.Speech.Synthesis.Prompt" />
    <altmember cref="T:System.Speech.Synthesis.PromptBuilder" />
    <related type="Article" href="https://docs.microsoft.com/previous-versions/office/developer/speech-technologies/hh361644(v%3doffice.14)">Sprachsynthese</related>
  </Docs>
  <Members>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public SpeechSynthesizer ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.#ctor" />
      <MemberSignature Language="VB.NET" Value="Public Sub New ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; SpeechSynthesizer();" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <Parameters />
      <Docs>
        <summary>Initialisiert eine neue Instanz der <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" />-Klasse.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Wenn Sie ein neues initialisieren <xref:System.Speech.Synthesis.SpeechSynthesizer> -Instanz verwendet die Standard-System-Stimme. So konfigurieren Sie die <xref:System.Speech.Synthesis.SpeechSynthesizer> verwenden, um eines der stimmen zurück, installierten Sprachsynthese (Text-Sprach-) verwenden, die <xref:System.Speech.Synthesis.SpeechSynthesizer.SelectVoice%2A> oder <xref:System.Speech.Synthesis.SpeechSynthesizer.SelectVoiceByHints%2A> Methode. Rufen Sie Informationen darüber, welche stimmen zurück, die installiert werden mit der <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> Methode und die <xref:System.Speech.Synthesis.VoiceInfo> Klasse.  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Synthesis.InstalledVoice" />
        <altmember cref="M:System.Speech.Synthesis.SpeechSynthesizer.SelectVoice(System.String)" />
        <altmember cref="M:System.Speech.Synthesis.SpeechSynthesizer.SelectVoiceByHints(System.Speech.Synthesis.VoiceGender)" />
        <altmember cref="M:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices" />
      </Docs>
    </Member>
    <Member MemberName="AddLexicon">
      <MemberSignature Language="C#" Value="public void AddLexicon (Uri uri, string mediaType);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AddLexicon(class System.Uri uri, string mediaType) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.AddLexicon(System.Uri,System.String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AddLexicon(Uri ^ uri, System::String ^ mediaType);" />
      <MemberSignature Language="F#" Value="member this.AddLexicon : Uri * string -&gt; unit" Usage="speechSynthesizer.AddLexicon (uri, mediaType)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="uri" Type="System.Uri" />
        <Parameter Name="mediaType" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="uri">Der Speicherort der Lexikoninformationen.</param>
        <param name="mediaType">Der Medientyp des Lexikons. Bei Medientypwerten wird die Groß-/Kleinschreibung nicht berücksichtigt.</param>
        <summary>Fügt dem <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" />-Objekt ein Lexikon hinzu.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Ein Lexikon Aussprache ist eine Auflistung von Wörtern oder Ausdrücken sowie deren Aussprache, die aus Buchstaben und Zeichen aus einem unterstützten Lautalphabet bestehen. Sie können ein Lexikon verwenden, um benutzerdefinierte Aussprachen für spezielle Vokabular in der Anwendung angeben.  
  
 Aussprache, die in der externen Lexikondatei angegeben haben Vorrang vor der Aussprache der im internen Lexikon vorhanden oder ein Wörterbuch des Sprache-Synthesizers. Jedoch Aussprache Inline angegeben, in den eingabeaufforderungen, die mit einem erstellt die <xref:System.Speech.Synthesis.PromptBuilder.AppendTextWithPronunciation%2A>, <xref:System.Speech.Synthesis.PromptBuilder.AppendSsmlMarkup%2A>, oder <xref:System.Speech.Synthesis.PromptBuilder.AppendSsml%2A> Methoden haben Vorrang vor Aussprache, die in jeder Lexikon angegeben. Inline-Aussprache gelten nur für ein einzelnes Vorkommen eines Worts. Finden Sie unter [Lexika und phonetischen Alphabete](https://docs.microsoft.com/previous-versions/office/developer/speech-technologies/hh378335(v%3doffice.14)) für Weitere Informationen.  
  
 Sie können mehrere Lexika zum Hinzufügen einer <xref:System.Speech.Synthesis.SpeechSynthesizer> Objekt. Zwei Werte werden für die derzeit unterstützt die `mediaType` Parameter:  
  
-   Der Wert `application/pls+xml` gibt an, dass das Lexikon, entspricht die [Aussprache Lexikon Spezifikation (PLS) Version 1.0](https://go.microsoft.com/fwlink/?LinkId=201766). Dies ist das bevorzugte Format verwenden.  
  
-   Der Wert `application/vdn.ms-sapi-lex` gibt an, dass das Lexikon-Format Unkomprimierten Lexikon vorhanden ist, wird ein Format, das Microsoft. Dies ist ein altes Format, und es wird empfohlen, dass Sie das oben beschriebene PLS-Format verwenden.  
  
   
  
## Examples  
 Das folgende Beispiel zeigt die Auswirkungen der hinzufügen und entfernen ein Lexikon, das eine benutzerdefinierte Aussprache für das Wort "blue" enthält. Das Lexikon definiert die Aussprache "Blau" Sound wie "Bleep". Während das Lexikon geladen wird, verwendet der Sprache-Synthesizer die Aussprache, die in das Lexikon definiert.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Speak the prompt.  
        synth.Speak("My favorite color is blue.");  
  
        // Add a lexicon that changes the pronunciation of "blue".  
        synth.AddLexicon(new Uri("C:\\test\\Blue.pls"), "application/pls+xml");  
  
        // Speak the prompt.  
        synth.Speak("My favorite color is blue.");  
  
        // Remove the lexicon.  
        synth.RemoveLexicon(new Uri("C:\\test\\Blue.pls"));  
  
        // Speak the prompt.  
        synth.Speak("My favorite color is blue.");  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
```  
  
 Folgen den Inhalt der Lexikondatei Blue.pls:  
  
```xml  
<?xml version="1.0" encoding="UTF-8"?>  
  
<lexicon version="1.0"   
      xmlns="http://www.w3.org/2005/01/pronunciation-lexicon"  
      alphabet="x-microsoft-ups" xml:lang="en-US">  
  
  <lexeme>  
    <grapheme> blue </grapheme>  
    <phoneme> B L I P </phoneme>  
  </lexeme>  
  
</lexicon>  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Synthesis.SpeechSynthesizer.RemoveLexicon(System.Uri)" />
      </Docs>
    </Member>
    <Member MemberName="BookmarkReached">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Synthesis.BookmarkReachedEventArgs&gt; BookmarkReached;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Synthesis.BookmarkReachedEventArgs&gt; BookmarkReached" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Synthesis.SpeechSynthesizer.BookmarkReached" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event BookmarkReached As EventHandler(Of BookmarkReachedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Synthesis::BookmarkReachedEventArgs ^&gt; ^ BookmarkReached;" />
      <MemberSignature Language="F#" Value="member this.BookmarkReached : EventHandler&lt;System.Speech.Synthesis.BookmarkReachedEventArgs&gt; " Usage="member this.BookmarkReached : System.EventHandler&lt;System.Speech.Synthesis.BookmarkReachedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Synthesis.BookmarkReachedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Wird ausgelöst, wenn das <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" /> ein Lesezeichen in einer Eingabeaufforderung feststellt.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Die <xref:System.Speech.Synthesis.SpeechSynthesizer> löst dieses Ereignis bei der Verarbeitung eines der <xref:System.Speech.Synthesis.SpeechSynthesizer.Speak%2A>, <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync%2A>, <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsml%2A>, oder <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsmlAsync%2A> Methoden. Weitere Informationen zu dem Ereignis zugeordneten Daten, finden Sie unter <xref:System.Speech.Synthesis.BookmarkReachedEventArgs>.  
  
 Sie können mithilfe von Lesezeichen hinzufügen der <xref:System.Speech.Synthesis.PromptBuilder.AppendBookmark%2A> Methode.  
  
   
  
## Examples  
 Das folgende Beispiel erstellt eine Eingabeaufforderung, die enthält zwei Lesezeichen und sendet die Ausgabe an eine WAV-Datei für die Wiedergabe. Der Handler für die <xref:System.Speech.Synthesis.SpeechSynthesizer.BookmarkReached> Ereignis schreibt den Namen des Lesezeichens und seine Position im Audiostream aus, wenn das Ereignis, an die Konsole ausgelöst wurde.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToWaveFile(@"C:\test\weather.wav");  
  
        // Create a SoundPlayer instance to play the output audio file.  
        System.Media.SoundPlayer m_SoundPlayer =  
          new System.Media.SoundPlayer(@"C:\test\weather.wav");  
  
        // Build a prompt and append bookmarks.  
        PromptBuilder builder = new PromptBuilder(  
          new System.Globalization.CultureInfo("en-US"));  
        builder.AppendText(  
          "The weather forecast for today is partly cloudy with some sun breaks.");  
        builder.AppendBookmark("Daytime forecast");  
        builder.AppendText(  
          "Tonight's weather will be cloudy with a 30% chance of showers.");  
        builder.AppendBookmark("Nightime forecast");  
  
        // Add a handler for the BookmarkReached event.  
        synth.BookmarkReached +=  
          new EventHandler<BookmarkReachedEventArgs>(synth_BookmarkReached);  
  
        // Speak the prompt and play back the output file.  
        synth.Speak(builder);  
        m_SoundPlayer.Play();  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Write the name and position of the bookmark to the console.  
    static void synth_BookmarkReached(object sender, BookmarkReachedEventArgs e)  
    {  
      Console.WriteLine("Bookmark ({0}) reached at: {1} ",  
        e.Bookmark, e.AudioPosition);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="" />
      </Docs>
    </Member>
    <Member MemberName="Dispose">
      <MemberSignature Language="C#" Value="public void Dispose ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig newslot virtual instance void Dispose() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.Dispose" />
      <MemberSignature Language="VB.NET" Value="Public Sub Dispose ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; virtual void Dispose();" />
      <MemberSignature Language="F#" Value="abstract member Dispose : unit -&gt; unit&#xA;override this.Dispose : unit -&gt; unit" Usage="speechSynthesizer.Dispose " />
      <MemberType>Method</MemberType>
      <Implements>
        <InterfaceMember>M:System.IDisposable.Dispose</InterfaceMember>
      </Implements>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Verwirft das <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" />-Objekt und gibt Ressourcen frei, die während der Sitzung verwendet werden.</summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="Finalize">
      <MemberSignature Language="C#" Value="~SpeechSynthesizer ();" />
      <MemberSignature Language="ILAsm" Value=".method familyhidebysig virtual instance void Finalize() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.Finalize" />
      <MemberSignature Language="VB.NET" Value="Finalize ()" />
      <MemberSignature Language="C++ CLI" Value="!SpeechSynthesizer ()" />
      <MemberSignature Language="F#" Value="override this.Finalize : unit -&gt; unit" Usage="speechSynthesizer.Finalize " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Stellt die Bereinigung von Ressourcen für den Fall sicher, dass die <see cref="M:System.Speech.Synthesis.SpeechSynthesizer.Dispose" />-Methode nicht aufgerufen wird.</summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="GetCurrentlySpokenPrompt">
      <MemberSignature Language="C#" Value="public System.Speech.Synthesis.Prompt GetCurrentlySpokenPrompt ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Speech.Synthesis.Prompt GetCurrentlySpokenPrompt() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.GetCurrentlySpokenPrompt" />
      <MemberSignature Language="VB.NET" Value="Public Function GetCurrentlySpokenPrompt () As Prompt" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; System::Speech::Synthesis::Prompt ^ GetCurrentlySpokenPrompt();" />
      <MemberSignature Language="F#" Value="member this.GetCurrentlySpokenPrompt : unit -&gt; System.Speech.Synthesis.Prompt" Usage="speechSynthesizer.GetCurrentlySpokenPrompt " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Synthesis.Prompt</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Ruft die Eingabeaufforderung ab, die <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" /> spricht.</summary>
        <returns>Gibt das Prompt-Objekt zurück, das derzeit gesprochen wird.</returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Examples  
  
```csharp  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="" />
      </Docs>
    </Member>
    <MemberGroup MemberName="GetInstalledVoices">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Gibt die Auflistung von Stimmen der Sprachsynthese (Text-zu-Sprache) zurück, die derzeit auf dem System installiert sind.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Wenn eine Anwendung ruft <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A>, die Methode stellt sicher, dass jede der stimmen zurück (Engines für die Sprachsynthese) in die Registrierung erfüllt bestimmte Mindestkriterien gefunden. Für alle Stimme an, die Überprüfung schlägt fehl, <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> legt die <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> Eigenschaft, um `False`. Eine Anwendung eine Stimme kann nicht ausgewählt werden, deren <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> Eigenschaft `False`. Anwendungen werden in der Regel nicht Festlegen der Sprachnotizen <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> Eigenschaft.  
  
 ]]></format>
        </remarks>
      </Docs>
    </MemberGroup>
    <Member MemberName="GetInstalledVoices">
      <MemberSignature Language="C#" Value="public System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Synthesis.InstalledVoice&gt; GetInstalledVoices ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Collections.ObjectModel.ReadOnlyCollection`1&lt;class System.Speech.Synthesis.InstalledVoice&gt; GetInstalledVoices() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices" />
      <MemberSignature Language="VB.NET" Value="Public Function GetInstalledVoices () As ReadOnlyCollection(Of InstalledVoice)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; System::Collections::ObjectModel::ReadOnlyCollection&lt;System::Speech::Synthesis::InstalledVoice ^&gt; ^ GetInstalledVoices();" />
      <MemberSignature Language="F#" Value="member this.GetInstalledVoices : unit -&gt; System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Synthesis.InstalledVoice&gt;" Usage="speechSynthesizer.GetInstalledVoices " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Synthesis.InstalledVoice&gt;</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Gibt alle installierten Stimmen der Sprachsynthese (Text-zu-Sprache) zurück.</summary>
        <returns>Gibt eine schreibgeschützte Auflistung der Stimmen zurück, die derzeit auf dem System installiert sind.</returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Eine Stimme ist ein Modul für die Sprachsynthese (Text-Sprach- oder TTS), die auf dem System installiert ist.  
  
   
  
## Examples  
 Im folgende Beispiel ist Teil einer Konsolenanwendung, die initialisiert einen <xref:System.Speech.Synthesis.SpeechSynthesizer> Objekt und gibt Sie an die Konsole eine Liste mit den installierten stimmen (Engines für die Sprachsynthese) und zeigt die Informationen, die für jede Sprache verfügbar ist.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
using System.Speech.AudioFormat;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Output information about all of the installed voices.   
        Console.WriteLine("Installed voices -");  
        foreach (InstalledVoice voice in synth.GetInstalledVoices())  
        {  
          VoiceInfo info = voice.VoiceInfo;  
          string AudioFormats = "";  
          foreach (SpeechAudioFormatInfo fmt in info.SupportedAudioFormats)  
          {  
            AudioFormats += String.Format("{0}\n",  
            fmt.EncodingFormat.ToString());  
          }  
  
          Console.WriteLine(" Name:          " + info.Name);  
          Console.WriteLine(" Culture:       " + info.Culture);  
          Console.WriteLine(" Age:           " + info.Age);  
          Console.WriteLine(" Gender:        " + info.Gender);  
          Console.WriteLine(" Description:   " + info.Description);  
          Console.WriteLine(" ID:            " + info.Id);  
          Console.WriteLine(" Enabled:       " + voice.Enabled);  
          if (info.SupportedAudioFormats.Count != 0)  
          {  
            Console.WriteLine( " Audio formats: " + AudioFormats);  
          }  
          else  
          {  
            Console.WriteLine(" No supported audio formats found");  
          }  
  
          string AdditionalInfo = "";  
          foreach (string key in info.AdditionalInfo.Keys)  
          {  
            AdditionalInfo += String.Format("  {0}: {1}\n", key, info.AdditionalInfo[key]);  
          }  
  
          Console.WriteLine(" Additional Info - " + AdditionalInfo);  
          Console.WriteLine();  
        }  
      }  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Synthesis.InstalledVoice" />
        <altmember cref="M:System.Speech.Synthesis.SpeechSynthesizer.SelectVoice(System.String)" />
        <altmember cref="Overload:System.Speech.Synthesis.SpeechSynthesizer.SelectVoiceByHints" />
        <altmember cref="Overload:System.Speech.Synthesis.PromptBuilder.StartVoice" />
      </Docs>
    </Member>
    <Member MemberName="GetInstalledVoices">
      <MemberSignature Language="C#" Value="public System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Synthesis.InstalledVoice&gt; GetInstalledVoices (System.Globalization.CultureInfo culture);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Collections.ObjectModel.ReadOnlyCollection`1&lt;class System.Speech.Synthesis.InstalledVoice&gt; GetInstalledVoices(class System.Globalization.CultureInfo culture) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices(System.Globalization.CultureInfo)" />
      <MemberSignature Language="VB.NET" Value="Public Function GetInstalledVoices (culture As CultureInfo) As ReadOnlyCollection(Of InstalledVoice)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; System::Collections::ObjectModel::ReadOnlyCollection&lt;System::Speech::Synthesis::InstalledVoice ^&gt; ^ GetInstalledVoices(System::Globalization::CultureInfo ^ culture);" />
      <MemberSignature Language="F#" Value="member this.GetInstalledVoices : System.Globalization.CultureInfo -&gt; System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Synthesis.InstalledVoice&gt;" Usage="speechSynthesizer.GetInstalledVoices culture" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Synthesis.InstalledVoice&gt;</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="culture" Type="System.Globalization.CultureInfo" />
      </Parameters>
      <Docs>
        <param name="culture">Das Gebietsschema, das die Sprache unterstützen muss.</param>
        <summary>Gibt alle installierten Stimmen der Sprachsynthese (Text-zu-Sprache) zurück, die ein bestimmtes Gebietsschema unterstützen.</summary>
        <returns>Gibt eine schreibgeschützte Auflistung der Stimmen zurück, die derzeit auf dem System installiert sind, die das angegebene Gebietsschema unterstützen.</returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Wenn keine das angegebene Gebietsschema der installierten stimmen-Unterstützung, gibt diese Methode eine leere Auflistung zurück.  
  
 Microsoft Windows und die "System.Speech"-API akzeptiert alle gültige Sprache / Land-Codes. Um unter Verwendung der Sprache, die in die Culture-Eigenschaft angegebenen Sprachsynthese auszuführen, muss eine Sprachsynthese-Engine, die dieser Sprache / Land-Code unterstützt installiert werden. Der sprachesynthese-Engines, die mit den im Lieferumfang von Microsoft Windows 7 arbeiten Sie mit der folgenden Sprache / Land-Codes:  
  
-   En-US. Englisch (USA)  
  
-   zh-CN. Chinesisch (China)  
  
-   zh-TW. Chinesisch (Taiwan)  
  
 Zwei Buchstaben bestehenden Sprachcodes, z. B. "En" sind ebenfalls zulässig.  
  
   
  
## Examples  
 Im folgende Beispiel ist Teil einer Konsolenanwendung, die initialisiert einen <xref:System.Speech.Synthesis.SpeechSynthesizer> Objekt und gibt Sie an die Konsole eine Liste der installierten stimmen zurück, die das Gebietsschema En-US zu unterstützen.  
  
```csharp  
using System;  
using System.Globalization;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the speech synthesizer.  
      using (SpeechSynthesizer synthesizer = new SpeechSynthesizer())  
      {  
  
        // Output information about all of the installed voices that  
        // support the en-US locacale.   
        Console.WriteLine("Installed voices for the en-US locale:");  
        foreach (InstalledVoice voice in  
          synthesizer.GetInstalledVoices(new CultureInfo("en-US")))  
        {  
          VoiceInfo info = voice.VoiceInfo;  
          OutputVoiceInfo(info);  
        }  
  
        // Output information about the current voice.  
        Console.WriteLine();  
        Console.WriteLine("Current voice:");  
        OutputVoiceInfo(synthesizer.Voice);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Display information about a synthesizer voice.  
    private static void OutputVoiceInfo(VoiceInfo info)  
    {  
      Console.WriteLine("  Name: {0}, culture: {1}, gender: {2}, age: {3}.",  
        info.Name, info.Culture, info.Gender, info.Age);  
      Console.WriteLine("    Description: {0}", info.Description);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Synthesis.InstalledVoice" />
      </Docs>
    </Member>
    <Member MemberName="Pause">
      <MemberSignature Language="C#" Value="public void Pause ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void Pause() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.Pause" />
      <MemberSignature Language="VB.NET" Value="Public Sub Pause ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void Pause();" />
      <MemberSignature Language="F#" Value="member this.Pause : unit -&gt; unit" Usage="speechSynthesizer.Pause " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Pausiert das <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" />-Objekt.</summary>
        <remarks>To be added.</remarks>
        <altmember cref="M:System.Speech.Synthesis.SpeechSynthesizer.Resume" />
        <altmember cref="P:System.Speech.Synthesis.SpeechSynthesizer.State" />
        <altmember cref="E:System.Speech.Synthesis.SpeechSynthesizer.StateChanged" />
      </Docs>
    </Member>
    <Member MemberName="PhonemeReached">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Synthesis.PhonemeReachedEventArgs&gt; PhonemeReached;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Synthesis.PhonemeReachedEventArgs&gt; PhonemeReached" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Synthesis.SpeechSynthesizer.PhonemeReached" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event PhonemeReached As EventHandler(Of PhonemeReachedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Synthesis::PhonemeReachedEventArgs ^&gt; ^ PhonemeReached;" />
      <MemberSignature Language="F#" Value="member this.PhonemeReached : EventHandler&lt;System.Speech.Synthesis.PhonemeReachedEventArgs&gt; " Usage="member this.PhonemeReached : System.EventHandler&lt;System.Speech.Synthesis.PhonemeReachedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Synthesis.PhonemeReachedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Wird ausgelöst, wenn ein Phonem erreicht wird.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Ein Phonem beendet ist eine grundlegende Komponente des geschriebenen Sprache, in der Regel auf einen Buchstaben ein Buchstabe (oder die Kombination aus zwei Buchstaben), der einen oder mehrere unterschiedliche Sounds darstellt. Der Buchstabe "c" ist beispielsweise ein Phonem beendet, die wie "s" in "Cinder" oder wie "k" in "Catch" klingen mag. Eine geschriebene Wort ist eine Gruppe von phonemen basiert. Ein Phonem in word ändern, wird dessen Rechtschreibung geändert werden.  
  
 Ein <xref:System.Speech.Synthesis.SpeechSynthesizer> Instanz generiert einen <xref:System.Speech.Synthesis.SpeechSynthesizer.PhonemeReached> Ereignis für jeden Teil ein Wort, das ein Phonem bildet. Z. B. für das Wort "Design" erzeugt drei <xref:System.Speech.Synthesis.SpeechSynthesizer.PhonemeReached> Ereignisse: eine für den Sound "th", für den Sound "e" und eine für das "m" Sound (me).  
  
 Ein Beispiel und Informationen zu Daten, die dem Ereignis zugeordnet wird, finden Sie unter <xref:System.Speech.Synthesis.PhonemeReachedEventArgs>.  
  
 ]]></format>
        </remarks>
        <altmember cref="" />
      </Docs>
    </Member>
    <Member MemberName="Rate">
      <MemberSignature Language="C#" Value="public int Rate { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance int32 Rate" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Synthesis.SpeechSynthesizer.Rate" />
      <MemberSignature Language="VB.NET" Value="Public Property Rate As Integer" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property int Rate { int get(); void set(int value); };" />
      <MemberSignature Language="F#" Value="member this.Rate : int with get, set" Usage="System.Speech.Synthesis.SpeechSynthesizer.Rate" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Int32</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Ruft die Sprechrate des <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" />-Objekts ab oder legt sie fest.</summary>
        <value>Gibt die Sprechrate des <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" />- Objekts von -10 bis 10 zurück.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Examples  
 Im folgende Beispiel spricht eine Zeichenfolge mit die sprechrate-2 festgelegt.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      SpeechSynthesizer synth = new SpeechSynthesizer();  
  
      // Set a value for the speaking rate.  
      synth.Rate = -2;  
  
      // Configure the audio output.   
      synth.SetOutputToDefaultAudioDevice();  
  
      // Speak a text string synchronously.  
      synth.Speak("This example speaks a string with the speaking rate set to -2.");  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }     
  }    
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Synthesis.PromptStyle" />
        <altmember cref="T:System.Speech.Synthesis.PromptRate" />
      </Docs>
    </Member>
    <Member MemberName="RemoveLexicon">
      <MemberSignature Language="C#" Value="public void RemoveLexicon (Uri uri);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void RemoveLexicon(class System.Uri uri) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.RemoveLexicon(System.Uri)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void RemoveLexicon(Uri ^ uri);" />
      <MemberSignature Language="F#" Value="member this.RemoveLexicon : Uri -&gt; unit" Usage="speechSynthesizer.RemoveLexicon uri" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="uri" Type="System.Uri" />
      </Parameters>
      <Docs>
        <param name="uri">Der Speicherort des Lexikondokuments.</param>
        <summary>Entfernt ein Lexikon aus dem <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" />-Objekt.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Ein Beispiel finden Sie unter <xref:System.Speech.Synthesis.SpeechSynthesizer.AddLexicon%2A>.  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Synthesis.SpeechSynthesizer.AddLexicon(System.Uri,System.String)" />
      </Docs>
    </Member>
    <Member MemberName="Resume">
      <MemberSignature Language="C#" Value="public void Resume ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void Resume() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.Resume" />
      <MemberSignature Language="VB.NET" Value="Public Sub Resume ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void Resume();" />
      <MemberSignature Language="F#" Value="member this.Resume : unit -&gt; unit" Usage="speechSynthesizer.Resume " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Setzt das <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" />-Objekt fort, nachdem es angehalten wurde.</summary>
        <remarks>To be added.</remarks>
        <altmember cref="M:System.Speech.Synthesis.SpeechSynthesizer.Pause" />
        <altmember cref="P:System.Speech.Synthesis.SpeechSynthesizer.State" />
        <altmember cref="E:System.Speech.Synthesis.SpeechSynthesizer.StateChanged" />
      </Docs>
    </Member>
    <Member MemberName="SelectVoice">
      <MemberSignature Language="C#" Value="public void SelectVoice (string name);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void SelectVoice(string name) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.SelectVoice(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub SelectVoice (name As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void SelectVoice(System::String ^ name);" />
      <MemberSignature Language="F#" Value="member this.SelectVoice : string -&gt; unit" Usage="speechSynthesizer.SelectVoice name" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="name" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="name">Der Name der Stimme, die ausgewählt werden soll.</param>
        <summary>Wählt eine bestimmte Stimme nach Namen aus.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Verwenden der <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> Methode und <xref:System.Speech.Synthesis.VoiceInfo> Klasse die Namen der abzurufenden installiert Speech (TTS) stimmen zurück, die Sie auswählen können. Um eine Stimme auszuwählen, übergeben Sie den gesamten Inhalt der <xref:System.Speech.Synthesis.VoiceInfo.Name%2A> Eigenschaft als Argument für die <xref:System.Speech.Synthesis.SpeechSynthesizer.SelectVoice%2A> Methode. Die <xref:System.Speech.Synthesis.SpeechSynthesizer> -Objekt wählt die erste installierte Stimme für die enthält `name` in der Stimme des <xref:System.Speech.Synthesis.VoiceInfo.Name%2A?displayProperty=nameWithType> Eigenschaft. Die <xref:System.Speech.Synthesis.SpeechSynthesizer> führt einen Groß-/Kleinschreibung beachtet, Teilzeichenfolge-Vergleich, um festzustellen, ob die Sprache entspricht den `name`.  
  
 Wenn eine Anwendung ruft <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A>, die Methode überprüft, ob jeder der stimmen zurück, es in der Registrierung findet, bestimmte Mindestkriterien erfüllt. Für alle Stimme an, die Überprüfung schlägt fehl, <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> legt die <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> Eigenschaft, um `False`. Eine Anwendung eine Stimme kann nicht ausgewählt werden, deren <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> Eigenschaft `False`. Anwendungen werden in der Regel nicht Festlegen der Sprachnotizen <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> Eigenschaft.  
  
 Um eine Stimme von Geschlecht, Alter und Gebietsschema auszuwählen, verwenden Sie eines der <xref:System.Speech.Synthesis.SpeechSynthesizer.SelectVoiceByHints%2A> Methoden.  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices" />
        <altmember cref="M:System.Speech.Synthesis.SpeechSynthesizer.SelectVoiceByHints(System.Speech.Synthesis.VoiceGender)" />
      </Docs>
    </Member>
    <MemberGroup MemberName="SelectVoiceByHints">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Wählt eine Stimme mit bestimmten Eigenschaften aus.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Verwenden der <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> Methode und <xref:System.Speech.Synthesis.VoiceInfo> Klasse die Namen der abzurufenden installiert Speech (TTS) stimmen zurück, die Sie auswählen können. Die <xref:System.Speech.Synthesis.SpeechSynthesizer> -Objekt wählt die erste installierte Stimme, die die angegebenen Merkmalen entspricht.  
  
 Wenn eine Anwendung ruft <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A>, die Methode überprüft, ob jeder der stimmen zurück, es in der Registrierung findet, bestimmte Mindestkriterien erfüllt. Für alle Stimme an, die Überprüfung schlägt fehl, <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> legt die <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> Eigenschaft, um `False`. Eine Anwendung eine Stimme kann nicht ausgewählt werden, deren <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> Eigenschaft `False`. Anwendungen werden in der Regel nicht Festlegen der Sprachnotizen <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> Eigenschaft.  
  
 Um eine Stimme nach Namen auszuwählen, verwenden die <xref:System.Speech.Synthesis.SpeechSynthesizer.SelectVoice%2A> Methode  
  
 ]]></format>
        </remarks>
      </Docs>
    </MemberGroup>
    <Member MemberName="SelectVoiceByHints">
      <MemberSignature Language="C#" Value="public void SelectVoiceByHints (System.Speech.Synthesis.VoiceGender gender);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void SelectVoiceByHints(valuetype System.Speech.Synthesis.VoiceGender gender) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.SelectVoiceByHints(System.Speech.Synthesis.VoiceGender)" />
      <MemberSignature Language="VB.NET" Value="Public Sub SelectVoiceByHints (gender As VoiceGender)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void SelectVoiceByHints(System::Speech::Synthesis::VoiceGender gender);" />
      <MemberSignature Language="F#" Value="member this.SelectVoiceByHints : System.Speech.Synthesis.VoiceGender -&gt; unit" Usage="speechSynthesizer.SelectVoiceByHints gender" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="gender" Type="System.Speech.Synthesis.VoiceGender" />
      </Parameters>
      <Docs>
        <param name="gender">Das auszuwählende Geschlecht der Stimme.</param>
        <summary>Wählt eine Stimme mit einem bestimmten Geschlecht aus.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Verwenden der <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> Methode und <xref:System.Speech.Synthesis.VoiceInfo> Klasse die Namen der abzurufenden installiert Speech (TTS) stimmen zurück, die Sie auswählen können. Die <xref:System.Speech.Synthesis.SpeechSynthesizer> -Objekt wählt die erste installierte Stimme, deren <xref:System.Speech.Synthesis.VoiceInfo.Gender%2A> Eigenschaft entspricht der `gender` Parameter.  
  
 Wenn eine Anwendung ruft <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A>, die Methode überprüft, ob jeder der stimmen zurück, es in der Registrierung findet, bestimmte Mindestkriterien erfüllt. Für alle Stimme an, die Überprüfung schlägt fehl, <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> legt die <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> Eigenschaft, um `False`. Eine Anwendung eine Stimme kann nicht ausgewählt werden, deren <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> Eigenschaft `False`. Anwendungen werden in der Regel nicht Festlegen der Sprachnotizen <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> Eigenschaft.  
  
 Um eine Stimme, die basierend auf anderen Merkmalen auswählen zu können, finden Sie unter den anderen <xref:System.Speech.Synthesis.SpeechSynthesizer.SelectVoiceByHints%2A> Methoden.  
  
 Um eine Stimme nach Namen auszuwählen, verwenden die <xref:System.Speech.Synthesis.SpeechSynthesizer.SelectVoice%2A> Methode.  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Synthesis.VoiceGender" />
        <altmember cref="T:System.Speech.Synthesis.VoiceInfo" />
        <altmember cref="M:System.Speech.Synthesis.SpeechSynthesizer.SelectVoice(System.String)" />
      </Docs>
    </Member>
    <Member MemberName="SelectVoiceByHints">
      <MemberSignature Language="C#" Value="public void SelectVoiceByHints (System.Speech.Synthesis.VoiceGender gender, System.Speech.Synthesis.VoiceAge age);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void SelectVoiceByHints(valuetype System.Speech.Synthesis.VoiceGender gender, valuetype System.Speech.Synthesis.VoiceAge age) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.SelectVoiceByHints(System.Speech.Synthesis.VoiceGender,System.Speech.Synthesis.VoiceAge)" />
      <MemberSignature Language="VB.NET" Value="Public Sub SelectVoiceByHints (gender As VoiceGender, age As VoiceAge)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void SelectVoiceByHints(System::Speech::Synthesis::VoiceGender gender, System::Speech::Synthesis::VoiceAge age);" />
      <MemberSignature Language="F#" Value="member this.SelectVoiceByHints : System.Speech.Synthesis.VoiceGender * System.Speech.Synthesis.VoiceAge -&gt; unit" Usage="speechSynthesizer.SelectVoiceByHints (gender, age)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="gender" Type="System.Speech.Synthesis.VoiceGender" />
        <Parameter Name="age" Type="System.Speech.Synthesis.VoiceAge" />
      </Parameters>
      <Docs>
        <param name="gender">Das auszuwählende Geschlecht der Stimme.</param>
        <param name="age">Das Alter der auszuwählenden Stimme.</param>
        <summary>Wählt eine Stimme mit einem bestimmten Geschlecht und einem Alter aus.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Verwenden der <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> Methode und <xref:System.Speech.Synthesis.VoiceInfo> Klasse die Namen der abzurufenden installiert Speech (TTS) stimmen zurück, die Sie auswählen können. Die <xref:System.Speech.Synthesis.SpeechSynthesizer> -Objekt wählt die erste installierte Stimme, deren <xref:System.Speech.Synthesis.VoiceInfo.Gender%2A> und <xref:System.Speech.Synthesis.VoiceInfo.Age%2A> Eigenschaften Übereinstimmung der `gender` und `age` Parameter.  
  
 Wenn eine Anwendung ruft <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A>, die Methode überprüft, ob jeder der stimmen zurück, es in der Registrierung findet, bestimmte Mindestkriterien erfüllt. Für alle Stimme an, die Überprüfung schlägt fehl, <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> legt die <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> Eigenschaft, um `False`. Eine Anwendung eine Stimme kann nicht ausgewählt werden, deren <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> Eigenschaft `False`. Anwendungen werden in der Regel nicht Festlegen der Sprachnotizen <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> Eigenschaft.  
  
 Um eine Stimme, die basierend auf anderen Merkmalen auswählen zu können, finden Sie unter den anderen <xref:System.Speech.Synthesis.SpeechSynthesizer.SelectVoiceByHints%2A> Methoden.  
  
 Um eine Stimme nach Namen auszuwählen, verwenden die <xref:System.Speech.Synthesis.SpeechSynthesizer.SelectVoice%2A> Methode.  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Synthesis.VoiceAge" />
        <altmember cref="T:System.Speech.Synthesis.VoiceGender" />
        <altmember cref="T:System.Speech.Synthesis.VoiceInfo" />
        <altmember cref="M:System.Speech.Synthesis.SpeechSynthesizer.SelectVoice(System.String)" />
      </Docs>
    </Member>
    <Member MemberName="SelectVoiceByHints">
      <MemberSignature Language="C#" Value="public void SelectVoiceByHints (System.Speech.Synthesis.VoiceGender gender, System.Speech.Synthesis.VoiceAge age, int voiceAlternate);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void SelectVoiceByHints(valuetype System.Speech.Synthesis.VoiceGender gender, valuetype System.Speech.Synthesis.VoiceAge age, int32 voiceAlternate) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.SelectVoiceByHints(System.Speech.Synthesis.VoiceGender,System.Speech.Synthesis.VoiceAge,System.Int32)" />
      <MemberSignature Language="VB.NET" Value="Public Sub SelectVoiceByHints (gender As VoiceGender, age As VoiceAge, voiceAlternate As Integer)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void SelectVoiceByHints(System::Speech::Synthesis::VoiceGender gender, System::Speech::Synthesis::VoiceAge age, int voiceAlternate);" />
      <MemberSignature Language="F#" Value="member this.SelectVoiceByHints : System.Speech.Synthesis.VoiceGender * System.Speech.Synthesis.VoiceAge * int -&gt; unit" Usage="speechSynthesizer.SelectVoiceByHints (gender, age, voiceAlternate)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="gender" Type="System.Speech.Synthesis.VoiceGender" />
        <Parameter Name="age" Type="System.Speech.Synthesis.VoiceAge" />
        <Parameter Name="voiceAlternate" Type="System.Int32" />
      </Parameters>
      <Docs>
        <param name="gender">Das auszuwählende Geschlecht der Stimme.</param>
        <param name="age">Das Alter der auszuwählenden Stimme.</param>
        <param name="voiceAlternate">Die Position der auszuwählenden Stimme.</param>
        <summary>Wählt eine Stimme mit einem bestimmten Geschlecht und einem Alter auf Grundlage der Position aus, in der die Stimmen sortiert sind.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Verwenden der <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> Methode und <xref:System.Speech.Synthesis.VoiceInfo> Klasse die Namen der abzurufenden installiert Speech (TTS) stimmen zurück, die Sie auswählen können. Die <xref:System.Speech.Synthesis.SpeechSynthesizer> Objekt findet, installiert stimmen, deren <xref:System.Speech.Synthesis.VoiceInfo.Gender%2A> und <xref:System.Speech.Synthesis.VoiceInfo.Age%2A> Eigenschaften Übereinstimmung der `gender` und `age` Parameter. Die <xref:System.Speech.Synthesis.SpeechSynthesizer> zählt die Übereinstimmungen, wird erkannt und die Stimme zurückgegeben wird, wenn die Anzahl, der `voiceAlternate` Parameter.  
  
 Wenn eine Anwendung ruft <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A>, die Methode überprüft, ob jeder der stimmen zurück, es in der Registrierung findet, bestimmte Mindestkriterien erfüllt. Für alle Stimme an, die Überprüfung schlägt fehl, <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> legt die <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> Eigenschaft, um `False`. Eine Anwendung eine Stimme kann nicht ausgewählt werden, deren <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> Eigenschaft `False`. Anwendungen werden in der Regel nicht Festlegen der Sprachnotizen <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> Eigenschaft.  
  
 Um eine Stimme, die basierend auf anderen Merkmalen auswählen zu können, finden Sie unter den anderen <xref:System.Speech.Synthesis.SpeechSynthesizer.SelectVoiceByHints%2A> Überladungen.  
  
 Um eine Stimme nach Namen auszuwählen, verwenden die <xref:System.Speech.Synthesis.SpeechSynthesizer.SelectVoice%2A> Methode.  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Synthesis.VoiceAge" />
        <altmember cref="T:System.Speech.Synthesis.VoiceGender" />
        <altmember cref="T:System.Speech.Synthesis.VoiceInfo" />
        <altmember cref="M:System.Speech.Synthesis.SpeechSynthesizer.SelectVoice(System.String)" />
      </Docs>
    </Member>
    <Member MemberName="SelectVoiceByHints">
      <MemberSignature Language="C#" Value="public void SelectVoiceByHints (System.Speech.Synthesis.VoiceGender gender, System.Speech.Synthesis.VoiceAge age, int voiceAlternate, System.Globalization.CultureInfo culture);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void SelectVoiceByHints(valuetype System.Speech.Synthesis.VoiceGender gender, valuetype System.Speech.Synthesis.VoiceAge age, int32 voiceAlternate, class System.Globalization.CultureInfo culture) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.SelectVoiceByHints(System.Speech.Synthesis.VoiceGender,System.Speech.Synthesis.VoiceAge,System.Int32,System.Globalization.CultureInfo)" />
      <MemberSignature Language="VB.NET" Value="Public Sub SelectVoiceByHints (gender As VoiceGender, age As VoiceAge, voiceAlternate As Integer, culture As CultureInfo)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void SelectVoiceByHints(System::Speech::Synthesis::VoiceGender gender, System::Speech::Synthesis::VoiceAge age, int voiceAlternate, System::Globalization::CultureInfo ^ culture);" />
      <MemberSignature Language="F#" Value="member this.SelectVoiceByHints : System.Speech.Synthesis.VoiceGender * System.Speech.Synthesis.VoiceAge * int * System.Globalization.CultureInfo -&gt; unit" Usage="speechSynthesizer.SelectVoiceByHints (gender, age, voiceAlternate, culture)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="gender" Type="System.Speech.Synthesis.VoiceGender" />
        <Parameter Name="age" Type="System.Speech.Synthesis.VoiceAge" />
        <Parameter Name="voiceAlternate" Type="System.Int32" />
        <Parameter Name="culture" Type="System.Globalization.CultureInfo" />
      </Parameters>
      <Docs>
        <param name="gender">Das auszuwählende Geschlecht der Stimme.</param>
        <param name="age">Das Alter der auszuwählenden Stimme.</param>
        <param name="voiceAlternate">Die Position der auszuwählenden Stimme.</param>
        <param name="culture">Das auszuwählende Gebietsschema der Sprache.</param>
        <summary>Wählt eine Stimme mit einem bestimmten Geschlecht, Alter und Gebietsschema auf Grundlage der Position aus, in der die Stimmen sortiert sind.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Die <xref:System.Speech.Synthesis.SpeechSynthesizer> Objekt sucht stimmen, deren <xref:System.Speech.Synthesis.VoiceInfo.Gender%2A>, <xref:System.Speech.Synthesis.VoiceInfo.Age%2A>, und <xref:System.Speech.Synthesis.VoiceInfo.Culture%2A> Eigenschaften Übereinstimmung der `gender`, `age`, und `culture` Parameter. Die <xref:System.Speech.Synthesis.SpeechSynthesizer> zählt die Übereinstimmungen, wird erkannt und die Stimme zurückgegeben wird, wenn die Anzahl, der `voiceAlternate` Parameter.  
  
 Microsoft Windows und die "System.Speech"-API akzeptiert alle gültige Sprache / Land-Codes. Sprachsynthese mit der Sprache, die im angegebenen Ausführen der `culture` -Parameter, die einer sprachesynthese-Engine, die unterstützt werden, dass Sprache / Land-Code installiert werden muss. Der sprachesynthese-Engines, die mit den im Lieferumfang von Microsoft Windows 7 arbeiten Sie mit der folgenden Sprache / Land-Codes:  
  
-   En-US. Englisch (USA)  
  
-   zh-CN. Chinesisch (China)  
  
-   zh-TW. Chinesisch (Taiwan)  
  
 Zwei Buchstaben bestehenden Sprachcodes, z. B. "En" sind ebenfalls zulässig.  
  
 Wenn eine Anwendung ruft <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A>, die Methode überprüft, ob jeder der stimmen zurück, es in der Registrierung findet, bestimmte Mindestkriterien erfüllt. Für alle Stimme an, die Überprüfung schlägt fehl, <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> legt die <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> Eigenschaft, um `False`. Eine Anwendung eine Stimme kann nicht ausgewählt werden, deren <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> Eigenschaft `False`. Anwendungen werden in der Regel nicht Festlegen der Sprachnotizen <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> Eigenschaft.  
  
 Um eine Stimme, die basierend auf anderen Merkmalen auswählen zu können, finden Sie unter den anderen <xref:System.Speech.Synthesis.SpeechSynthesizer.SelectVoiceByHints%2A> Überladungen.  
  
 Um eine Stimme nach Namen auszuwählen, verwenden die <xref:System.Speech.Synthesis.SpeechSynthesizer.SelectVoice%2A> Methode.  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Globalization.CultureInfo" />
        <altmember cref="T:System.Speech.Synthesis.VoiceAge" />
        <altmember cref="T:System.Speech.Synthesis.VoiceGender" />
        <altmember cref="T:System.Speech.Synthesis.VoiceInfo" />
        <altmember cref="M:System.Speech.Synthesis.SpeechSynthesizer.SelectVoice(System.String)" />
      </Docs>
    </Member>
    <Member MemberName="SetOutputToAudioStream">
      <MemberSignature Language="C#" Value="public void SetOutputToAudioStream (System.IO.Stream audioDestination, System.Speech.AudioFormat.SpeechAudioFormatInfo formatInfo);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void SetOutputToAudioStream(class System.IO.Stream audioDestination, class System.Speech.AudioFormat.SpeechAudioFormatInfo formatInfo) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToAudioStream(System.IO.Stream,System.Speech.AudioFormat.SpeechAudioFormatInfo)" />
      <MemberSignature Language="VB.NET" Value="Public Sub SetOutputToAudioStream (audioDestination As Stream, formatInfo As SpeechAudioFormatInfo)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void SetOutputToAudioStream(System::IO::Stream ^ audioDestination, System::Speech::AudioFormat::SpeechAudioFormatInfo ^ formatInfo);" />
      <MemberSignature Language="F#" Value="member this.SetOutputToAudioStream : System.IO.Stream * System.Speech.AudioFormat.SpeechAudioFormatInfo -&gt; unit" Usage="speechSynthesizer.SetOutputToAudioStream (audioDestination, formatInfo)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="audioDestination" Type="System.IO.Stream" />
        <Parameter Name="formatInfo" Type="System.Speech.AudioFormat.SpeechAudioFormatInfo" />
      </Parameters>
      <Docs>
        <param name="audioDestination">Der Stream, an den Syntheseausgabe angefügt werden soll.</param>
        <param name="formatInfo">Das Format, das für die Syntheseausgabe verwendet werden soll.</param>
        <summary>Konfiguriert das <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" />-Objekt, um die Ausgabe an einem Audiostream anzufügen.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Rufen Sie <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToNull%2A> Freigeben der <xref:System.Speech.Synthesis.SpeechSynthesizer>der Verweis auf den Stream.  
  
 Andere Konfigurationsoptionen für die Ausgabe, finden Sie unter den <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToDefaultAudioDevice%2A>, <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToNull%2A>, <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToWaveFile%2A>, und <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToWaveStream%2A> Methoden.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="SetOutputToDefaultAudioDevice">
      <MemberSignature Language="C#" Value="public void SetOutputToDefaultAudioDevice ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void SetOutputToDefaultAudioDevice() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToDefaultAudioDevice" />
      <MemberSignature Language="VB.NET" Value="Public Sub SetOutputToDefaultAudioDevice ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void SetOutputToDefaultAudioDevice();" />
      <MemberSignature Language="F#" Value="member this.SetOutputToDefaultAudioDevice : unit -&gt; unit" Usage="speechSynthesizer.SetOutputToDefaultAudioDevice " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Konfiguriert das <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" />-Objekt, um die Ausgabe zum Audiogerät zu senden.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Können Sie die **Sound** Fenster in der Windows **Systemsteuerung** das Standardaudiogerät für den Computer zu konfigurieren.  
  
 Andere Konfigurationsoptionen für die Ausgabe, finden Sie unter den <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToAudioStream%2A>, <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToNull%2A>, <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToWaveFile%2A>, und <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToWaveStream%2A> Methoden.  
  
   
  
## Examples  
 Im folgenden Beispiel wird den Synthesizer, um einen Ausdruck, der den Standard-Audioausgabe zu sprechen.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the speech synthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the synthesizer to send output to the default audio device.  
        synth.SetOutputToDefaultAudioDevice();  
  
        // Speak a phrase.  
        synth.Speak("This is sample text-to-speech output.");  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="SetOutputToNull">
      <MemberSignature Language="C#" Value="public void SetOutputToNull ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void SetOutputToNull() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToNull" />
      <MemberSignature Language="VB.NET" Value="Public Sub SetOutputToNull ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void SetOutputToNull();" />
      <MemberSignature Language="F#" Value="member this.SetOutputToNull : unit -&gt; unit" Usage="speechSynthesizer.SetOutputToNull " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Konfiguriert das <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" />-Objekt, um keine Ausgabe aus Synthesevorgängen an ein Gerät, eine Datei oder einen Stream zu senden.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Mit dieser Methode können Sie die Version der <xref:System.Speech.Synthesis.SpeechSynthesizer>der Verweis auf eine Datei oder den Stream. Ein Beispiel finden Sie unter <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToWaveStream%2A>.  
  
 Andere Konfigurationsoptionen für die Ausgabe, finden Sie unter den <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToAudioStream%2A>, <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToDefaultAudioDevice%2A>, <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToWaveFile%2A>, und <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToWaveStream%2A> Methoden.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <MemberGroup MemberName="SetOutputToWaveFile">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Konfiguriert das <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" />-Objekt, um die Ausgabe an eine Datei im Waveform Audioformat anzufügen.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Freigeben der <xref:System.Speech.Synthesis.SpeechSynthesizer>den Verweisdaten in der Datei, neu konfigurieren die <xref:System.Speech.Synthesis.SpeechSynthesizer>die Ausgabe, z. B. durch Aufrufen von <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToNull%2A>.  
  
 Andere Konfigurationsoptionen für die Ausgabe, finden Sie unter den <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToAudioStream%2A>, <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToDefaultAudioDevice%2A>, <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToNull%2A>, und <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToWaveStream%2A> Methoden.  
  
 ]]></format>
        </remarks>
      </Docs>
    </MemberGroup>
    <Member MemberName="SetOutputToWaveFile">
      <MemberSignature Language="C#" Value="public void SetOutputToWaveFile (string path);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void SetOutputToWaveFile(string path) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToWaveFile(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub SetOutputToWaveFile (path As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void SetOutputToWaveFile(System::String ^ path);" />
      <MemberSignature Language="F#" Value="member this.SetOutputToWaveFile : string -&gt; unit" Usage="speechSynthesizer.SetOutputToWaveFile path" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="path" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="path">Der Pfad zur Datei.</param>
        <summary>Konfiguriert das <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" />-Objekt, um die Ausgabe an eine Datei anzufügen, die Audio im Waveform Format enthält.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Verwenden Sie zum Konfigurieren von der Ausgabe aus, und geben Sie das audio-Format, das <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToWaveFile%2A> Methode.  
  
   
  
## Examples  
 Im folgende Beispiel wird eine Instanz der <xref:System.Media.SoundPlayer> eine Eingabeaufforderung zu spielen, die an eine WAV-Datei ausgegeben wurde. Da die <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync%2A> Aufruf asynchron ist, ist die <xref:System.Media.SoundPlayer> Instanz erstellt wird (und die <xref:System.Media.SoundPlayer.Play%2A> aufgerufene Methode) in den Handler für die <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakCompleted> Ereignis.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      SpeechSynthesizer synth = new SpeechSynthesizer();  
  
      // Configure the audio output.   
      synth.SetOutputToWaveFile(@"C:\Test\Sample.wav");  
  
      // Register for the SpeakCompleted event.  
      synth.SpeakCompleted += new EventHandler<SpeakCompletedEventArgs>(synth_SpeakCompleted);  
  
      // Build a prompt.  
      PromptBuilder builder = new PromptBuilder();  
      builder.AppendText("This sample asynchronously speaks a prompt to a WAVE file.");  
  
      // Speak the string asynchronously.  
      synth.SpeakAsync(builder);  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the SpeakCompleted event.  
    static void synth_SpeakCompleted(object sender, SpeakCompletedEventArgs e)  
    {  
  
      // Create a SoundPlayer instance to play the output audio file.  
      System.Media.SoundPlayer m_SoundPlayer =  
        new System.Media.SoundPlayer(@"C:\Test\Sample.wav");  
  
      //  Play the output file.  
      m_SoundPlayer.Play();  
    }  
  }  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToAudioStream(System.IO.Stream,System.Speech.AudioFormat.SpeechAudioFormatInfo)" />
        <altmember cref="M:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToDefaultAudioDevice" />
        <altmember cref="M:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToNull" />
        <altmember cref="M:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToWaveStream(System.IO.Stream)" />
      </Docs>
    </Member>
    <Member MemberName="SetOutputToWaveFile">
      <MemberSignature Language="C#" Value="public void SetOutputToWaveFile (string path, System.Speech.AudioFormat.SpeechAudioFormatInfo formatInfo);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void SetOutputToWaveFile(string path, class System.Speech.AudioFormat.SpeechAudioFormatInfo formatInfo) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToWaveFile(System.String,System.Speech.AudioFormat.SpeechAudioFormatInfo)" />
      <MemberSignature Language="VB.NET" Value="Public Sub SetOutputToWaveFile (path As String, formatInfo As SpeechAudioFormatInfo)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void SetOutputToWaveFile(System::String ^ path, System::Speech::AudioFormat::SpeechAudioFormatInfo ^ formatInfo);" />
      <MemberSignature Language="F#" Value="member this.SetOutputToWaveFile : string * System.Speech.AudioFormat.SpeechAudioFormatInfo -&gt; unit" Usage="speechSynthesizer.SetOutputToWaveFile (path, formatInfo)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="path" Type="System.String" />
        <Parameter Name="formatInfo" Type="System.Speech.AudioFormat.SpeechAudioFormatInfo" />
      </Parameters>
      <Docs>
        <param name="path">Der Pfad zur Datei.</param>
        <param name="formatInfo">Die Audioformat-Informationen.</param>
        <summary>Konfiguriert das <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" />-Objekt, um die Ausgabe zu einer Datei im Waveform-Audioformat in einem angegebenen Format anzufügen.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Examples  
 Das folgende Beispiel gibt das Format der Ausgabe der Sprachsynthese und sendet sie an eine WAV-Datei.  
  
```csharp  
using System;  
using System.IO;  
using System.Speech.Synthesis;  
using System.Speech.AudioFormat;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToWaveFile(@"C:\temp\test.wav",   
          new SpeechAudioFormatInfo(32000, AudioBitsPerSample.Sixteen, AudioChannel.Mono));  
  
        // Create a SoundPlayer instance to play output audio file.  
        System.Media.SoundPlayer m_SoundPlayer =   
          new System.Media.SoundPlayer(@"C:\temp\test.wav");  
  
        // Build a prompt.  
        PromptBuilder builder = new PromptBuilder();  
        builder.AppendText("This is sample output to a WAVE file.");  
  
        // Speak the prompt.  
        synth.Speak(builder);  
        m_SoundPlayer.Play();  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToAudioStream(System.IO.Stream,System.Speech.AudioFormat.SpeechAudioFormatInfo)" />
        <altmember cref="M:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToDefaultAudioDevice" />
        <altmember cref="M:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToNull" />
        <altmember cref="M:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToWaveStream(System.IO.Stream)" />
      </Docs>
    </Member>
    <Member MemberName="SetOutputToWaveStream">
      <MemberSignature Language="C#" Value="public void SetOutputToWaveStream (System.IO.Stream audioDestination);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void SetOutputToWaveStream(class System.IO.Stream audioDestination) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToWaveStream(System.IO.Stream)" />
      <MemberSignature Language="VB.NET" Value="Public Sub SetOutputToWaveStream (audioDestination As Stream)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void SetOutputToWaveStream(System::IO::Stream ^ audioDestination);" />
      <MemberSignature Language="F#" Value="member this.SetOutputToWaveStream : System.IO.Stream -&gt; unit" Usage="speechSynthesizer.SetOutputToWaveStream audioDestination" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="audioDestination" Type="System.IO.Stream" />
      </Parameters>
      <Docs>
        <param name="audioDestination">Der Stream, an den Syntheseausgabe angefügt werden soll.</param>
        <summary>Konfiguriert das <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" />-Objekt, um die Ausgabe an einen Stream anzufügen, die Audio im Waveform Format enthält.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Freigeben der <xref:System.Speech.Synthesis.SpeechSynthesizer>dem Verweis in den Stream, Reconfigure Synthesizers die Ausgabe, z. B. durch Aufrufen von <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToNull%2A>.  
  
 Andere Konfigurationsoptionen für die Ausgabe, finden Sie unter den <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToAudioStream%2A>, <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToDefaultAudioDevice%2A>, <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToNull%2A>, und <xref:System.Speech.Synthesis.SpeechSynthesizer.SetOutputToWaveFile%2A> Methoden.  
  
   
  
## Examples  
 Das folgende Beispiel gibt einen Ausdruck, der eine WAV-Stream.  
  
```csharp  
using System;  
using System.IO;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the speech synthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      using (MemoryStream streamAudio = new MemoryStream())  
      {  
  
        // Create a SoundPlayer instance to play the output audio file.  
        System.Media.SoundPlayer m_SoundPlayer = new System.Media.SoundPlayer();  
  
        // Configure the synthesizer to output to an audio stream.  
        synth.SetOutputToWaveStream(streamAudio);  
  
        // Speak a phrase.  
        synth.Speak("This is sample text-to-speech output.");  
        streamAudio.Position = 0;  
        m_SoundPlayer.Stream = streamAudio;  
        m_SoundPlayer.Play();  
  
        // Set the synthesizer output to null to release the stream.   
        synth.SetOutputToNull();  
  
        // Insert code to persist or process the stream contents here.  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <MemberGroup MemberName="Speak">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Generiert eine zur Zeichenfolge synchrone Sprachausgabe, ein <see cref="T:System.Speech.Synthesis.Prompt" />-Objekt oder ein <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Die <xref:System.Speech.Synthesis.SpeechSynthesizer.Speak%2A> Methoden generieren Spracherkennung synchron. Die Methoden geben keine zurück, bis der Inhalt von der <xref:System.Speech.Synthesis.SpeechSynthesizer.Speak%2A> Instanz vollständig gesprochen wurde. Dies ist die einfachste Möglichkeit zum Generieren der Sprache. Wenn jedoch Ihre Anwendung muss während des Sprechens Aufgaben, z. B. hervorhebungstext, Paint-Animation, Monitor-Steuerelemente oder andere Aufgaben verwenden die <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync%2A> Methoden oder <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsmlAsync%2A> Methode zum Generieren einer Sprachausgabe asynchron.  
  
 Während eines Aufrufs dieser Methode die <xref:System.Speech.Synthesis.SpeechSynthesizer> können die folgenden Ereignisse auslösen:  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.StateChanged>. Wird ausgelöst, wenn es sich bei der sprechzustand des Synthesizers ändert.  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakStarted>. Wird ausgelöst, wenn der Synthesizer beginnt, Generieren von Sprache.  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.PhonemeReached>. Jedes Mal ausgelöst, die der Synthesizer erreicht, einem Buchstaben oder einer Kombination aus Buchstaben, die diskret Sound von Sprache in einer anderen Sprache zu bilden.  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakProgress>. Jedes Mal ausgelöst, schließt der Synthesizer ein Wort zu sprechen.  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.VisemeReached>. Jedes Mal ausgelöst, gesprochenen Ausgabe eine Änderung der Position der Mund oder die gesichtserkennung gleiche verwendet, um die Spracherkennung zu erstellen erfordert.  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.BookmarkReached>. Wird ausgelöst, wenn es sich bei der Synthesizer ein Lesezeichen an einer Eingabeaufforderung feststellt.  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.VoiceChange>. Ausgelöst, wenn die Stimme für den Synthesizer ändert.  
  
 Die <xref:System.Speech.Synthesis.SpeechSynthesizer> löst nicht die <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakCompleted> Ereignis während der Verarbeitung eines der <xref:System.Speech.Synthesis.SpeechSynthesizer.Speak%2A> Methoden.  
  
 ]]></format>
        </remarks>
      </Docs>
    </MemberGroup>
    <Member MemberName="Speak">
      <MemberSignature Language="C#" Value="public void Speak (System.Speech.Synthesis.Prompt prompt);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void Speak(class System.Speech.Synthesis.Prompt prompt) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.Speak(System.Speech.Synthesis.Prompt)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void Speak(System::Speech::Synthesis::Prompt ^ prompt);" />
      <MemberSignature Language="F#" Value="member this.Speak : System.Speech.Synthesis.Prompt -&gt; unit" Usage="speechSynthesizer.Speak prompt" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="prompt" Type="System.Speech.Synthesis.Prompt" />
      </Parameters>
      <Docs>
        <param name="prompt">Der zu sprechende Inhalt.</param>
        <summary>Spricht synchron den Inhalt eines <see cref="T:System.Speech.Synthesis.Prompt" />-Objekts.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Um den Inhalt des asynchron zu sprechen ein <xref:System.Speech.Synthesis.Prompt> -Objekts <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync%2A>.  
  
   
  
## Examples  
 Das folgende Beispiel erstellt eine <xref:System.Speech.Synthesis.Prompt> Objekt aus einer Zeichenfolge und übergibt das Objekt als Argument an die <xref:System.Speech.Synthesis.SpeechSynthesizer.Speak%2A> Methode.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Create a prompt from a string.  
        Prompt color = new Prompt("What is your favorite color?");  
  
        // Speak the contents of the prompt synchronously.  
        synth.Speak(color);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="" />
      </Docs>
    </Member>
    <Member MemberName="Speak">
      <MemberSignature Language="C#" Value="public void Speak (System.Speech.Synthesis.PromptBuilder promptBuilder);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void Speak(class System.Speech.Synthesis.PromptBuilder promptBuilder) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.Speak(System.Speech.Synthesis.PromptBuilder)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void Speak(System::Speech::Synthesis::PromptBuilder ^ promptBuilder);" />
      <MemberSignature Language="F#" Value="member this.Speak : System.Speech.Synthesis.PromptBuilder -&gt; unit" Usage="speechSynthesizer.Speak promptBuilder" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="promptBuilder" Type="System.Speech.Synthesis.PromptBuilder" />
      </Parameters>
      <Docs>
        <param name="promptBuilder">Der zu sprechende Inhalt.</param>
        <summary>Spricht synchron den Inhalt eines <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekts.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Um den Inhalt des asynchron zu sprechen ein <xref:System.Speech.Synthesis.PromptBuilder> -Objekts <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync%2A>.  
  
   
  
## Examples  
 Das folgende Beispiel erstellt eine <xref:System.Speech.Synthesis.PromptBuilder> Objekt aus einer Zeichenfolge und übergibt das Objekt als Argument an die <xref:System.Speech.Synthesis.SpeechSynthesizer.Speak%2A> Methode.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Create a PromptBuilder object and append a text string.  
        PromptBuilder song = new PromptBuilder();  
        song.AppendText("Say the name of the song you want to hear");  
  
        // Speak the contents of the prompt synchronously.  
        synth.Speak(song);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="" />
      </Docs>
    </Member>
    <Member MemberName="Speak">
      <MemberSignature Language="C#" Value="public void Speak (string textToSpeak);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void Speak(string textToSpeak) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.Speak(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub Speak (textToSpeak As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void Speak(System::String ^ textToSpeak);" />
      <MemberSignature Language="F#" Value="member this.Speak : string -&gt; unit" Usage="speechSynthesizer.Speak textToSpeak" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="textToSpeak" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="textToSpeak">Der zu sprechende Text.</param>
        <summary>Spricht synchron den Inhalt einer Zeichenfolge.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Um eine Zeichenfolge, die SSML-Markup enthält synchron zu sprechen, verwenden Sie die <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsml%2A> Methode. Um den Inhalt einer Zeichenfolge asynchron zu sprechen, verwenden Sie die <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync%2A> Methode.  
  
   
  
## Examples  
 Wie im folgenden Beispiel gezeigt die <xref:System.Speech.Synthesis.SpeechSynthesizer.Speak%2A> Methode bietet die einfachste Möglichkeit zum Generieren der Sprache, die synchron auszugeben.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Speak a string synchronously.  
        synth.Speak("What is your favorite color?");  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="" />
      </Docs>
    </Member>
    <MemberGroup MemberName="SpeakAsync">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Generiert eine zur Zeichenfolge asynchrone Sprachausgabe, ein <see cref="T:System.Speech.Synthesis.Prompt" />-Objekt oder ein <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekt.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Die <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync%2A> Methoden generieren asynchron die Spracherkennung. Die Methoden sofort ohne warten auf den Inhalt der <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync%2A> Objekt, das das sprechen abgeschlossen haben. Verwendung <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync%2A> Wenn Ihre Anwendung muss zum Ausführen von Aufgaben während des Sprechens hervorzuheben, z. B. Text, Animationen, Monitor-Steuerelemente oder andere Aufgaben zu zeichnen.  
  
 Während eines Aufrufs dieser Methode die <xref:System.Speech.Synthesis.SpeechSynthesizer> können die folgenden Ereignisse auslösen:  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.StateChanged>. Wird ausgelöst, wenn es sich bei der sprechzustand des Synthesizers ändert.  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakStarted>. Wird ausgelöst, wenn der Synthesizer beginnt, Generieren von Sprache.  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.PhonemeReached>. Jedes Mal ausgelöst, die der Synthesizer erreicht, einem Buchstaben oder einer Kombination aus Buchstaben, die diskret Sound von Sprache in einer anderen Sprache zu bilden.  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakProgress>. Jedes Mal ausgelöst, schließt der Synthesizer ein Wort zu sprechen.  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.VisemeReached>. Jedes Mal ausgelöst, gesprochenen Ausgabe eine Änderung der Position der Mund oder die gesichtserkennung gleiche verwendet, um die Spracherkennung zu erstellen erfordert.  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.BookmarkReached>. Wird ausgelöst, wenn es sich bei der Synthesizer ein Lesezeichen an einer Eingabeaufforderung feststellt.  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.VoiceChange>. Ausgelöst, wenn die Stimme für den Synthesizer ändert.  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakCompleted>. Wird ausgelöst, wenn der Synthesizer beendet eine <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync%2A> Vorgang.  
  
 Wenn Ihre Anwendung nicht während des Sprechens Aufgaben ausführen muss, können Sie die <xref:System.Speech.Synthesis.SpeechSynthesizer.Speak%2A> Methoden oder <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsml%2A> Methode zum Generieren einer Sprachausgabe synchron.  
  
 ]]></format>
        </remarks>
        <altmember cref="E:System.Speech.Synthesis.SpeechSynthesizer.BookmarkReached" />
        <altmember cref="E:System.Speech.Synthesis.SpeechSynthesizer.PhonemeReached" />
        <altmember cref="E:System.Speech.Synthesis.SpeechSynthesizer.SpeakCompleted" />
        <altmember cref="E:System.Speech.Synthesis.SpeechSynthesizer.SpeakProgress" />
        <altmember cref="E:System.Speech.Synthesis.SpeechSynthesizer.SpeakStarted" />
        <altmember cref="E:System.Speech.Synthesis.SpeechSynthesizer.StateChanged" />
        <altmember cref="E:System.Speech.Synthesis.SpeechSynthesizer.VisemeReached" />
        <altmember cref="E:System.Speech.Synthesis.SpeechSynthesizer.VoiceChange" />
      </Docs>
    </MemberGroup>
    <Member MemberName="SpeakAsync">
      <MemberSignature Language="C#" Value="public void SpeakAsync (System.Speech.Synthesis.Prompt prompt);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void SpeakAsync(class System.Speech.Synthesis.Prompt prompt) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync(System.Speech.Synthesis.Prompt)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void SpeakAsync(System::Speech::Synthesis::Prompt ^ prompt);" />
      <MemberSignature Language="F#" Value="member this.SpeakAsync : System.Speech.Synthesis.Prompt -&gt; unit" Usage="speechSynthesizer.SpeakAsync prompt" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="prompt" Type="System.Speech.Synthesis.Prompt" />
      </Parameters>
      <Docs>
        <param name="prompt">Der zu sprechende Inhalt.</param>
        <summary>Spricht asynchron den Inhalt eines <see cref="T:System.Speech.Synthesis.Prompt" />-Objekts.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Können Sie Abbrechen, das asynchrone sprechen einer Eingabeaufforderung mit dem <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsyncCancel%2A> oder <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsyncCancelAll%2A> Methode.  
  
 Um den Inhalt des synchron zu sprechen ein <xref:System.Speech.Synthesis.Prompt> -Objekts <xref:System.Speech.Synthesis.SpeechSynthesizer.Speak%2A>.  
  
   
  
## Examples  
 Das folgende Beispiel erstellt eine <xref:System.Speech.Synthesis.Prompt> Objekt aus einer Zeichenfolge und übergibt das Objekt als Argument an die <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync%2A> Methode.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      SpeechSynthesizer synth = new SpeechSynthesizer();  
  
      // Configure the audio output.   
      synth.SetOutputToDefaultAudioDevice();  
  
      // Create a prompt from a string.  
      Prompt color = new Prompt("What is your favorite color?");  
  
      // Speak the contents of the prompt asynchronously.  
      synth.SpeakAsync(color);  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="" />
      </Docs>
    </Member>
    <Member MemberName="SpeakAsync">
      <MemberSignature Language="C#" Value="public System.Speech.Synthesis.Prompt SpeakAsync (System.Speech.Synthesis.PromptBuilder promptBuilder);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Speech.Synthesis.Prompt SpeakAsync(class System.Speech.Synthesis.PromptBuilder promptBuilder) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync(System.Speech.Synthesis.PromptBuilder)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; System::Speech::Synthesis::Prompt ^ SpeakAsync(System::Speech::Synthesis::PromptBuilder ^ promptBuilder);" />
      <MemberSignature Language="F#" Value="member this.SpeakAsync : System.Speech.Synthesis.PromptBuilder -&gt; System.Speech.Synthesis.Prompt" Usage="speechSynthesizer.SpeakAsync promptBuilder" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Synthesis.Prompt</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="promptBuilder" Type="System.Speech.Synthesis.PromptBuilder" />
      </Parameters>
      <Docs>
        <param name="promptBuilder">Der zu sprechende Inhalt.</param>
        <summary>Spricht asynchron den Inhalt eines <see cref="T:System.Speech.Synthesis.PromptBuilder" />-Objekts.</summary>
        <returns>Gibt das Objekt zurück, das den zu sprechenden Inhalt enthält.</returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Um den Inhalt des synchron zu sprechen ein <xref:System.Speech.Synthesis.PromptBuilder> -Objekts <xref:System.Speech.Synthesis.SpeechSynthesizer.Speak%2A>.  
  
   
  
## Examples  
 Das folgende Beispiel erstellt eine <xref:System.Speech.Synthesis.PromptBuilder> Objekt aus einer Zeichenfolge und übergibt das Objekt als Argument an die <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync%2A> Methode.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      SpeechSynthesizer synth = new SpeechSynthesizer();  
  
      // Configure the audio output.   
      synth.SetOutputToDefaultAudioDevice();  
  
      // Create a PromptBuilder object and append a text string.  
      PromptBuilder song = new PromptBuilder();  
      song.AppendText("Say the name of the song you want to hear");  
  
      // Speak the contents of the prompt asynchronously.  
      synth.SpeakAsync(song);  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="" />
      </Docs>
    </Member>
    <Member MemberName="SpeakAsync">
      <MemberSignature Language="C#" Value="public System.Speech.Synthesis.Prompt SpeakAsync (string textToSpeak);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Speech.Synthesis.Prompt SpeakAsync(string textToSpeak) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Function SpeakAsync (textToSpeak As String) As Prompt" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; System::Speech::Synthesis::Prompt ^ SpeakAsync(System::String ^ textToSpeak);" />
      <MemberSignature Language="F#" Value="member this.SpeakAsync : string -&gt; System.Speech.Synthesis.Prompt" Usage="speechSynthesizer.SpeakAsync textToSpeak" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Synthesis.Prompt</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="textToSpeak" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="textToSpeak">Der zu sprechende Text.</param>
        <summary>Spricht asynchron den Inhalt eines -Objekts.</summary>
        <returns>Gibt das Objekt zurück, das den zu sprechenden Inhalt enthält.</returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Um eine Zeichenfolge, die SSML-Markup enthält asynchron zu sprechen, verwenden Sie die <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsmlAsync%2A> Methode. Um den Inhalt einer Zeichenfolge synchron zu sprechen, verwenden Sie die <xref:System.Speech.Synthesis.SpeechSynthesizer.Speak%2A> Methode. Können Sie Abbrechen, das asynchrone sprechen einer Eingabeaufforderung mit dem <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsyncCancel%2A> oder <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsyncCancelAll%2A> Methode.  
  
   
  
## Examples  
 Wie im folgenden Beispiel gezeigt die <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync%2A> Methode bietet die einfachste Möglichkeit zum Generieren der Sprache, die asynchron auszugeben.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      SpeechSynthesizer synth = new SpeechSynthesizer();  
  
      // Configure the audio output.   
      synth.SetOutputToDefaultAudioDevice();  
  
      // Speak a string asynchronously.  
      synth.SpeakAsync("What is your favorite color?");  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="Overload:System.Speech.Synthesis.SpeechSynthesizer.Speak" />
      </Docs>
    </Member>
    <Member MemberName="SpeakAsyncCancel">
      <MemberSignature Language="C#" Value="public void SpeakAsyncCancel (System.Speech.Synthesis.Prompt prompt);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void SpeakAsyncCancel(class System.Speech.Synthesis.Prompt prompt) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsyncCancel(System.Speech.Synthesis.Prompt)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void SpeakAsyncCancel(System::Speech::Synthesis::Prompt ^ prompt);" />
      <MemberSignature Language="F#" Value="member this.SpeakAsyncCancel : System.Speech.Synthesis.Prompt -&gt; unit" Usage="speechSynthesizer.SpeakAsyncCancel prompt" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="prompt" Type="System.Speech.Synthesis.Prompt" />
      </Parameters>
      <Docs>
        <param name="prompt">Der Inhalt, für den ein Sprechvorgang abgebrochen wird.</param>
        <summary>Bricht den asynchronen Synthesevorgang für eine Eingabeaufforderung in der Warteschlange ab.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Sie können diese Methode auch verwenden, um einen asynchronen abzubrechen sprechen Vorgang für die folgenden:  
  
-   Den Inhalt einer <xref:System.String> gemäß einer <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync%2A?displayProperty=nameWithType> Methode.  
  
-   Den Inhalt einer <xref:System.Speech.Synthesis.PromptBuilder> gemäß einer <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync%2A?displayProperty=nameWithType> Methode.  
  
-   Den Inhalt einer <xref:System.String> , die anhand des SSML enthält eine <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsmlAsync%2A> Methode.  
  
 Beim Aufruf <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync%2A?displayProperty=nameWithType>, <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync%2A?displayProperty=nameWithType>, oder <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsmlAsync%2A>, "System.Speech" erstellt eine <xref:System.Speech.Synthesis.Prompt> -Objekt und füllt sie mit dem Inhalt des Parameters der Methode und gibt die <xref:System.Speech.Synthesis.Prompt> Objekt. Wenn Sie eine Kopie des zurückgegebenen beibehalten <xref:System.Speech.Synthesis.Prompt>, können Sie ihn in übergeben <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsyncCancel%2A> gesehen, in einem angegebenen Inhalt Abbrechen einer <xref:System.String> oder <xref:System.Speech.Synthesis.PromptBuilder> Objekt.  
  
 ]]></format>
        </remarks>
        <altmember cref="" />
      </Docs>
    </Member>
    <Member MemberName="SpeakAsyncCancelAll">
      <MemberSignature Language="C#" Value="public void SpeakAsyncCancelAll ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void SpeakAsyncCancelAll() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsyncCancelAll" />
      <MemberSignature Language="VB.NET" Value="Public Sub SpeakAsyncCancelAll ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void SpeakAsyncCancelAll();" />
      <MemberSignature Language="F#" Value="member this.SpeakAsyncCancelAll : unit -&gt; unit" Usage="speechSynthesizer.SpeakAsyncCancelAll " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Bricht alle in der Warteschlange stehenden, asynchronen Sprachesynthesevorgänge ab.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Examples  
 Das folgende Beispiel zeigt eine Verwendung von <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsyncCancelAll%2A> zum Abbrechen der asynchronen sprechen einer Eingabeaufforderung, so, dass eine neue Eingabeaufforderung gesprochen werden kann. Beachten Sie, dass die <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakCompleted> Ereignis wird ausgelöst, wenn eine <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync%2A> Vorgang wird abgebrochen.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
using System.Threading;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      SpeechSynthesizer synth = new SpeechSynthesizer();  
  
      // Configure the audio output.   
      synth.SetOutputToDefaultAudioDevice();  
  
      // Subscribe to the StateChanged event.  
      synth.StateChanged += new EventHandler<StateChangedEventArgs>(synth_StateChanged);  
  
      // Subscribe to the SpeakProgress event.  
      synth.SpeakProgress += new EventHandler<SpeakProgressEventArgs>(synth_SpeakProgress);  
  
      // Subscribe to the SpeakCompleted event.  
      synth.SpeakCompleted += new EventHandler<SpeakCompletedEventArgs>(synth_SpeakCompleted);  
  
      // Begin speaking a text string asynchronously.  
      synth.SpeakAsync("Speech is an effective and natural way for people to interact with applications, " +  
        "complementing or even replacing the use of mice, keyboards, controllers, and gestures.");  
  
      // Speak for four seconds.  
      Thread.Sleep(4000);  
  
      // Cancel the SpeakAsync operation and wait one second.  
      synth.SpeakAsyncCancelAll();  
      Thread.Sleep(1000);  
  
      // Speak a new text string.  
      synth.Speak("An urgent email message has arrived. Do you want to hear it?");  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Write to the console when the SpeakAsync operation has been cancelled.  
    static void synth_SpeakCompleted(object sender, SpeakCompletedEventArgs e)  
    {  
      Console.WriteLine("\nThe SpeakAsync operation was cancelled!!");  
    }  
  
    // When it changes, write the state of the SpeechSynthesizer to the console.  
    static void synth_StateChanged(object sender, StateChangedEventArgs e)  
    {  
      Console.WriteLine("\nSynthesizer State: {0}    Previous State: {1}\n", e.State, e.PreviousState);  
    }  
  
    // Write the text being spoken by the SpeechSynthesizer to the console.  
    static void synth_SpeakProgress(object sender, SpeakProgressEventArgs e)  
    {  
      Console.WriteLine(e.Text);  
    }      
  }    
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="" />
      </Docs>
    </Member>
    <Member MemberName="SpeakCompleted">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Synthesis.SpeakCompletedEventArgs&gt; SpeakCompleted;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Synthesis.SpeakCompletedEventArgs&gt; SpeakCompleted" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Synthesis.SpeechSynthesizer.SpeakCompleted" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event SpeakCompleted As EventHandler(Of SpeakCompletedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Synthesis::SpeakCompletedEventArgs ^&gt; ^ SpeakCompleted;" />
      <MemberSignature Language="F#" Value="member this.SpeakCompleted : EventHandler&lt;System.Speech.Synthesis.SpeakCompletedEventArgs&gt; " Usage="member this.SpeakCompleted : System.EventHandler&lt;System.Speech.Synthesis.SpeakCompletedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Synthesis.SpeakCompletedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Wird ausgelöst, wenn das <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" /> das Sprechen einer Eingabeaufforderung abschließt.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Die <xref:System.Speech.Synthesis.SpeechSynthesizer> löst die <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakCompleted> Ereignis nach dem Abschluss aller der <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync%2A> oder <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsmlAsync%2A> Methoden.  
  
 Die <xref:System.Speech.Synthesis.SpeakCompletedEventArgs> Klasse verfügt über keine Eigenschaften, und keine Daten aus zurückgibt, die <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakCompleted> Ereignis. Er wird bereitgestellt, um Autoren von Ereignishandlern für Schreiben der <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakCompleted> Ereignis.  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Synthesis.SpeakCompletedEventArgs" />
      </Docs>
    </Member>
    <Member MemberName="SpeakProgress">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Synthesis.SpeakProgressEventArgs&gt; SpeakProgress;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Synthesis.SpeakProgressEventArgs&gt; SpeakProgress" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Synthesis.SpeechSynthesizer.SpeakProgress" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event SpeakProgress As EventHandler(Of SpeakProgressEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Synthesis::SpeakProgressEventArgs ^&gt; ^ SpeakProgress;" />
      <MemberSignature Language="F#" Value="member this.SpeakProgress : EventHandler&lt;System.Speech.Synthesis.SpeakProgressEventArgs&gt; " Usage="member this.SpeakProgress : System.EventHandler&lt;System.Speech.Synthesis.SpeakProgressEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Synthesis.SpeakProgressEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Wird ausgelöst, nachdem der <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" /> jedes einzelne Wort einer Eingabeaufforderung spricht.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Die <xref:System.Speech.Synthesis.SpeechSynthesizer> löst dieses Ereignis für jedes neue Wort, das sie an einer Eingabeaufforderung mit einer der spricht der <xref:System.Speech.Synthesis.SpeechSynthesizer.Speak%2A>, <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync%2A>, <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsml%2A>, oder <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsmlAsync%2A> Methoden. Ein Beispiel und Weitere Informationen zu dem Ereignis zugeordneten Daten, finden Sie unter <xref:System.Speech.Synthesis.SpeakProgressEventArgs>.  
  
 ]]></format>
        </remarks>
        <altmember cref="" />
      </Docs>
    </Member>
    <Member MemberName="SpeakSsml">
      <MemberSignature Language="C#" Value="public void SpeakSsml (string textToSpeak);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void SpeakSsml(string textToSpeak) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsml(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub SpeakSsml (textToSpeak As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void SpeakSsml(System::String ^ textToSpeak);" />
      <MemberSignature Language="F#" Value="member this.SpeakSsml : string -&gt; unit" Usage="speechSynthesizer.SpeakSsml textToSpeak" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="textToSpeak" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="textToSpeak">Die zu sprechende SSML-Zeichenfolge.</param>
        <summary>Spricht synchron eine <see cref="T:System.String" />, welche ein SSML-Markup enthält.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Den Inhalt der `textToSpeak` Parameter enthalten muss eine `speak` Element und entsprechen der [Speech Synthesis Markup Language (SSML) Version 1.0](https://go.microsoft.com/fwlink/?LinkId=201763). Weitere Informationen finden Sie unter [Speech Synthesis Markup Language Reference](https://msdn.microsoft.com/library/0c51279e-84d2-4f73-a924-8832039abf94).  
  
 Um eine Zeichenfolge, die SSML-Markup enthält asynchron zu sprechen, verwenden Sie die <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsmlAsync%2A> Methode. Sie können <xref:System.Speech.Synthesis.SpeechSynthesizer.Speak%2A> initiiert die synchrone Apropos einer Zeichenfolge, die SSML-Code nicht enthält.  
  
 Während eines Aufrufs dieser Methode die <xref:System.Speech.Synthesis.SpeechSynthesizer> können die folgenden Ereignisse auslösen:  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.StateChanged>. Wird ausgelöst, wenn es sich bei der sprechzustand des Synthesizers ändert.  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakStarted>. Wird ausgelöst, wenn der Synthesizer beginnt, Generieren von Sprache.  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.PhonemeReached>. Jedes Mal ausgelöst, die der Synthesizer erreicht, einem Buchstaben oder einer Kombination aus Buchstaben, die diskret Sound von Sprache in einer anderen Sprache zu bilden.  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakProgress>. Jedes Mal ausgelöst, schließt der Synthesizer ein Wort zu sprechen.  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.VisemeReached>. Jedes Mal ausgelöst, gesprochenen Ausgabe eine Änderung der Position der Mund oder die gesichtserkennung gleiche verwendet, um die Spracherkennung zu erstellen erfordert.  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.BookmarkReached>. Wird ausgelöst, wenn es sich bei der Synthesizer ein Lesezeichen an einer Eingabeaufforderung feststellt.  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.VoiceChange>. Ausgelöst, wenn die Stimme für den Synthesizer ändert.  
  
 Die <xref:System.Speech.Synthesis.SpeechSynthesizer> löst nicht die <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakCompleted> Ereignis während der Verarbeitung der <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsml%2A> Methode.  
  
   
  
## Examples  
 Im folgende Beispiel wird gerendert, das Datum 1/29/2009 als ein Tag im Monat, Tag, Jahr Reihenfolge.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      SpeechSynthesizer synth = new SpeechSynthesizer();  
  
      // Configure the audio output.   
      synth.SetOutputToDefaultAudioDevice();  
  
      // Build an SSML prompt in a string.  
      string str = "<speak version=\"1.0\"";  
      str += " xmlns=\"http://www.w3.org/2001/10/synthesis\"";  
      str += " xml:lang=\"en-US\">";  
      str += "<say-as type=\"date:mdy\"> 1/29/2009 </say-as>";  
      str += "</speak>";  
  
      // Speak the contents of the prompt synchronously.
      synth.SpeakSsml(str);  
  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="" />
      </Docs>
    </Member>
    <Member MemberName="SpeakSsmlAsync">
      <MemberSignature Language="C#" Value="public System.Speech.Synthesis.Prompt SpeakSsmlAsync (string textToSpeak);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Speech.Synthesis.Prompt SpeakSsmlAsync(string textToSpeak) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsmlAsync(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Function SpeakSsmlAsync (textToSpeak As String) As Prompt" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; System::Speech::Synthesis::Prompt ^ SpeakSsmlAsync(System::String ^ textToSpeak);" />
      <MemberSignature Language="F#" Value="member this.SpeakSsmlAsync : string -&gt; System.Speech.Synthesis.Prompt" Usage="speechSynthesizer.SpeakSsmlAsync textToSpeak" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Synthesis.Prompt</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="textToSpeak" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="textToSpeak">Das zu sprechende SMML-Markup.</param>
        <summary>Spricht asynchron eine <see cref="T:System.String" />, die SSML-Markup enthält.</summary>
        <returns>To be added.</returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Den Inhalt der `textToSpeak` Parameter enthalten muss eine `speak` Element und entsprechen der [Speech Synthesis Markup Language (SSML) Version 1.0](https://go.microsoft.com/fwlink/?LinkId=201763). Weitere Informationen finden Sie unter [Speech Synthesis Markup Language Reference](https://msdn.microsoft.com/library/0c51279e-84d2-4f73-a924-8832039abf94).  
  
 Um eine Zeichenfolge, die SSML-Markup enthält synchron zu sprechen, verwenden Sie die <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsml%2A> Methode. Sie können <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync%2A> initiiert die asynchrone Apropos einer Zeichenfolge, die SSML-Code nicht enthält.  
  
 Während eines Aufrufs dieser Methode die <xref:System.Speech.Synthesis.SpeechSynthesizer> können die folgenden Ereignisse auslösen:  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.StateChanged>. Wird ausgelöst, wenn es sich bei der sprechzustand des Synthesizers ändert.  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakStarted>. Wird ausgelöst, wenn der Synthesizer beginnt, Generieren von Sprache.  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.PhonemeReached>. Jedes Mal ausgelöst, die der Synthesizer erreicht, einem Buchstaben oder einer Kombination aus Buchstaben, die diskret Sound von Sprache in einer anderen Sprache zu bilden.  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakProgress>. Jedes Mal ausgelöst, schließt der Synthesizer ein Wort zu sprechen.  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.VisemeReached>. Jedes Mal ausgelöst, gesprochenen Ausgabe eine Änderung der Position der Mund oder die gesichtserkennung gleiche verwendet, um die Spracherkennung zu erstellen erfordert.  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.BookmarkReached>. Wird ausgelöst, wenn es sich bei der Synthesizer ein Lesezeichen an einer Eingabeaufforderung feststellt.  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.VoiceChange>. Ausgelöst, wenn die Stimme für den Synthesizer ändert.  
  
-   <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakCompleted>. Wird ausgelöst, wenn der Synthesizer die Verarbeitung abgeschlossen hat eine <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsmlAsync%2A> Vorgang.  
  
 Wenn Ihre Anwendung Dos nicht während des Sprechens Aufgaben ausführen müssen, können Sie die <xref:System.Speech.Synthesis.SpeechSynthesizer.Speak%2A> oder <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsml%2A> Methode zum Generieren einer Sprachausgabe synchron.  
  
   
  
## Examples  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      SpeechSynthesizer synth = new SpeechSynthesizer();  
  
      // Configure the audio output.   
      synth.SetOutputToDefaultAudioDevice();  
  
      // Build an SSML prompt in a string.  
      string str = "<speak version=\"1.0\"";  
      str += " xmlns=\"http://www.w3.org/2001/10/synthesis\"";  
      str += " xml:lang=\"en-US\">";  
      str += "<say-as type=\"date:mdy\"> 1/29/2009 </say-as>";  
      str += "</speak>";  
  
      // Speak the contents of the prompt asynchronously.  
      synth.SpeakSsmlAsync(str);  
  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="" />
      </Docs>
    </Member>
    <Member MemberName="SpeakStarted">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Synthesis.SpeakStartedEventArgs&gt; SpeakStarted;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Synthesis.SpeakStartedEventArgs&gt; SpeakStarted" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Synthesis.SpeechSynthesizer.SpeakStarted" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event SpeakStarted As EventHandler(Of SpeakStartedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Synthesis::SpeakStartedEventArgs ^&gt; ^ SpeakStarted;" />
      <MemberSignature Language="F#" Value="member this.SpeakStarted : EventHandler&lt;System.Speech.Synthesis.SpeakStartedEventArgs&gt; " Usage="member this.SpeakStarted : System.EventHandler&lt;System.Speech.Synthesis.SpeakStartedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Synthesis.SpeakStartedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Wird ausgelöst, wenn das <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" /> mit dem Sprechen einer Eingabeaufforderung beginnt.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Die <xref:System.Speech.Synthesis.SpeechSynthesizer> löst dieses Ereignis, wenn es beginnt mit der eine Eingabeaufforderung, die mit einer der Verarbeitung der <xref:System.Speech.Synthesis.SpeechSynthesizer.Speak%2A>, <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync%2A>, <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsml%2A>, oder <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsmlAsync%2A> Methoden.  
  
 Die <xref:System.Speech.Synthesis.SpeakStartedEventArgs> Klasse verfügt über keine Eigenschaften, und keine Daten aus zurückgibt, die <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakStarted> Ereignis. Er wird bereitgestellt, um Autoren von Ereignishandlern für Schreiben der <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakStarted> Ereignis.  
  
 ]]></format>
        </remarks>
        <altmember cref="" />
      </Docs>
    </Member>
    <Member MemberName="State">
      <MemberSignature Language="C#" Value="public System.Speech.Synthesis.SynthesizerState State { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.Speech.Synthesis.SynthesizerState State" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Synthesis.SpeechSynthesizer.State" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property State As SynthesizerState" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::Synthesis::SynthesizerState State { System::Speech::Synthesis::SynthesizerState get(); };" />
      <MemberSignature Language="F#" Value="member this.State : System.Speech.Synthesis.SynthesizerState" Usage="System.Speech.Synthesis.SpeechSynthesizer.State" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Synthesis.SynthesizerState</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Ruft den aktuellen Sprechzustand des <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" />-Objekts ab.</summary>
        <value>Gibt den aktuellen Sprechzustand des <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" />-Objekts ab.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Den neuen Status der abzurufenden der <xref:System.Speech.Synthesis.SpeechSynthesizer> nach dem ändern, verwenden die <xref:System.Speech.Synthesis.StateChangedEventArgs.State%2A> Eigenschaft der <xref:System.Speech.Synthesis.StateChangedEventArgs> Klasse.  
  
   
  
## Examples  
 Das folgende Beispiel zeigt den Status der <xref:System.Speech.Synthesis.SpeechSynthesizer> vor, während und nach dem sprechen einer Eingabeaufforderung.  
  
```csharp  
using System;  
using System.Threading;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      SpeechSynthesizer synth = new SpeechSynthesizer() ;  
  
      // Configure the audio output.   
      synth.SetOutputToDefaultAudioDevice();  
  
      // Subscribe to the SpeakProgress event.         
      synth.SpeakProgress += new EventHandler<SpeakProgressEventArgs>(synth_SpeakProgress);  
  
      // Write the state of the SpeechSynthesizer to the console.  
      Console.WriteLine("Current Synthesizer state: " + synth.State + "\n");  
  
      // Speak a string asynchronously.  
      synth.SpeakAsync("What is your favorite color?");  
  
      // Write the state of the SpeechSynthesizer to the console while it is speaking.  
      Thread.Sleep(1000);  
      Console.WriteLine("\n - Current Synthesizer state: " + synth.State + " - \n");  
  
      // Write the state of the SpeechSynthesizer to the console after it is done speaking.  
      Thread.Sleep(2000);  
      Console.WriteLine("\nCurrent Synthesizer state: " + synth.State);  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    static void synth_SpeakProgress(object sender, SpeakProgressEventArgs e)  
    {  
      Console.WriteLine(e.Text);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="StateChanged">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Synthesis.StateChangedEventArgs&gt; StateChanged;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Synthesis.StateChangedEventArgs&gt; StateChanged" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Synthesis.SpeechSynthesizer.StateChanged" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event StateChanged As EventHandler(Of StateChangedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Synthesis::StateChangedEventArgs ^&gt; ^ StateChanged;" />
      <MemberSignature Language="F#" Value="member this.StateChanged : EventHandler&lt;System.Speech.Synthesis.StateChangedEventArgs&gt; " Usage="member this.StateChanged : System.EventHandler&lt;System.Speech.Synthesis.StateChangedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Synthesis.StateChangedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Wird ausgelöst, wenn sich der Zustand von <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" /> ändert.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Die <xref:System.Speech.Synthesis.SpeechSynthesizer> löst dieses Ereignis aus, wenn seine Vorträge <xref:System.Speech.Synthesis.SpeechSynthesizer.State%2A> Änderungen. Ein Beispiel und Weitere Informationen zu dem Ereignis zugeordneten Daten, finden Sie unter <xref:System.Speech.Synthesis.StateChangedEventArgs>.  
  
 Verwenden Sie zum Anhalten und Fortsetzen von Sprachsynthese, die <xref:System.Speech.Synthesis.SpeechSynthesizer.Pause%2A> und <xref:System.Speech.Synthesis.SpeechSynthesizer.Resume%2A> Methoden.  
  
 ]]></format>
        </remarks>
        <altmember cref="" />
      </Docs>
    </Member>
    <Member MemberName="VisemeReached">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Synthesis.VisemeReachedEventArgs&gt; VisemeReached;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Synthesis.VisemeReachedEventArgs&gt; VisemeReached" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Synthesis.SpeechSynthesizer.VisemeReached" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event VisemeReached As EventHandler(Of VisemeReachedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Synthesis::VisemeReachedEventArgs ^&gt; ^ VisemeReached;" />
      <MemberSignature Language="F#" Value="member this.VisemeReached : EventHandler&lt;System.Speech.Synthesis.VisemeReachedEventArgs&gt; " Usage="member this.VisemeReached : System.EventHandler&lt;System.Speech.Synthesis.VisemeReachedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Synthesis.VisemeReachedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Wird ausgelöst, wenn ein viseme erreicht wird.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Ein mundbild beendet ist die grundlegende Position den Mund und gesichtserkennung, wenn ein Phonem aussprechen. Visemes sind visuelle Darstellungen der Phoneme.  
  
 "System.Speech" unterstützt 21 Visemes für Englisch (USA), von denen jeder zu einem oder mehreren phonemen entspricht.  <xref:System.Speech.Synthesis.SpeechSynthesizer.VisemeReached> Ereignisse werden ausgelöst, wenn ein neues Phonem erreicht einen anderen entsprechenden mundbilds als das vorherige Phonem erreicht hat. Da einige Visemes mehr als ein Phonem, darstellen einer <xref:System.Speech.Synthesis.SpeechSynthesizer.VisemeReached> Ereignis wird nicht generiert werden, wenn das nächste Phonem erreicht die gleiche mundbilds als das vorherige Phonem entspricht. Für den gesprochenen Text "dieser Zone", beispielsweise eine <xref:System.Speech.Synthesis.SpeechSynthesizer.PhonemeReached> Ereignis wird ausgelöst, für das "s" in "this" und "Z" in "Zone". Allerdings eine <xref:System.Speech.Synthesis.SpeechSynthesizer.VisemeReached> Ereignis wird nicht für das "Z" in "Zone" ausgelöst, da es die gleichen mundbilds als das "s" in "this" entspricht.  
  
 Im folgenden finden eine Liste der 21 SAPI Phoneme und Phonem-Gruppen, die ein Viseme in Englisch (USA) entsprechen.  
  
|Mundbilds|Phoneme(s)|  
|------------|------------------|  
|0|Ruheintervall|  
|1|AE, ax, ah|  
|2|aa|  
|3|AO|  
|4|EY, eh, oh!|  
|5|er|  
|6|y "," Iy "," bei "," ix|  
|7|w, uw|  
|8|zulassen|  
|9|AW|  
|10|Oy|  
|11|ein beliebiger|  
|12|h|  
|13|b|  
|14|l|  
|15|s, z|  
|16|sh-, ch, Jh, Zh|  
|17|th, dh|  
|18|f, v|  
|19|t, t, n|  
|20|k, g, ng|  
|21|p, b, m|  
  
 Informationen zu Daten im Zusammenhang mit der `VisemeReached` Ereignis finden Sie unter <xref:System.Speech.Synthesis.VisemeReachedEventArgs>.  
  
 ]]></format>
        </remarks>
        <altmember cref="" />
      </Docs>
    </Member>
    <Member MemberName="Voice">
      <MemberSignature Language="C#" Value="public System.Speech.Synthesis.VoiceInfo Voice { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Speech.Synthesis.VoiceInfo Voice" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Synthesis.SpeechSynthesizer.Voice" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Voice As VoiceInfo" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::Synthesis::VoiceInfo ^ Voice { System::Speech::Synthesis::VoiceInfo ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.Voice : System.Speech.Synthesis.VoiceInfo" Usage="System.Speech.Synthesis.SpeechSynthesizer.Voice" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Synthesis.VoiceInfo</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Ruft Informationen über die aktuelle Stimme des <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" />-Objekts ab.</summary>
        <value>Gibt Informationen über die aktuelle Stimme des <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" />-Objekts zurück.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Wenn Sie ein neues initialisieren <xref:System.Speech.Synthesis.SpeechSynthesizer>, verwendet die Standard-System-Stimme. So konfigurieren Sie die <xref:System.Speech.Synthesis.SpeechSynthesizer> Objekt, das keines der installierten Stimmen der Sprachsynthese zurück, verwenden Sie die <xref:System.Speech.Synthesis.SpeechSynthesizer.SelectVoice%2A> oder <xref:System.Speech.Synthesis.SpeechSynthesizer.SelectVoiceByHints%2A> Methode. Rufen Sie Informationen darüber, welche stimmen zurück, die installiert werden mit der <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> Methode und die <xref:System.Speech.Synthesis.VoiceInfo> Klasse.  
  
   
  
## Examples  
 Im folgende Beispiel initialisiert eine Instanz der <xref:System.Speech.Synthesis.SpeechSynthesizer> und ruft Informationen über die aktuelle Stimme ab.  
  
```csharp  
using System;  
using System.IO;  
using System.Speech.Synthesis;  
using System.Speech.AudioFormat;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Get information about supported audio formats.  
        string AudioFormats = "";  
        foreach (SpeechAudioFormatInfo fmt in synth.Voice.SupportedAudioFormats)  
        {  
          AudioFormats += String.Format("{0}\n",  
          fmt.EncodingFormat.ToString());  
        }  
  
        // Write information about the voice to the console.  
        Console.WriteLine(" Name:          " + synth.Voice.Name);  
        Console.WriteLine(" Culture:       " + synth.Voice.Culture);  
        Console.WriteLine(" Age:           " + synth.Voice.Age);  
        Console.WriteLine(" Gender:        " + synth.Voice.Gender);  
        Console.WriteLine(" Description:   " + synth.Voice.Description);  
        Console.WriteLine(" ID:            " + synth.Voice.Id);  
        if (synth.Voice.SupportedAudioFormats.Count != 0)  
        {  
          Console.WriteLine(" Audio formats: " + AudioFormats);  
        }  
        else  
        {  
          Console.WriteLine(" No supported audio formats found");  
        }  
  
        // Get additional information about the voice.  
        string AdditionalInfo = "";  
        foreach (string key in synth.Voice.AdditionalInfo.Keys)  
        {  
          AdditionalInfo += String.Format("  {0}: {1}\n",  
            key, synth.Voice.AdditionalInfo[key]);  
        }  
  
        Console.WriteLine(" Additional Info - " + AdditionalInfo);  
        Console.WriteLine();  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Synthesis.SpeechSynthesizer.SelectVoice(System.String)" />
        <altmember cref="M:System.Speech.Synthesis.SpeechSynthesizer.SelectVoiceByHints(System.Speech.Synthesis.VoiceGender)" />
        <altmember cref="M:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices" />
        <altmember cref="E:System.Speech.Synthesis.SpeechSynthesizer.VoiceChange" />
      </Docs>
    </Member>
    <Member MemberName="VoiceChange">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Synthesis.VoiceChangeEventArgs&gt; VoiceChange;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Synthesis.VoiceChangeEventArgs&gt; VoiceChange" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Synthesis.SpeechSynthesizer.VoiceChange" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event VoiceChange As EventHandler(Of VoiceChangeEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Synthesis::VoiceChangeEventArgs ^&gt; ^ VoiceChange;" />
      <MemberSignature Language="F#" Value="member this.VoiceChange : EventHandler&lt;System.Speech.Synthesis.VoiceChangeEventArgs&gt; " Usage="member this.VoiceChange : System.EventHandler&lt;System.Speech.Synthesis.VoiceChangeEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Synthesis.VoiceChangeEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Wird ausgelöst, wenn sich die Stimme von <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" /> ändert.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Ein Beispiel und Informationen zu Daten, die dem Ereignis zugeordnet wird, finden Sie unter <xref:System.Speech.Synthesis.VoiceChangeEventArgs>.  
  
 Können Sie die Sprache ändern, die <xref:System.Speech.Synthesis.SpeechSynthesizer> verwendet, mit der <xref:System.Speech.Synthesis.PromptBuilder>des <xref:System.Speech.Synthesis.PromptBuilder.StartVoice%2A> Methoden oder <xref:System.Speech.Synthesis.SpeechSynthesizer>des <xref:System.Speech.Synthesis.SpeechSynthesizer.SelectVoice%2A> oder <xref:System.Speech.Synthesis.SpeechSynthesizer.SelectVoiceByHints%2A> Methoden.  
  
 ]]></format>
        </remarks>
        <altmember cref="" />
      </Docs>
    </Member>
    <Member MemberName="Volume">
      <MemberSignature Language="C#" Value="public int Volume { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance int32 Volume" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Synthesis.SpeechSynthesizer.Volume" />
      <MemberSignature Language="VB.NET" Value="Public Property Volume As Integer" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property int Volume { int get(); void set(int value); };" />
      <MemberSignature Language="F#" Value="member this.Volume : int with get, set" Usage="System.Speech.Synthesis.SpeechSynthesizer.Volume" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Int32</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Ruft die Ausgabelautstärke des <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" />-Objekts ab oder legt sie fest.</summary>
        <value>Gibt die Lautstärke des <see cref="T:System.Speech.Synthesis.SpeechSynthesizer" /> von 0 bis 100 zurück.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Examples  
 Im folgenden Beispiel wird die Menge der der <xref:System.Speech.Synthesis.SpeechSynthesizer>Ausgabe Audio für die synthetisierten Stimme und WAV-Datei.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Set the volume of the SpeechSynthesizer's ouput.  
        synth.Volume = 60;  
  
        // Build a prompt containing recorded audio and synthesized speech.  
        PromptBuilder builder = new PromptBuilder(  
          new System.Globalization.CultureInfo("en-US"));  
        builder.AppendAudio("C:\\Test\\WelcomeToContosoRadio.wav");  
        builder.AppendText(  
          "The weather forecast for today is partly cloudy with some sun breaks.");  
  
        // Speak the prompt.  
        synth.Speak(builder);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
  </Members>
</Type>
