<Namespace Name="System.Speech.Recognition">
  <Metadata>
    <Meta Name="ms.openlocfilehash" Value="be08311c812e33ac449fae40c2d2494af9dc7fe5" />
    <Meta Name="ms.sourcegitcommit" Value="434f60616a9793fa8436744549fc856e94f7a648" />
    <Meta Name="ms.translationtype" Value="HT" />
    <Meta Name="ms.contentlocale" Value="de-DE" />
    <Meta Name="ms.lasthandoff" Value="08/24/2018" />
    <Meta Name="ms.locfileid" Value="30735974" />
  </Metadata>
  <Docs>
    <summary>Der <see cref="N:System.Speech.Recognition" />-Namespace enthält Windows Desktop Speech-Technologie zum Implementieren von Spracherkennung.</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Die Software für Windows Desktop Speech Technology bietet eine einfache Sprache Recognition-Infrastruktur, die digitalisiert Geräuschmeßnorm Signale und Wörter und Spracherkennung Elemente aus der Audioeingabe wiederhergestellt.  
  
 Anwendungen verwenden die <xref:System.Speech.Recognition> Namespace zugreifen, und erweitern diese grundlegenden spracherkennungstechnologie durch Algorithmen zum Identifizieren und zu, die auf bestimmte Ausdrücke oder Word-Muster zu definieren und verwalten das Laufzeitverhalten von dieser Sprache die Infrastruktur.  
  
 **Grammatiken erstellen**  
  
 Sie erstellen eine Grammatik, die einem Satz von Regeln oder Einschränkungen, die zum Definieren von Wörtern und Ausdrücken, die die Anwendung erkennt als sinnvolle Eingabe bestehen. Verwenden einen Konstruktor für die <xref:System.Speech.Recognition.Grammar> -Klasse, Sie können ein "Grammar"-Objekt erstellen, zur Laufzeit von <xref:System.Speech.Recognition.GrammarBuilder> oder <xref:System.Speech.Recognition.SrgsGrammar.SrgsDocument> Instanzen oder aus einer Datei, eine Zeichenfolge oder ein Stream, der eine Definition einer Grammatik enthält.  
  
 Mithilfe der <xref:System.Speech.Recognition.GrammarBuilder> und <xref:System.Speech.Recognition.Choices> -Klassen Sie Grammatiken programmgesteuert erstellen von geringen bis mittleren Komplexität, die verwendet werden kann, um Erkennungsvorgänge für viele allgemeine Szenarien auszuführen. Zum Erstellen von Grammatiken programmgesteuert, die entsprechen, den [Speech Recognition Grammar Specification 1.0 (SRGS)](http://go.microsoft.com/fwlink/?LinkId=201761) und nutzen die Flexibilität, SRGS erstellen, verwenden Sie die Typen von der <xref:System.Speech.Recognition.SrgsGrammar> Namespace. Sie können auch XML-Format SRGS-Grammatik, die mit einem beliebigen Text-Editor erstellen und das Ergebnis erstellen <xref:System.Speech.Recognition.GrammarBuilder>, <xref:System.Speech.Recognition.SrgsGrammar.SrgsDocument> , oder <xref:System.Speech.Recognition.Grammar> Objekte.  
  
 Darüber hinaus die <xref:System.Speech.Recognition.DictationGrammar> Klasse stellt eine besondere Schreibweisen Grammatik zur Unterstützung von einem herkömmlichen Diktat-Modell bereit.  
  
 Finden Sie unter [Grammatiken erstellen](http://msdn.microsoft.com/library/dbea278c-21a5-4816-aee7-5fd88ef993dd) in die [System Spracherkennung Programmierhandbuch für .NET Framework 4.0](http://msdn.microsoft.com/library/610116c7-3817-40ff-857b-5d41e8511043) für Weitere Informationen und Beispiele.  
  
 **Verwalten des Spracherkennungsmoduls**  
  
 Instanzen von <xref:System.Speech.Recognition.SpeechRecognizer> und <xref:System.Speech.Recognition.SpeechRecognitionEngine> mit bereitgestellten <xref:System.Speech.Recognition.Grammar> Objekte stellen die primären Zugriff auf die von der Windows Desktop Speech Technology Spracherkennungsmoduls.  
  
 Können Sie die <xref:System.Speech.Recognition.SpeechRecognizer> Klasse zum Erstellen von Clientanwendungen, die die spracherkennungstechnologie von Windows, die Sie durch konfigurieren können bereitgestellte verwenden die **Systemsteuerung**. Solche Anwendungen werden mithilfe eines Computers audio Eingabe Standardmechanismus für die Eingabe akzeptieren.  
  
 Für mehr Kontrolle über die Konfiguration und den Typ der erkennungs-Engine, erstellen Sie eine Anwendung mit <xref:System.Speech.Recognition.SpeechRecognitionEngine>, der prozessintern ausgeführt. Mithilfe der <xref:System.Speech.Recognition.SpeechRecognitionEngine> -Klasse, Sie können auch dynamisch Audioeingabe, die von Geräten, Dateien oder Streams auswählen.  
  
 Finden Sie unter [initialisieren und zu verwalten einer Spracherkennungs-Engine](http://msdn.microsoft.com/library/6eed5b59-1258-4013-8a4c-a1ddabd93ae4) in die [System Spracherkennung Programmierhandbuch für .NET Framework 4.0](http://msdn.microsoft.com/library/610116c7-3817-40ff-857b-5d41e8511043) für Weitere Informationen.  
  
 **Reagieren auf Ereignisse**  
  
 <xref:System.Speech.Recognition.SpeechRecognizer> und <xref:System.Speech.Recognition.SpeechRecognitionEngine> Objekte generiert Ereignisse als Reaktion auf die Audioeingabe für die spracherkennungs-Engine. Die `AudioLevelUpdated`, `AudioSignalProblemOccurred`, `AudioStateChanged` Ereignisse als Reaktion auf Änderungen in das eingehende Signal ausgelöst werden. Die `SpeechDetected` Ereignis wird ausgelöst, wenn die spracherkennungs-Engine eingehende Audio als Sprache identifiziert. Löst das Spracherkennungsmodul die `SpeechRecognized` Ereignis, wenn sie Spracheingabe in eines seiner geladenen Grammatiken übereinstimmt, und löst die `SpeechRecognitionRejected` wenn Spracheingabe entspricht keinem von der geladenen Grammatiken.  
  
 Andere Arten von Ereignissen enthalten die `LoadGrammarCompleted` Ereignis das eine spracherkennungs-Engine ausgelöst werden soll, wenn sie eine Grammatik geladen ist. Die <xref:System.Speech.Recognition.SpeechRecognizer.StateChanged> ist ausschließlich für die <xref:System.Speech.Recognition.SpeechRecognizer> -Klasse, die löst das Ereignis, wenn der Status der Windows-Spracherkennung geändert.  
  
 Sie können sich registrieren für Ereignisse, die löst die spracherkennungs-Engine benachrichtigt werden, und erstellen Ereignishandler, die mit der `EventsArgs` Klassen im Zusammenhang mit der jedes dieser Ereignisse, die das Verhalten Ihrer Anwendung programmieren, wenn ein Ereignis ausgelöst wird.  
  
 Finden Sie unter [mit Speech Recognition Ereignissen](http://msdn.microsoft.com/library/01c598ca-2e0e-4e89-b303-cd1cef9e8482) in die [System Spracherkennung Programmierhandbuch für .NET Framework 4.0](http://msdn.microsoft.com/library/610116c7-3817-40ff-857b-5d41e8511043) für Weitere Informationen.  
  
 ]]></format>
    </remarks>
    <altmember cref="N:System.Speech.AudioFormat" />
    <altmember cref="N:System.Speech.Recognition.SrgsGrammar" />
    <altmember cref="N:System.Speech.Synthesis" />
    <altmember cref="N:System.Speech.Synthesis.TtsEngine" />
  </Docs>
</Namespace>